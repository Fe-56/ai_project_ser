{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wav2Vec2 transfer learning on wav2vec2-base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import torch\n",
    "import random\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import Wav2Vec2Processor, Trainer, TrainingArguments, Wav2Vec2ForSequenceClassification\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../data/train_dataset.csv')\n",
    "df_train = df_train[['Filepath', 'Emotion']]\n",
    "df_test = pd.read_csv('../data/test_dataset.csv')\n",
    "df_test = df_test[['Filepath', 'Emotion']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train)\n",
    "print(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to integers\n",
    "unique_labels = sorted(df_train['Emotion'].unique())\n",
    "label_map = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "print(label_map)\n",
    "\n",
    "df_train['Emotion'] = df_train['Emotion'].map(label_map)\n",
    "df_test['Emotion'] = df_test['Emotion'].map(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train)\n",
    "print(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset class\n",
    "class SpeechEmotionDataset(Dataset):\n",
    "    # Max_length = 4s, 64000 because sampling rate is 16000\n",
    "    def __init__(self, df, processor, max_length=64000):\n",
    "        self.df = df\n",
    "        self.processor = processor\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        audio_path = '../data/' + self.df.iloc[idx]['Filepath']\n",
    "        label = self.df.iloc[idx]['Emotion']\n",
    "\n",
    "        # Load audio file\n",
    "        speech, sr = librosa.load(audio_path, sr=16000)\n",
    "\n",
    "        # Pad speech to required length\n",
    "        speech = np.pad(speech, (0, self.max_length -\n",
    "                        len(speech)), mode='constant')\n",
    "\n",
    "        # Preprocess audio\n",
    "        inputs = self.processor(speech, sampling_rate=16000, return_tensors='pt',\n",
    "                                padding=True, truncate=True, max_length=self.max_length)\n",
    "\n",
    "        input_values = inputs.input_values.squeeze()\n",
    "        return {'input_values': input_values, 'labels': torch.tensor(label, dtype=torch.long)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'facebook/wav2vec2-base'\n",
    "processor = Wav2Vec2Processor.from_pretrained(model_name)\n",
    "model = Wav2Vec2ForSequenceClassification.from_pretrained(\n",
    "    model_name, num_labels=len(label_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "train_dataset = SpeechEmotionDataset(df_train, processor)\n",
    "test_dataset = SpeechEmotionDataset(df_test, processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Training Arguments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_args = TrainingArguments(\n",
    "    output_dir='./models/wav2vec2-base',\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    fp16=True,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    report_to=[]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function for computing metrics\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids  # original labels\n",
    "    preds = np.argmax(pred.predictions, axis=1)  # model predicted labels\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, preds, average=\"weighted\")\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=train_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = trainer.evaluate()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model predictions on the test dataset\n",
    "predictions = trainer.predict(test_dataset)\n",
    "# Convert logits to predicted class labels\n",
    "pred_labels = np.argmax(predictions.predictions, axis=1)\n",
    "true_labels = predictions.label_ids  # Ground truth labels\n",
    "\n",
    "# Compute the confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, pred_labels)\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=label_map.keys(), yticklabels=label_map.keys())\n",
    "\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.title(\"Confusion Matrix Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_label_map = {idx: label for label, idx in label_map.items()}\n",
    "print(inv_label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = random.randrange(0, len(test_dataset))\n",
    "print(\"Original Label:\", inv_label_map[int(test_dataset[idx]['labels'])])\n",
    "input_values = test_dataset[idx]['input_values'].unsqueeze(0).to('cuda')\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_values)\n",
    "logits = outputs.logits\n",
    "\n",
    "predicted_class = logits.argmax(dim=-1).item()\n",
    "print('Predicted Label:', inv_label_map[predicted_class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = random.randrange(0, len(test_dataset))\n",
    "print(\"Original Label:\", inv_label_map[int(test_dataset[idx]['labels'])])\n",
    "input_values = test_dataset[idx]['input_values'].unsqueeze(0).to('cuda')\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_values)\n",
    "logits = outputs.logits\n",
    "\n",
    "predicted_class = logits.argmax(dim=-1).item()\n",
    "print('Predicted Label:', inv_label_map[predicted_class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = random.randrange(0, len(test_dataset))\n",
    "print(\"Original Label:\", inv_label_map[int(test_dataset[idx]['labels'])])\n",
    "input_values = test_dataset[idx]['input_values'].unsqueeze(0).to('cuda')\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_values)\n",
    "logits = outputs.logits\n",
    "\n",
    "predicted_class = logits.argmax(dim=-1).item()\n",
    "print('Predicted Label:', inv_label_map[predicted_class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
