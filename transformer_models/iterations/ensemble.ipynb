{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\profi\\OneDrive\\Desktop\\AI-Project--Speech-Emotion-Recognition\\myenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.nn.functional import softmax\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import set_seed, Wav2Vec2Processor, Wav2Vec2ForSequenceClassification, Wav2Vec2FeatureExtractor, WavLMForSequenceClassification, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_path = os.getcwd()\n",
    "project_root = os.path.abspath(os.path.join(notebook_path, '../..'))\n",
    "sys.path.insert(0, project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu121\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "seed = 42\n",
    "set_seed(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = pd.read_csv('../../data/val_dataset.csv')\n",
    "df_val = df_val[['Filepath', 'Emotion']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Filepath",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Emotion",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "4682723a-3513-42a4-b369-199266190add",
       "rows": [
        [
         "0",
         "./dataset/esd\\0020\\Sad\\0020_001395.wav",
         "Sad"
        ],
        [
         "1",
         "./dataset/meld\\train\\dia930_utt5.mp4",
         "Neutral"
        ],
        [
         "2",
         "./dataset/mlend\\MLEndSND_Public\\24481.wav",
         "Bored"
        ],
        [
         "3",
         "./dataset/crema-d\\AudioWAV\\1002_IEO_SAD_HI.wav",
         "Sad"
        ],
        [
         "4",
         "./dataset/esd\\0011\\Angry\\0011_000373.wav",
         "Anger"
        ],
        [
         "5",
         "./dataset/crema-d\\AudioWAV\\1050_IWL_SAD_XX.wav",
         "Sad"
        ],
        [
         "6",
         "./dataset/tess\\OAF_neutral\\OAF_lease_neutral.wav",
         "Neutral"
        ],
        [
         "7",
         "./dataset/crema-d\\AudioWAV\\1033_DFA_SAD_XX.wav",
         "Sad"
        ],
        [
         "8",
         "./dataset/crema-d\\AudioWAV\\1059_IEO_NEU_XX.wav",
         "Neutral"
        ],
        [
         "9",
         "./dataset/esd\\0014\\Angry\\0014_000503.wav",
         "Anger"
        ],
        [
         "10",
         "./dataset/ravdess\\Actor_20\\03-01-04-01-02-02-20.wav",
         "Sad"
        ],
        [
         "11",
         "./dataset/mlend\\MLEndSND_Public\\41268.wav",
         "Happy"
        ],
        [
         "12",
         "./dataset/esd\\0016\\Surprise\\0016_001715.wav",
         "Surprise"
        ],
        [
         "13",
         "./dataset/esd\\0011\\Happy\\0011_000935.wav",
         "Happy"
        ],
        [
         "14",
         "./dataset/esd\\0018\\Sad\\0018_001210.wav",
         "Sad"
        ],
        [
         "15",
         "./dataset/crema-d\\AudioWAV\\1079_IWL_SAD_XX.wav",
         "Sad"
        ],
        [
         "16",
         "./dataset/esd\\0019\\Angry\\0019_000646.wav",
         "Anger"
        ],
        [
         "17",
         "./dataset/mlend\\MLEndSND_Public\\31175.wav",
         "Bored"
        ],
        [
         "18",
         "./dataset/mlend\\MLEndSND_Public\\37494.wav",
         "Question"
        ],
        [
         "19",
         "./dataset/esd\\0017\\Sad\\0017_001154.wav",
         "Sad"
        ],
        [
         "20",
         "./dataset/mlend\\MLEndSND_Public\\12125.wav",
         "Happy"
        ],
        [
         "21",
         "./dataset/meld\\train\\dia1036_utt12.mp4",
         "Neutral"
        ],
        [
         "22",
         "./dataset/esd\\0012\\Sad\\0012_001194.wav",
         "Sad"
        ],
        [
         "23",
         "./dataset/esd\\0015\\Neutral\\0015_000079.wav",
         "Neutral"
        ],
        [
         "24",
         "./dataset/mlend\\MLEndSND_Public\\07613.wav",
         "Happy"
        ],
        [
         "25",
         "./dataset/mlend\\MLEndSND_Public\\10182.wav",
         "Happy"
        ],
        [
         "26",
         "./dataset/mlend\\MLEndSND_Public\\30464.wav",
         "Neutral"
        ],
        [
         "27",
         "./dataset/tess\\YAF_pleasant_surprised\\YAF_keen_ps.wav",
         "Surprise"
        ],
        [
         "28",
         "./dataset/meld\\train\\dia806_utt0.mp4",
         "Surprise"
        ],
        [
         "29",
         "./dataset/ravdess\\Actor_09\\03-01-01-01-02-01-09.wav",
         "Neutral"
        ],
        [
         "30",
         "./dataset/mlend\\MLEndSND_Public\\32504.wav",
         "Neutral"
        ],
        [
         "31",
         "./dataset/mlend\\MLEndSND_Public\\08221.wav",
         "Bored"
        ],
        [
         "32",
         "./dataset/mlend\\MLEndSND_Public\\11843.wav",
         "Question"
        ],
        [
         "33",
         "./dataset/mlend\\MLEndSND_Public\\26478.wav",
         "Question"
        ],
        [
         "34",
         "./dataset/esd\\0020\\Angry\\0020_000520.wav",
         "Anger"
        ],
        [
         "35",
         "./dataset/mlend\\MLEndSND_Public\\03991.wav",
         "Question"
        ],
        [
         "36",
         "./dataset/crema-d\\AudioWAV\\1062_IOM_SAD_XX.wav",
         "Sad"
        ],
        [
         "37",
         "./dataset/mlend\\MLEndSND_Public\\42670.wav",
         "Question"
        ],
        [
         "38",
         "./dataset/crema-d\\AudioWAV\\1078_IEO_ANG_MD.wav",
         "Anger"
        ],
        [
         "39",
         "./dataset/esd\\0020\\Angry\\0020_000575.wav",
         "Anger"
        ],
        [
         "40",
         "./dataset/esd\\0013\\Neutral\\0013_000174.wav",
         "Neutral"
        ],
        [
         "41",
         "./dataset/esd\\0018\\Surprise\\0018_001519.wav",
         "Surprise"
        ],
        [
         "42",
         "./dataset/mlend\\MLEndSND_Public\\03212.wav",
         "Neutral"
        ],
        [
         "43",
         "./dataset/tess\\OAF_disgust\\OAF_room_disgust.wav",
         "Disgust"
        ],
        [
         "44",
         "./dataset/mlend\\MLEndSND_Public\\19669.wav",
         "Bored"
        ],
        [
         "45",
         "./dataset/esd\\0014\\Happy\\0014_000858.wav",
         "Happy"
        ],
        [
         "46",
         "./dataset/meld\\train\\dia47_utt12.mp4",
         "Neutral"
        ],
        [
         "47",
         "./dataset/crema-d\\AudioWAV\\1001_IEO_ANG_MD.wav",
         "Anger"
        ],
        [
         "48",
         "./dataset/crema-d\\AudioWAV\\1006_IWW_ANG_XX.wav",
         "Anger"
        ],
        [
         "49",
         "./dataset/esd\\0013\\Angry\\0013_000468.wav",
         "Anger"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 9476
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filepath</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./dataset/esd\\0020\\Sad\\0020_001395.wav</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./dataset/meld\\train\\dia930_utt5.mp4</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./dataset/mlend\\MLEndSND_Public\\24481.wav</td>\n",
       "      <td>Bored</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./dataset/crema-d\\AudioWAV\\1002_IEO_SAD_HI.wav</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./dataset/esd\\0011\\Angry\\0011_000373.wav</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9471</th>\n",
       "      <td>./dataset/tess\\YAF_disgust\\YAF_take_disgust.wav</td>\n",
       "      <td>Disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9472</th>\n",
       "      <td>./dataset/mlend\\MLEndSND_Public\\43418.wav</td>\n",
       "      <td>Bored</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9473</th>\n",
       "      <td>./dataset/mlend\\MLEndSND_Public\\02459.wav</td>\n",
       "      <td>Bored</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9474</th>\n",
       "      <td>./dataset/mlend\\MLEndSND_Public\\10609.wav</td>\n",
       "      <td>Question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9475</th>\n",
       "      <td>./dataset/mlend\\MLEndSND_Public\\23072.wav</td>\n",
       "      <td>Question</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9476 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Filepath   Emotion\n",
       "0              ./dataset/esd\\0020\\Sad\\0020_001395.wav       Sad\n",
       "1                ./dataset/meld\\train\\dia930_utt5.mp4   Neutral\n",
       "2           ./dataset/mlend\\MLEndSND_Public\\24481.wav     Bored\n",
       "3      ./dataset/crema-d\\AudioWAV\\1002_IEO_SAD_HI.wav       Sad\n",
       "4            ./dataset/esd\\0011\\Angry\\0011_000373.wav     Anger\n",
       "...                                               ...       ...\n",
       "9471  ./dataset/tess\\YAF_disgust\\YAF_take_disgust.wav   Disgust\n",
       "9472        ./dataset/mlend\\MLEndSND_Public\\43418.wav     Bored\n",
       "9473        ./dataset/mlend\\MLEndSND_Public\\02459.wav     Bored\n",
       "9474        ./dataset/mlend\\MLEndSND_Public\\10609.wav  Question\n",
       "9475        ./dataset/mlend\\MLEndSND_Public\\23072.wav  Question\n",
       "\n",
       "[9476 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Anger': 0, 'Bored': 1, 'Disgust': 2, 'Fear': 3, 'Happy': 4, 'Neutral': 5, 'Question': 6, 'Sad': 7, 'Surprise': 8}\n"
     ]
    }
   ],
   "source": [
    "# Convert labels to integers\n",
    "unique_labels = sorted(df_val['Emotion'].unique())\n",
    "label_map = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "print(label_map)\n",
    "\n",
    "df_val['Emotion'] = df_val['Emotion'].map(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Filepath",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Emotion",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "94ce7eeb-16bc-42df-9a6e-e07e8d8280f8",
       "rows": [
        [
         "0",
         "./dataset/esd\\0020\\Sad\\0020_001395.wav",
         "7"
        ],
        [
         "1",
         "./dataset/meld\\train\\dia930_utt5.mp4",
         "5"
        ],
        [
         "2",
         "./dataset/mlend\\MLEndSND_Public\\24481.wav",
         "1"
        ],
        [
         "3",
         "./dataset/crema-d\\AudioWAV\\1002_IEO_SAD_HI.wav",
         "7"
        ],
        [
         "4",
         "./dataset/esd\\0011\\Angry\\0011_000373.wav",
         "0"
        ],
        [
         "5",
         "./dataset/crema-d\\AudioWAV\\1050_IWL_SAD_XX.wav",
         "7"
        ],
        [
         "6",
         "./dataset/tess\\OAF_neutral\\OAF_lease_neutral.wav",
         "5"
        ],
        [
         "7",
         "./dataset/crema-d\\AudioWAV\\1033_DFA_SAD_XX.wav",
         "7"
        ],
        [
         "8",
         "./dataset/crema-d\\AudioWAV\\1059_IEO_NEU_XX.wav",
         "5"
        ],
        [
         "9",
         "./dataset/esd\\0014\\Angry\\0014_000503.wav",
         "0"
        ],
        [
         "10",
         "./dataset/ravdess\\Actor_20\\03-01-04-01-02-02-20.wav",
         "7"
        ],
        [
         "11",
         "./dataset/mlend\\MLEndSND_Public\\41268.wav",
         "4"
        ],
        [
         "12",
         "./dataset/esd\\0016\\Surprise\\0016_001715.wav",
         "8"
        ],
        [
         "13",
         "./dataset/esd\\0011\\Happy\\0011_000935.wav",
         "4"
        ],
        [
         "14",
         "./dataset/esd\\0018\\Sad\\0018_001210.wav",
         "7"
        ],
        [
         "15",
         "./dataset/crema-d\\AudioWAV\\1079_IWL_SAD_XX.wav",
         "7"
        ],
        [
         "16",
         "./dataset/esd\\0019\\Angry\\0019_000646.wav",
         "0"
        ],
        [
         "17",
         "./dataset/mlend\\MLEndSND_Public\\31175.wav",
         "1"
        ],
        [
         "18",
         "./dataset/mlend\\MLEndSND_Public\\37494.wav",
         "6"
        ],
        [
         "19",
         "./dataset/esd\\0017\\Sad\\0017_001154.wav",
         "7"
        ],
        [
         "20",
         "./dataset/mlend\\MLEndSND_Public\\12125.wav",
         "4"
        ],
        [
         "21",
         "./dataset/meld\\train\\dia1036_utt12.mp4",
         "5"
        ],
        [
         "22",
         "./dataset/esd\\0012\\Sad\\0012_001194.wav",
         "7"
        ],
        [
         "23",
         "./dataset/esd\\0015\\Neutral\\0015_000079.wav",
         "5"
        ],
        [
         "24",
         "./dataset/mlend\\MLEndSND_Public\\07613.wav",
         "4"
        ],
        [
         "25",
         "./dataset/mlend\\MLEndSND_Public\\10182.wav",
         "4"
        ],
        [
         "26",
         "./dataset/mlend\\MLEndSND_Public\\30464.wav",
         "5"
        ],
        [
         "27",
         "./dataset/tess\\YAF_pleasant_surprised\\YAF_keen_ps.wav",
         "8"
        ],
        [
         "28",
         "./dataset/meld\\train\\dia806_utt0.mp4",
         "8"
        ],
        [
         "29",
         "./dataset/ravdess\\Actor_09\\03-01-01-01-02-01-09.wav",
         "5"
        ],
        [
         "30",
         "./dataset/mlend\\MLEndSND_Public\\32504.wav",
         "5"
        ],
        [
         "31",
         "./dataset/mlend\\MLEndSND_Public\\08221.wav",
         "1"
        ],
        [
         "32",
         "./dataset/mlend\\MLEndSND_Public\\11843.wav",
         "6"
        ],
        [
         "33",
         "./dataset/mlend\\MLEndSND_Public\\26478.wav",
         "6"
        ],
        [
         "34",
         "./dataset/esd\\0020\\Angry\\0020_000520.wav",
         "0"
        ],
        [
         "35",
         "./dataset/mlend\\MLEndSND_Public\\03991.wav",
         "6"
        ],
        [
         "36",
         "./dataset/crema-d\\AudioWAV\\1062_IOM_SAD_XX.wav",
         "7"
        ],
        [
         "37",
         "./dataset/mlend\\MLEndSND_Public\\42670.wav",
         "6"
        ],
        [
         "38",
         "./dataset/crema-d\\AudioWAV\\1078_IEO_ANG_MD.wav",
         "0"
        ],
        [
         "39",
         "./dataset/esd\\0020\\Angry\\0020_000575.wav",
         "0"
        ],
        [
         "40",
         "./dataset/esd\\0013\\Neutral\\0013_000174.wav",
         "5"
        ],
        [
         "41",
         "./dataset/esd\\0018\\Surprise\\0018_001519.wav",
         "8"
        ],
        [
         "42",
         "./dataset/mlend\\MLEndSND_Public\\03212.wav",
         "5"
        ],
        [
         "43",
         "./dataset/tess\\OAF_disgust\\OAF_room_disgust.wav",
         "2"
        ],
        [
         "44",
         "./dataset/mlend\\MLEndSND_Public\\19669.wav",
         "1"
        ],
        [
         "45",
         "./dataset/esd\\0014\\Happy\\0014_000858.wav",
         "4"
        ],
        [
         "46",
         "./dataset/meld\\train\\dia47_utt12.mp4",
         "5"
        ],
        [
         "47",
         "./dataset/crema-d\\AudioWAV\\1001_IEO_ANG_MD.wav",
         "0"
        ],
        [
         "48",
         "./dataset/crema-d\\AudioWAV\\1006_IWW_ANG_XX.wav",
         "0"
        ],
        [
         "49",
         "./dataset/esd\\0013\\Angry\\0013_000468.wav",
         "0"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 9476
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filepath</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./dataset/esd\\0020\\Sad\\0020_001395.wav</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./dataset/meld\\train\\dia930_utt5.mp4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./dataset/mlend\\MLEndSND_Public\\24481.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./dataset/crema-d\\AudioWAV\\1002_IEO_SAD_HI.wav</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./dataset/esd\\0011\\Angry\\0011_000373.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9471</th>\n",
       "      <td>./dataset/tess\\YAF_disgust\\YAF_take_disgust.wav</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9472</th>\n",
       "      <td>./dataset/mlend\\MLEndSND_Public\\43418.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9473</th>\n",
       "      <td>./dataset/mlend\\MLEndSND_Public\\02459.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9474</th>\n",
       "      <td>./dataset/mlend\\MLEndSND_Public\\10609.wav</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9475</th>\n",
       "      <td>./dataset/mlend\\MLEndSND_Public\\23072.wav</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9476 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Filepath  Emotion\n",
       "0              ./dataset/esd\\0020\\Sad\\0020_001395.wav        7\n",
       "1                ./dataset/meld\\train\\dia930_utt5.mp4        5\n",
       "2           ./dataset/mlend\\MLEndSND_Public\\24481.wav        1\n",
       "3      ./dataset/crema-d\\AudioWAV\\1002_IEO_SAD_HI.wav        7\n",
       "4            ./dataset/esd\\0011\\Angry\\0011_000373.wav        0\n",
       "...                                               ...      ...\n",
       "9471  ./dataset/tess\\YAF_disgust\\YAF_take_disgust.wav        2\n",
       "9472        ./dataset/mlend\\MLEndSND_Public\\43418.wav        1\n",
       "9473        ./dataset/mlend\\MLEndSND_Public\\02459.wav        1\n",
       "9474        ./dataset/mlend\\MLEndSND_Public\\10609.wav        6\n",
       "9475        ./dataset/mlend\\MLEndSND_Public\\23072.wav        6\n",
       "\n",
       "[9476 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\profi\\OneDrive\\Desktop\\AI-Project--Speech-Emotion-Recognition\\myenv\\lib\\site-packages\\transformers\\configuration_utils.py:315: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load Model 1: facebook/wav2vec2-base\n",
    "model1_checkpoint_path = '../models/wav2vec2-base_standardpad/checkpoint-16584'\n",
    "processor1 = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base\")\n",
    "model1 = Wav2Vec2ForSequenceClassification.from_pretrained(\n",
    "    model1_checkpoint_path, num_labels=len(label_map))\n",
    "\n",
    "# Load Model 2: microsoft/wavlm-base\n",
    "model2_checkpoint_path = '../models/wavlm-base_standardpad/checkpoint-13820'\n",
    "processor2 = Wav2Vec2FeatureExtractor.from_pretrained(\"microsoft/wavlm-base\")\n",
    "model2 = WavLMForSequenceClassification.from_pretrained(\n",
    "    model2_checkpoint_path, num_labels=len(label_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_models.emotion_datasets.SpeechEmotionDatasetStandardPad import SpeechEmotionDatasetStandardPad\n",
    "\n",
    "# Create two validation datasets, one for each model\n",
    "val_dataset1 = SpeechEmotionDatasetStandardPad(df_val, processor1)\n",
    "val_dataset2 = SpeechEmotionDatasetStandardPad(df_val, processor2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword argument `truncate` is not a valid argument for this processor and will be ignored.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_values': tensor([ 1.0359e-02,  1.0359e-02,  1.0359e-02,  ..., -7.3200e-05,\n",
       "         -7.3200e-05, -7.3200e-05]),\n",
       " 'labels': tensor(7)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_values': tensor([0.0005, 0.0005, 0.0005,  ..., 0.0000, 0.0000, 0.0000]),\n",
       " 'labels': tensor(7)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset2[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get predictions from each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to obtain model probabilities\n",
    "def get_model_probs(model, dataset, batch_size=128):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            # The dataset returns a dict with 'input_values'\n",
    "            input_values = batch[\"input_values\"].to(device)\n",
    "            outputs = model(input_values).logits  # shape: (B, num_labels)\n",
    "            probs = softmax(outputs, dim=1).cpu().numpy()\n",
    "            all_probs.append(probs)\n",
    "    return np.vstack(all_probs)  # shape: (N, num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\profi\\OneDrive\\Desktop\\AI-Project--Speech-Emotion-Recognition\\transformer_models\\emotion_datasets\\SpeechEmotionDatasetStandardPad.py:22: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  speech, sr = librosa.load(audio_path, sr=16000)\n",
      "c:\\Users\\profi\\OneDrive\\Desktop\\AI-Project--Speech-Emotion-Recognition\\myenv\\lib\\site-packages\\librosa\\core\\audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_meta (stacked predictions): (9476, 18)\n",
      "Shape of y_meta (labels): (9476,)\n"
     ]
    }
   ],
   "source": [
    "# Get probabilities for each model from their respective datasets\n",
    "probs1 = get_model_probs(model1, val_dataset1, batch_size=128)\n",
    "probs2 = get_model_probs(model2, val_dataset2, batch_size=128)\n",
    "\n",
    "# Stack predictions horizontally\n",
    "X_meta = np.hstack([probs1, probs2])  # shape: (N, num_labels * 2)\n",
    "\n",
    "# Extract ground truth labels from one of the datasets (they should be the same)\n",
    "y_meta = np.array([sample['labels'].item() for sample in val_dataset1])\n",
    "\n",
    "print(\"Shape of X_meta (stacked predictions):\", X_meta.shape)\n",
    "print(\"Shape of y_meta (labels):\", y_meta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
