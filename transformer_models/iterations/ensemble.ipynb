{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\profi\\OneDrive\\Desktop\\AI-Project--Speech-Emotion-Recognition\\myenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from torch.nn.functional import softmax\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import set_seed, Wav2Vec2Processor, Wav2Vec2ForSequenceClassification, Wav2Vec2FeatureExtractor, WavLMForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_path = os.getcwd()\n",
    "project_root = os.path.abspath(os.path.join(notebook_path, '../..'))\n",
    "sys.path.insert(0, project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu121\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "seed = 42\n",
    "set_seed(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = pd.read_csv('../../data/val_dataset.csv')\n",
    "df_val = df_val[['Filepath', 'Emotion']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Filepath",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Emotion",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "ae47107f-4ea3-4813-8c98-cc85ca08c48f",
       "rows": [
        [
         "0",
         "./dataset/esd\\0020\\Sad\\0020_001395.wav",
         "Sad"
        ],
        [
         "1",
         "./dataset/meld\\train\\dia930_utt5.mp4",
         "Neutral"
        ],
        [
         "2",
         "./dataset/mlend\\MLEndSND_Public\\24481.wav",
         "Bored"
        ],
        [
         "3",
         "./dataset/crema-d\\AudioWAV\\1002_IEO_SAD_HI.wav",
         "Sad"
        ],
        [
         "4",
         "./dataset/esd\\0011\\Angry\\0011_000373.wav",
         "Anger"
        ],
        [
         "5",
         "./dataset/crema-d\\AudioWAV\\1050_IWL_SAD_XX.wav",
         "Sad"
        ],
        [
         "6",
         "./dataset/tess\\OAF_neutral\\OAF_lease_neutral.wav",
         "Neutral"
        ],
        [
         "7",
         "./dataset/crema-d\\AudioWAV\\1033_DFA_SAD_XX.wav",
         "Sad"
        ],
        [
         "8",
         "./dataset/crema-d\\AudioWAV\\1059_IEO_NEU_XX.wav",
         "Neutral"
        ],
        [
         "9",
         "./dataset/esd\\0014\\Angry\\0014_000503.wav",
         "Anger"
        ],
        [
         "10",
         "./dataset/ravdess\\Actor_20\\03-01-04-01-02-02-20.wav",
         "Sad"
        ],
        [
         "11",
         "./dataset/mlend\\MLEndSND_Public\\41268.wav",
         "Happy"
        ],
        [
         "12",
         "./dataset/esd\\0016\\Surprise\\0016_001715.wav",
         "Surprise"
        ],
        [
         "13",
         "./dataset/esd\\0011\\Happy\\0011_000935.wav",
         "Happy"
        ],
        [
         "14",
         "./dataset/esd\\0018\\Sad\\0018_001210.wav",
         "Sad"
        ],
        [
         "15",
         "./dataset/crema-d\\AudioWAV\\1079_IWL_SAD_XX.wav",
         "Sad"
        ],
        [
         "16",
         "./dataset/esd\\0019\\Angry\\0019_000646.wav",
         "Anger"
        ],
        [
         "17",
         "./dataset/mlend\\MLEndSND_Public\\31175.wav",
         "Bored"
        ],
        [
         "18",
         "./dataset/mlend\\MLEndSND_Public\\37494.wav",
         "Question"
        ],
        [
         "19",
         "./dataset/esd\\0017\\Sad\\0017_001154.wav",
         "Sad"
        ],
        [
         "20",
         "./dataset/mlend\\MLEndSND_Public\\12125.wav",
         "Happy"
        ],
        [
         "21",
         "./dataset/meld\\train\\dia1036_utt12.mp4",
         "Neutral"
        ],
        [
         "22",
         "./dataset/esd\\0012\\Sad\\0012_001194.wav",
         "Sad"
        ],
        [
         "23",
         "./dataset/esd\\0015\\Neutral\\0015_000079.wav",
         "Neutral"
        ],
        [
         "24",
         "./dataset/mlend\\MLEndSND_Public\\07613.wav",
         "Happy"
        ],
        [
         "25",
         "./dataset/mlend\\MLEndSND_Public\\10182.wav",
         "Happy"
        ],
        [
         "26",
         "./dataset/mlend\\MLEndSND_Public\\30464.wav",
         "Neutral"
        ],
        [
         "27",
         "./dataset/tess\\YAF_pleasant_surprised\\YAF_keen_ps.wav",
         "Surprise"
        ],
        [
         "28",
         "./dataset/meld\\train\\dia806_utt0.mp4",
         "Surprise"
        ],
        [
         "29",
         "./dataset/ravdess\\Actor_09\\03-01-01-01-02-01-09.wav",
         "Neutral"
        ],
        [
         "30",
         "./dataset/mlend\\MLEndSND_Public\\32504.wav",
         "Neutral"
        ],
        [
         "31",
         "./dataset/mlend\\MLEndSND_Public\\08221.wav",
         "Bored"
        ],
        [
         "32",
         "./dataset/mlend\\MLEndSND_Public\\11843.wav",
         "Question"
        ],
        [
         "33",
         "./dataset/mlend\\MLEndSND_Public\\26478.wav",
         "Question"
        ],
        [
         "34",
         "./dataset/esd\\0020\\Angry\\0020_000520.wav",
         "Anger"
        ],
        [
         "35",
         "./dataset/mlend\\MLEndSND_Public\\03991.wav",
         "Question"
        ],
        [
         "36",
         "./dataset/crema-d\\AudioWAV\\1062_IOM_SAD_XX.wav",
         "Sad"
        ],
        [
         "37",
         "./dataset/mlend\\MLEndSND_Public\\42670.wav",
         "Question"
        ],
        [
         "38",
         "./dataset/crema-d\\AudioWAV\\1078_IEO_ANG_MD.wav",
         "Anger"
        ],
        [
         "39",
         "./dataset/esd\\0020\\Angry\\0020_000575.wav",
         "Anger"
        ],
        [
         "40",
         "./dataset/esd\\0013\\Neutral\\0013_000174.wav",
         "Neutral"
        ],
        [
         "41",
         "./dataset/esd\\0018\\Surprise\\0018_001519.wav",
         "Surprise"
        ],
        [
         "42",
         "./dataset/mlend\\MLEndSND_Public\\03212.wav",
         "Neutral"
        ],
        [
         "43",
         "./dataset/tess\\OAF_disgust\\OAF_room_disgust.wav",
         "Disgust"
        ],
        [
         "44",
         "./dataset/mlend\\MLEndSND_Public\\19669.wav",
         "Bored"
        ],
        [
         "45",
         "./dataset/esd\\0014\\Happy\\0014_000858.wav",
         "Happy"
        ],
        [
         "46",
         "./dataset/meld\\train\\dia47_utt12.mp4",
         "Neutral"
        ],
        [
         "47",
         "./dataset/crema-d\\AudioWAV\\1001_IEO_ANG_MD.wav",
         "Anger"
        ],
        [
         "48",
         "./dataset/crema-d\\AudioWAV\\1006_IWW_ANG_XX.wav",
         "Anger"
        ],
        [
         "49",
         "./dataset/esd\\0013\\Angry\\0013_000468.wav",
         "Anger"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 9476
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filepath</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./dataset/esd\\0020\\Sad\\0020_001395.wav</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./dataset/meld\\train\\dia930_utt5.mp4</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./dataset/mlend\\MLEndSND_Public\\24481.wav</td>\n",
       "      <td>Bored</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./dataset/crema-d\\AudioWAV\\1002_IEO_SAD_HI.wav</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./dataset/esd\\0011\\Angry\\0011_000373.wav</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9471</th>\n",
       "      <td>./dataset/tess\\YAF_disgust\\YAF_take_disgust.wav</td>\n",
       "      <td>Disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9472</th>\n",
       "      <td>./dataset/mlend\\MLEndSND_Public\\43418.wav</td>\n",
       "      <td>Bored</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9473</th>\n",
       "      <td>./dataset/mlend\\MLEndSND_Public\\02459.wav</td>\n",
       "      <td>Bored</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9474</th>\n",
       "      <td>./dataset/mlend\\MLEndSND_Public\\10609.wav</td>\n",
       "      <td>Question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9475</th>\n",
       "      <td>./dataset/mlend\\MLEndSND_Public\\23072.wav</td>\n",
       "      <td>Question</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9476 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Filepath   Emotion\n",
       "0              ./dataset/esd\\0020\\Sad\\0020_001395.wav       Sad\n",
       "1                ./dataset/meld\\train\\dia930_utt5.mp4   Neutral\n",
       "2           ./dataset/mlend\\MLEndSND_Public\\24481.wav     Bored\n",
       "3      ./dataset/crema-d\\AudioWAV\\1002_IEO_SAD_HI.wav       Sad\n",
       "4            ./dataset/esd\\0011\\Angry\\0011_000373.wav     Anger\n",
       "...                                               ...       ...\n",
       "9471  ./dataset/tess\\YAF_disgust\\YAF_take_disgust.wav   Disgust\n",
       "9472        ./dataset/mlend\\MLEndSND_Public\\43418.wav     Bored\n",
       "9473        ./dataset/mlend\\MLEndSND_Public\\02459.wav     Bored\n",
       "9474        ./dataset/mlend\\MLEndSND_Public\\10609.wav  Question\n",
       "9475        ./dataset/mlend\\MLEndSND_Public\\23072.wav  Question\n",
       "\n",
       "[9476 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Anger': 0, 'Bored': 1, 'Disgust': 2, 'Fear': 3, 'Happy': 4, 'Neutral': 5, 'Question': 6, 'Sad': 7, 'Surprise': 8}\n"
     ]
    }
   ],
   "source": [
    "# Convert labels to integers\n",
    "unique_labels = sorted(df_val['Emotion'].unique())\n",
    "label_map = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "print(label_map)\n",
    "\n",
    "df_val['Emotion'] = df_val['Emotion'].map(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Filepath",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Emotion",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "af2bcd51-5796-4fcc-82b2-1a8922dc5e7c",
       "rows": [
        [
         "0",
         "./dataset/esd\\0020\\Sad\\0020_001395.wav",
         "7"
        ],
        [
         "1",
         "./dataset/meld\\train\\dia930_utt5.mp4",
         "5"
        ],
        [
         "2",
         "./dataset/mlend\\MLEndSND_Public\\24481.wav",
         "1"
        ],
        [
         "3",
         "./dataset/crema-d\\AudioWAV\\1002_IEO_SAD_HI.wav",
         "7"
        ],
        [
         "4",
         "./dataset/esd\\0011\\Angry\\0011_000373.wav",
         "0"
        ],
        [
         "5",
         "./dataset/crema-d\\AudioWAV\\1050_IWL_SAD_XX.wav",
         "7"
        ],
        [
         "6",
         "./dataset/tess\\OAF_neutral\\OAF_lease_neutral.wav",
         "5"
        ],
        [
         "7",
         "./dataset/crema-d\\AudioWAV\\1033_DFA_SAD_XX.wav",
         "7"
        ],
        [
         "8",
         "./dataset/crema-d\\AudioWAV\\1059_IEO_NEU_XX.wav",
         "5"
        ],
        [
         "9",
         "./dataset/esd\\0014\\Angry\\0014_000503.wav",
         "0"
        ],
        [
         "10",
         "./dataset/ravdess\\Actor_20\\03-01-04-01-02-02-20.wav",
         "7"
        ],
        [
         "11",
         "./dataset/mlend\\MLEndSND_Public\\41268.wav",
         "4"
        ],
        [
         "12",
         "./dataset/esd\\0016\\Surprise\\0016_001715.wav",
         "8"
        ],
        [
         "13",
         "./dataset/esd\\0011\\Happy\\0011_000935.wav",
         "4"
        ],
        [
         "14",
         "./dataset/esd\\0018\\Sad\\0018_001210.wav",
         "7"
        ],
        [
         "15",
         "./dataset/crema-d\\AudioWAV\\1079_IWL_SAD_XX.wav",
         "7"
        ],
        [
         "16",
         "./dataset/esd\\0019\\Angry\\0019_000646.wav",
         "0"
        ],
        [
         "17",
         "./dataset/mlend\\MLEndSND_Public\\31175.wav",
         "1"
        ],
        [
         "18",
         "./dataset/mlend\\MLEndSND_Public\\37494.wav",
         "6"
        ],
        [
         "19",
         "./dataset/esd\\0017\\Sad\\0017_001154.wav",
         "7"
        ],
        [
         "20",
         "./dataset/mlend\\MLEndSND_Public\\12125.wav",
         "4"
        ],
        [
         "21",
         "./dataset/meld\\train\\dia1036_utt12.mp4",
         "5"
        ],
        [
         "22",
         "./dataset/esd\\0012\\Sad\\0012_001194.wav",
         "7"
        ],
        [
         "23",
         "./dataset/esd\\0015\\Neutral\\0015_000079.wav",
         "5"
        ],
        [
         "24",
         "./dataset/mlend\\MLEndSND_Public\\07613.wav",
         "4"
        ],
        [
         "25",
         "./dataset/mlend\\MLEndSND_Public\\10182.wav",
         "4"
        ],
        [
         "26",
         "./dataset/mlend\\MLEndSND_Public\\30464.wav",
         "5"
        ],
        [
         "27",
         "./dataset/tess\\YAF_pleasant_surprised\\YAF_keen_ps.wav",
         "8"
        ],
        [
         "28",
         "./dataset/meld\\train\\dia806_utt0.mp4",
         "8"
        ],
        [
         "29",
         "./dataset/ravdess\\Actor_09\\03-01-01-01-02-01-09.wav",
         "5"
        ],
        [
         "30",
         "./dataset/mlend\\MLEndSND_Public\\32504.wav",
         "5"
        ],
        [
         "31",
         "./dataset/mlend\\MLEndSND_Public\\08221.wav",
         "1"
        ],
        [
         "32",
         "./dataset/mlend\\MLEndSND_Public\\11843.wav",
         "6"
        ],
        [
         "33",
         "./dataset/mlend\\MLEndSND_Public\\26478.wav",
         "6"
        ],
        [
         "34",
         "./dataset/esd\\0020\\Angry\\0020_000520.wav",
         "0"
        ],
        [
         "35",
         "./dataset/mlend\\MLEndSND_Public\\03991.wav",
         "6"
        ],
        [
         "36",
         "./dataset/crema-d\\AudioWAV\\1062_IOM_SAD_XX.wav",
         "7"
        ],
        [
         "37",
         "./dataset/mlend\\MLEndSND_Public\\42670.wav",
         "6"
        ],
        [
         "38",
         "./dataset/crema-d\\AudioWAV\\1078_IEO_ANG_MD.wav",
         "0"
        ],
        [
         "39",
         "./dataset/esd\\0020\\Angry\\0020_000575.wav",
         "0"
        ],
        [
         "40",
         "./dataset/esd\\0013\\Neutral\\0013_000174.wav",
         "5"
        ],
        [
         "41",
         "./dataset/esd\\0018\\Surprise\\0018_001519.wav",
         "8"
        ],
        [
         "42",
         "./dataset/mlend\\MLEndSND_Public\\03212.wav",
         "5"
        ],
        [
         "43",
         "./dataset/tess\\OAF_disgust\\OAF_room_disgust.wav",
         "2"
        ],
        [
         "44",
         "./dataset/mlend\\MLEndSND_Public\\19669.wav",
         "1"
        ],
        [
         "45",
         "./dataset/esd\\0014\\Happy\\0014_000858.wav",
         "4"
        ],
        [
         "46",
         "./dataset/meld\\train\\dia47_utt12.mp4",
         "5"
        ],
        [
         "47",
         "./dataset/crema-d\\AudioWAV\\1001_IEO_ANG_MD.wav",
         "0"
        ],
        [
         "48",
         "./dataset/crema-d\\AudioWAV\\1006_IWW_ANG_XX.wav",
         "0"
        ],
        [
         "49",
         "./dataset/esd\\0013\\Angry\\0013_000468.wav",
         "0"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 9476
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filepath</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./dataset/esd\\0020\\Sad\\0020_001395.wav</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./dataset/meld\\train\\dia930_utt5.mp4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./dataset/mlend\\MLEndSND_Public\\24481.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./dataset/crema-d\\AudioWAV\\1002_IEO_SAD_HI.wav</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./dataset/esd\\0011\\Angry\\0011_000373.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9471</th>\n",
       "      <td>./dataset/tess\\YAF_disgust\\YAF_take_disgust.wav</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9472</th>\n",
       "      <td>./dataset/mlend\\MLEndSND_Public\\43418.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9473</th>\n",
       "      <td>./dataset/mlend\\MLEndSND_Public\\02459.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9474</th>\n",
       "      <td>./dataset/mlend\\MLEndSND_Public\\10609.wav</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9475</th>\n",
       "      <td>./dataset/mlend\\MLEndSND_Public\\23072.wav</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9476 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Filepath  Emotion\n",
       "0              ./dataset/esd\\0020\\Sad\\0020_001395.wav        7\n",
       "1                ./dataset/meld\\train\\dia930_utt5.mp4        5\n",
       "2           ./dataset/mlend\\MLEndSND_Public\\24481.wav        1\n",
       "3      ./dataset/crema-d\\AudioWAV\\1002_IEO_SAD_HI.wav        7\n",
       "4            ./dataset/esd\\0011\\Angry\\0011_000373.wav        0\n",
       "...                                               ...      ...\n",
       "9471  ./dataset/tess\\YAF_disgust\\YAF_take_disgust.wav        2\n",
       "9472        ./dataset/mlend\\MLEndSND_Public\\43418.wav        1\n",
       "9473        ./dataset/mlend\\MLEndSND_Public\\02459.wav        1\n",
       "9474        ./dataset/mlend\\MLEndSND_Public\\10609.wav        6\n",
       "9475        ./dataset/mlend\\MLEndSND_Public\\23072.wav        6\n",
       "\n",
       "[9476 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\profi\\OneDrive\\Desktop\\AI-Project--Speech-Emotion-Recognition\\myenv\\lib\\site-packages\\transformers\\configuration_utils.py:315: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load Model 1: facebook/wav2vec2-base\n",
    "model1_checkpoint_path = '../models/wav2vec2-base_standardpad_augmentation/checkpoint-33168' # change to wav2vec2 best model\n",
    "processor1 = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base\")\n",
    "model1 = Wav2Vec2ForSequenceClassification.from_pretrained(\n",
    "    model1_checkpoint_path, num_labels=len(label_map))\n",
    "\n",
    "# Load Model 2: microsoft/wavlm-base\n",
    "model2_checkpoint_path = '../models/wavlm-base_standardpad_augmentation/checkpoint-55280' # change to wavlm best model\n",
    "processor2 = Wav2Vec2FeatureExtractor.from_pretrained(\"microsoft/wavlm-base\")\n",
    "model2 = WavLMForSequenceClassification.from_pretrained(\n",
    "    model2_checkpoint_path, num_labels=len(label_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_models.emotion_datasets.SpeechEmotionDatasetStandardPad import SpeechEmotionDatasetStandardPad\n",
    "\n",
    "# Create two validation datasets, one for each model\n",
    "val_dataset1 = SpeechEmotionDatasetStandardPad(df_val, processor1)\n",
    "val_dataset2 = SpeechEmotionDatasetStandardPad(df_val, processor2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword argument `truncate` is not a valid argument for this processor and will be ignored.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_values': tensor([ 1.0359e-02,  1.0359e-02,  1.0359e-02,  ..., -7.3200e-05,\n",
       "         -7.3200e-05, -7.3200e-05]),\n",
       " 'labels': tensor(7)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_values': tensor([0.0005, 0.0005, 0.0005,  ..., 0.0000, 0.0000, 0.0000]),\n",
       " 'labels': tensor(7)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset2[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get predictions from each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to obtain model probabilities\n",
    "def get_model_logits(model, dataset, batch_size=128):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "    all_logits = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            # The dataset returns a dict with 'input_values'\n",
    "            input_values = batch[\"input_values\"].to(device)\n",
    "            logits = model(input_values).logits  # shape: (B, num_labels)\n",
    "            all_logits.append(logits.cpu().numpy())\n",
    "    return np.vstack(all_logits)  # shape: (N, num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\profi\\OneDrive\\Desktop\\AI-Project--Speech-Emotion-Recognition\\transformer_models\\emotion_datasets\\SpeechEmotionDatasetStandardPad.py:22: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  speech, sr = librosa.load(audio_path, sr=16000)\n",
      "c:\\Users\\profi\\OneDrive\\Desktop\\AI-Project--Speech-Emotion-Recognition\\myenv\\lib\\site-packages\\librosa\\core\\audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_meta (stacked predictions): (9476, 18)\n",
      "Shape of y_meta (labels): (9476,)\n"
     ]
    }
   ],
   "source": [
    "# Get probabilities for each model from their respective datasets\n",
    "logits1 = get_model_logits(model1, val_dataset1, batch_size=128)\n",
    "logits2 = get_model_logits(model2, val_dataset2, batch_size=128)\n",
    "\n",
    "# Stack predictions horizontally\n",
    "X_meta = np.hstack([logits1, logits2])  # shape: (N, num_labels * 2)\n",
    "\n",
    "# Extract ground truth labels from one of the datasets (they should be the same)\n",
    "y_meta = np.array([sample['labels'].item() for sample in val_dataset1])\n",
    "\n",
    "print(\"Shape of X_meta (stacked predictions):\", X_meta.shape)\n",
    "print(\"Shape of y_meta (labels):\", y_meta.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define simple Feed-Forward Neural Network for meta classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MetaFFNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(MetaFFNN, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            # First hidden layer\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            # Second hidden layer\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            # Third hidden layer\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            # Output layer\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define meta dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MetaDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train meta classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fold 1\n",
      "Epoch 1, Average Loss: 0.6643\n",
      "Epoch 2, Average Loss: 0.4845\n",
      "Epoch 3, Average Loss: 0.4580\n",
      "Epoch 4, Average Loss: 0.4402\n",
      "Epoch 5, Average Loss: 0.4397\n",
      "Epoch 6, Average Loss: 0.4216\n",
      "Epoch 7, Average Loss: 0.4205\n",
      "Epoch 8, Average Loss: 0.4182\n",
      "Epoch 9, Average Loss: 0.4126\n",
      "Epoch 10, Average Loss: 0.4159\n",
      "Epoch 11, Average Loss: 0.4024\n",
      "Epoch 12, Average Loss: 0.3976\n",
      "Epoch 13, Average Loss: 0.4043\n",
      "Epoch 14, Average Loss: 0.3947\n",
      "Epoch 15, Average Loss: 0.3979\n",
      "Epoch 16, Average Loss: 0.3826\n",
      "Epoch 17, Average Loss: 0.3850\n",
      "Epoch 18, Average Loss: 0.3776\n",
      "Epoch 19, Average Loss: 0.3797\n",
      "Epoch 20, Average Loss: 0.3764\n",
      "Epoch 21, Average Loss: 0.3760\n",
      "Epoch 22, Average Loss: 0.3763\n",
      "Epoch 23, Average Loss: 0.3601\n",
      "Epoch 24, Average Loss: 0.3622\n",
      "Epoch 25, Average Loss: 0.3676\n",
      "Epoch 26, Average Loss: 0.3620\n",
      "Epoch 27, Average Loss: 0.3621\n",
      "Epoch 28, Average Loss: 0.3563\n",
      "Epoch 29, Average Loss: 0.3449\n",
      "Epoch 30, Average Loss: 0.3496\n",
      "Epoch 31, Average Loss: 0.3648\n",
      "Epoch 32, Average Loss: 0.3460\n",
      "Epoch 33, Average Loss: 0.3568\n",
      "Epoch 34, Average Loss: 0.3456\n",
      "Epoch 35, Average Loss: 0.3431\n",
      "Epoch 36, Average Loss: 0.3349\n",
      "Epoch 37, Average Loss: 0.3507\n",
      "Epoch 38, Average Loss: 0.3475\n",
      "Epoch 39, Average Loss: 0.3342\n",
      "Epoch 40, Average Loss: 0.3305\n",
      "Epoch 41, Average Loss: 0.3288\n",
      "Epoch 42, Average Loss: 0.3358\n",
      "Epoch 43, Average Loss: 0.3352\n",
      "Epoch 44, Average Loss: 0.3325\n",
      "Epoch 45, Average Loss: 0.3230\n",
      "Epoch 46, Average Loss: 0.3318\n",
      "Epoch 47, Average Loss: 0.3232\n",
      "Epoch 48, Average Loss: 0.3218\n",
      "Epoch 49, Average Loss: 0.3163\n",
      "Epoch 50, Average Loss: 0.3225\n",
      "Epoch 51, Average Loss: 0.3232\n",
      "Epoch 52, Average Loss: 0.3248\n",
      "Epoch 53, Average Loss: 0.3106\n",
      "Epoch 54, Average Loss: 0.3120\n",
      "Epoch 55, Average Loss: 0.3161\n",
      "Epoch 56, Average Loss: 0.3059\n",
      "Epoch 57, Average Loss: 0.3137\n",
      "Epoch 58, Average Loss: 0.3041\n",
      "Epoch 59, Average Loss: 0.3087\n",
      "Epoch 60, Average Loss: 0.3011\n",
      "Epoch 61, Average Loss: 0.3162\n",
      "Epoch 62, Average Loss: 0.3037\n",
      "Epoch 63, Average Loss: 0.2969\n",
      "Epoch 64, Average Loss: 0.3025\n",
      "Epoch 65, Average Loss: 0.3051\n",
      "Epoch 66, Average Loss: 0.2916\n",
      "Epoch 67, Average Loss: 0.2926\n",
      "Epoch 68, Average Loss: 0.2908\n",
      "Epoch 69, Average Loss: 0.2932\n",
      "Epoch 70, Average Loss: 0.2973\n",
      "Epoch 71, Average Loss: 0.2975\n",
      "Epoch 72, Average Loss: 0.2902\n",
      "Epoch 73, Average Loss: 0.2879\n",
      "Epoch 74, Average Loss: 0.2861\n",
      "Epoch 75, Average Loss: 0.2932\n",
      "Epoch 76, Average Loss: 0.2925\n",
      "Epoch 77, Average Loss: 0.2865\n",
      "Epoch 78, Average Loss: 0.2905\n",
      "Epoch 79, Average Loss: 0.2901\n",
      "Epoch 80, Average Loss: 0.2837\n",
      "Epoch 81, Average Loss: 0.2796\n",
      "Epoch 82, Average Loss: 0.2855\n",
      "Epoch 83, Average Loss: 0.2900\n",
      "Epoch 84, Average Loss: 0.2844\n",
      "Epoch 85, Average Loss: 0.2779\n",
      "Epoch 86, Average Loss: 0.2788\n",
      "Epoch 87, Average Loss: 0.2737\n",
      "Epoch 88, Average Loss: 0.2789\n",
      "Epoch 89, Average Loss: 0.2779\n",
      "Epoch 90, Average Loss: 0.2844\n",
      "Epoch 91, Average Loss: 0.2807\n",
      "Epoch 92, Average Loss: 0.2838\n",
      "Epoch 93, Average Loss: 0.2863\n",
      "Epoch 94, Average Loss: 0.2806\n",
      "Epoch 95, Average Loss: 0.2728\n",
      "Epoch 96, Average Loss: 0.2616\n",
      "Epoch 97, Average Loss: 0.2738\n",
      "Epoch 98, Average Loss: 0.2829\n",
      "Epoch 99, Average Loss: 0.2728\n",
      "Epoch 100, Average Loss: 0.2764\n",
      "Epoch 101, Average Loss: 0.2643\n",
      "Epoch 102, Average Loss: 0.2701\n",
      "Epoch 103, Average Loss: 0.2628\n",
      "Epoch 104, Average Loss: 0.2675\n",
      "Epoch 105, Average Loss: 0.2871\n",
      "Epoch 106, Average Loss: 0.2655\n",
      "Early stopping at epoch 106\n",
      "Fold 1 Metrics: Accuracy: 0.8550, Precision: 0.8737, Recall: 0.8550, F1 Score: 0.8606\n",
      "\n",
      " Fold 2\n",
      "Epoch 1, Average Loss: 0.6553\n",
      "Epoch 2, Average Loss: 0.4833\n",
      "Epoch 3, Average Loss: 0.4537\n",
      "Epoch 4, Average Loss: 0.4547\n",
      "Epoch 5, Average Loss: 0.4298\n",
      "Epoch 6, Average Loss: 0.4231\n",
      "Epoch 7, Average Loss: 0.4236\n",
      "Epoch 8, Average Loss: 0.4151\n",
      "Epoch 9, Average Loss: 0.4165\n",
      "Epoch 10, Average Loss: 0.4111\n",
      "Epoch 11, Average Loss: 0.4060\n",
      "Epoch 12, Average Loss: 0.3982\n",
      "Epoch 13, Average Loss: 0.3971\n",
      "Epoch 14, Average Loss: 0.3917\n",
      "Epoch 15, Average Loss: 0.3877\n",
      "Epoch 16, Average Loss: 0.3978\n",
      "Epoch 17, Average Loss: 0.3783\n",
      "Epoch 18, Average Loss: 0.3819\n",
      "Epoch 19, Average Loss: 0.3789\n",
      "Epoch 20, Average Loss: 0.3844\n",
      "Epoch 21, Average Loss: 0.3736\n",
      "Epoch 22, Average Loss: 0.3731\n",
      "Epoch 23, Average Loss: 0.3715\n",
      "Epoch 24, Average Loss: 0.3623\n",
      "Epoch 25, Average Loss: 0.3583\n",
      "Epoch 26, Average Loss: 0.3612\n",
      "Epoch 27, Average Loss: 0.3604\n",
      "Epoch 28, Average Loss: 0.3665\n",
      "Epoch 29, Average Loss: 0.3550\n",
      "Epoch 30, Average Loss: 0.3518\n",
      "Epoch 31, Average Loss: 0.3503\n",
      "Epoch 32, Average Loss: 0.3409\n",
      "Epoch 33, Average Loss: 0.3482\n",
      "Epoch 34, Average Loss: 0.3564\n",
      "Epoch 35, Average Loss: 0.3599\n",
      "Epoch 36, Average Loss: 0.3451\n",
      "Epoch 37, Average Loss: 0.3387\n",
      "Epoch 38, Average Loss: 0.3420\n",
      "Epoch 39, Average Loss: 0.3422\n",
      "Epoch 40, Average Loss: 0.3353\n",
      "Epoch 41, Average Loss: 0.3323\n",
      "Epoch 42, Average Loss: 0.3272\n",
      "Epoch 43, Average Loss: 0.3293\n",
      "Epoch 44, Average Loss: 0.3288\n",
      "Epoch 45, Average Loss: 0.3297\n",
      "Epoch 46, Average Loss: 0.3232\n",
      "Epoch 47, Average Loss: 0.3323\n",
      "Epoch 48, Average Loss: 0.3201\n",
      "Epoch 49, Average Loss: 0.3144\n",
      "Epoch 50, Average Loss: 0.3263\n",
      "Epoch 51, Average Loss: 0.3153\n",
      "Epoch 52, Average Loss: 0.3161\n",
      "Epoch 53, Average Loss: 0.3238\n",
      "Epoch 54, Average Loss: 0.3104\n",
      "Epoch 55, Average Loss: 0.3049\n",
      "Epoch 56, Average Loss: 0.3120\n",
      "Epoch 57, Average Loss: 0.3075\n",
      "Epoch 58, Average Loss: 0.3146\n",
      "Epoch 59, Average Loss: 0.3082\n",
      "Epoch 60, Average Loss: 0.3028\n",
      "Epoch 61, Average Loss: 0.3131\n",
      "Epoch 62, Average Loss: 0.3108\n",
      "Epoch 63, Average Loss: 0.3118\n",
      "Epoch 64, Average Loss: 0.3037\n",
      "Epoch 65, Average Loss: 0.3044\n",
      "Epoch 66, Average Loss: 0.3081\n",
      "Epoch 67, Average Loss: 0.2975\n",
      "Epoch 68, Average Loss: 0.2982\n",
      "Epoch 69, Average Loss: 0.2975\n",
      "Epoch 70, Average Loss: 0.2983\n",
      "Epoch 71, Average Loss: 0.3012\n",
      "Epoch 72, Average Loss: 0.2937\n",
      "Epoch 73, Average Loss: 0.2930\n",
      "Epoch 74, Average Loss: 0.2907\n",
      "Epoch 75, Average Loss: 0.2939\n",
      "Epoch 76, Average Loss: 0.2919\n",
      "Epoch 77, Average Loss: 0.2891\n",
      "Epoch 78, Average Loss: 0.2927\n",
      "Epoch 79, Average Loss: 0.2872\n",
      "Epoch 80, Average Loss: 0.3139\n",
      "Epoch 81, Average Loss: 0.2949\n",
      "Epoch 82, Average Loss: 0.2886\n",
      "Epoch 83, Average Loss: 0.2841\n",
      "Epoch 84, Average Loss: 0.2825\n",
      "Epoch 85, Average Loss: 0.2827\n",
      "Epoch 86, Average Loss: 0.2901\n",
      "Epoch 87, Average Loss: 0.2884\n",
      "Epoch 88, Average Loss: 0.2816\n",
      "Epoch 89, Average Loss: 0.2815\n",
      "Epoch 90, Average Loss: 0.3020\n",
      "Epoch 91, Average Loss: 0.2843\n",
      "Epoch 92, Average Loss: 0.2847\n",
      "Epoch 93, Average Loss: 0.2894\n",
      "Epoch 94, Average Loss: 0.2771\n",
      "Epoch 95, Average Loss: 0.2789\n",
      "Epoch 96, Average Loss: 0.2819\n",
      "Epoch 97, Average Loss: 0.2784\n",
      "Epoch 98, Average Loss: 0.2777\n",
      "Epoch 99, Average Loss: 0.2909\n",
      "Epoch 100, Average Loss: 0.2909\n",
      "Epoch 101, Average Loss: 0.2843\n",
      "Epoch 102, Average Loss: 0.2807\n",
      "Epoch 103, Average Loss: 0.2826\n",
      "Epoch 104, Average Loss: 0.2695\n",
      "Epoch 105, Average Loss: 0.2809\n",
      "Epoch 106, Average Loss: 0.2732\n",
      "Epoch 107, Average Loss: 0.2695\n",
      "Epoch 108, Average Loss: 0.2741\n",
      "Epoch 109, Average Loss: 0.2760\n",
      "Epoch 110, Average Loss: 0.2691\n",
      "Epoch 111, Average Loss: 0.2726\n",
      "Epoch 112, Average Loss: 0.2700\n",
      "Epoch 113, Average Loss: 0.2775\n",
      "Epoch 114, Average Loss: 0.2734\n",
      "Epoch 115, Average Loss: 0.2717\n",
      "Epoch 116, Average Loss: 0.2715\n",
      "Epoch 117, Average Loss: 0.2721\n",
      "Epoch 118, Average Loss: 0.2810\n",
      "Epoch 119, Average Loss: 0.2647\n",
      "Epoch 120, Average Loss: 0.2614\n",
      "Epoch 121, Average Loss: 0.2656\n",
      "Epoch 122, Average Loss: 0.2820\n",
      "Epoch 123, Average Loss: 0.2729\n",
      "Epoch 124, Average Loss: 0.2710\n",
      "Epoch 125, Average Loss: 0.2701\n",
      "Epoch 126, Average Loss: 0.2675\n",
      "Epoch 127, Average Loss: 0.2639\n",
      "Epoch 128, Average Loss: 0.2546\n",
      "Epoch 129, Average Loss: 0.2619\n",
      "Epoch 130, Average Loss: 0.2625\n",
      "Epoch 131, Average Loss: 0.2494\n",
      "Epoch 132, Average Loss: 0.2627\n",
      "Epoch 133, Average Loss: 0.2734\n",
      "Epoch 134, Average Loss: 0.2707\n",
      "Epoch 135, Average Loss: 0.2630\n",
      "Epoch 136, Average Loss: 0.2527\n",
      "Epoch 137, Average Loss: 0.2630\n",
      "Epoch 138, Average Loss: 0.2641\n",
      "Epoch 139, Average Loss: 0.2708\n",
      "Epoch 140, Average Loss: 0.2623\n",
      "Epoch 141, Average Loss: 0.2559\n",
      "Early stopping at epoch 141\n",
      "Fold 2 Metrics: Accuracy: 0.8665, Precision: 0.8767, Recall: 0.8665, F1 Score: 0.8697\n",
      "\n",
      " Fold 3\n",
      "Epoch 1, Average Loss: 0.6851\n",
      "Epoch 2, Average Loss: 0.4824\n",
      "Epoch 3, Average Loss: 0.4474\n",
      "Epoch 4, Average Loss: 0.4447\n",
      "Epoch 5, Average Loss: 0.4292\n",
      "Epoch 6, Average Loss: 0.4218\n",
      "Epoch 7, Average Loss: 0.4137\n",
      "Epoch 8, Average Loss: 0.4157\n",
      "Epoch 9, Average Loss: 0.4125\n",
      "Epoch 10, Average Loss: 0.4106\n",
      "Epoch 11, Average Loss: 0.3972\n",
      "Epoch 12, Average Loss: 0.4014\n",
      "Epoch 13, Average Loss: 0.4012\n",
      "Epoch 14, Average Loss: 0.3920\n",
      "Epoch 15, Average Loss: 0.3995\n",
      "Epoch 16, Average Loss: 0.3872\n",
      "Epoch 17, Average Loss: 0.3896\n",
      "Epoch 18, Average Loss: 0.3892\n",
      "Epoch 19, Average Loss: 0.3830\n",
      "Epoch 20, Average Loss: 0.3718\n",
      "Epoch 21, Average Loss: 0.3744\n",
      "Epoch 22, Average Loss: 0.3804\n",
      "Epoch 23, Average Loss: 0.3740\n",
      "Epoch 24, Average Loss: 0.3769\n",
      "Epoch 25, Average Loss: 0.3672\n",
      "Epoch 26, Average Loss: 0.3669\n",
      "Epoch 27, Average Loss: 0.3605\n",
      "Epoch 28, Average Loss: 0.3562\n",
      "Epoch 29, Average Loss: 0.3553\n",
      "Epoch 30, Average Loss: 0.3576\n",
      "Epoch 31, Average Loss: 0.3549\n",
      "Epoch 32, Average Loss: 0.3502\n",
      "Epoch 33, Average Loss: 0.3380\n",
      "Epoch 34, Average Loss: 0.3429\n",
      "Epoch 35, Average Loss: 0.3542\n",
      "Epoch 36, Average Loss: 0.3604\n",
      "Epoch 37, Average Loss: 0.3360\n",
      "Epoch 38, Average Loss: 0.3439\n",
      "Epoch 39, Average Loss: 0.3425\n",
      "Epoch 40, Average Loss: 0.3427\n",
      "Epoch 41, Average Loss: 0.3378\n",
      "Epoch 42, Average Loss: 0.3322\n",
      "Epoch 43, Average Loss: 0.3393\n",
      "Epoch 44, Average Loss: 0.3297\n",
      "Epoch 45, Average Loss: 0.3267\n",
      "Epoch 46, Average Loss: 0.3370\n",
      "Epoch 47, Average Loss: 0.3302\n",
      "Epoch 48, Average Loss: 0.3293\n",
      "Epoch 49, Average Loss: 0.3207\n",
      "Epoch 50, Average Loss: 0.3224\n",
      "Epoch 51, Average Loss: 0.3195\n",
      "Epoch 52, Average Loss: 0.3172\n",
      "Epoch 53, Average Loss: 0.3283\n",
      "Epoch 54, Average Loss: 0.3226\n",
      "Epoch 55, Average Loss: 0.3213\n",
      "Epoch 56, Average Loss: 0.3090\n",
      "Epoch 57, Average Loss: 0.3138\n",
      "Epoch 58, Average Loss: 0.3048\n",
      "Epoch 59, Average Loss: 0.3096\n",
      "Epoch 60, Average Loss: 0.3166\n",
      "Epoch 61, Average Loss: 0.3163\n",
      "Epoch 62, Average Loss: 0.3060\n",
      "Epoch 63, Average Loss: 0.3078\n",
      "Epoch 64, Average Loss: 0.3111\n",
      "Epoch 65, Average Loss: 0.2958\n",
      "Epoch 66, Average Loss: 0.3043\n",
      "Epoch 67, Average Loss: 0.2920\n",
      "Epoch 68, Average Loss: 0.3032\n",
      "Epoch 69, Average Loss: 0.3000\n",
      "Epoch 70, Average Loss: 0.2956\n",
      "Epoch 71, Average Loss: 0.3008\n",
      "Epoch 72, Average Loss: 0.2921\n",
      "Epoch 73, Average Loss: 0.2976\n",
      "Epoch 74, Average Loss: 0.2917\n",
      "Epoch 75, Average Loss: 0.2946\n",
      "Epoch 76, Average Loss: 0.2855\n",
      "Epoch 77, Average Loss: 0.2925\n",
      "Epoch 78, Average Loss: 0.2915\n",
      "Epoch 79, Average Loss: 0.2940\n",
      "Epoch 80, Average Loss: 0.2956\n",
      "Epoch 81, Average Loss: 0.2926\n",
      "Epoch 82, Average Loss: 0.2683\n",
      "Epoch 83, Average Loss: 0.2949\n",
      "Epoch 84, Average Loss: 0.2903\n",
      "Epoch 85, Average Loss: 0.2827\n",
      "Epoch 86, Average Loss: 0.2823\n",
      "Epoch 87, Average Loss: 0.2962\n",
      "Epoch 88, Average Loss: 0.2974\n",
      "Epoch 89, Average Loss: 0.2801\n",
      "Epoch 90, Average Loss: 0.2776\n",
      "Epoch 91, Average Loss: 0.2745\n",
      "Epoch 92, Average Loss: 0.2896\n",
      "Early stopping at epoch 92\n",
      "Fold 3 Metrics: Accuracy: 0.8681, Precision: 0.8736, Recall: 0.8681, F1 Score: 0.8696\n",
      "\n",
      " Fold 4\n",
      "Epoch 1, Average Loss: 0.6738\n",
      "Epoch 2, Average Loss: 0.4711\n",
      "Epoch 3, Average Loss: 0.4598\n",
      "Epoch 4, Average Loss: 0.4416\n",
      "Epoch 5, Average Loss: 0.4396\n",
      "Epoch 6, Average Loss: 0.4277\n",
      "Epoch 7, Average Loss: 0.4184\n",
      "Epoch 8, Average Loss: 0.4183\n",
      "Epoch 9, Average Loss: 0.4171\n",
      "Epoch 10, Average Loss: 0.4096\n",
      "Epoch 11, Average Loss: 0.4013\n",
      "Epoch 12, Average Loss: 0.4002\n",
      "Epoch 13, Average Loss: 0.3979\n",
      "Epoch 14, Average Loss: 0.3902\n",
      "Epoch 15, Average Loss: 0.3952\n",
      "Epoch 16, Average Loss: 0.3966\n",
      "Epoch 17, Average Loss: 0.3944\n",
      "Epoch 18, Average Loss: 0.3844\n",
      "Epoch 19, Average Loss: 0.3801\n",
      "Epoch 20, Average Loss: 0.3800\n",
      "Epoch 21, Average Loss: 0.3809\n",
      "Epoch 22, Average Loss: 0.3652\n",
      "Epoch 23, Average Loss: 0.3692\n",
      "Epoch 24, Average Loss: 0.3706\n",
      "Epoch 25, Average Loss: 0.3712\n",
      "Epoch 26, Average Loss: 0.3634\n",
      "Epoch 27, Average Loss: 0.3625\n",
      "Epoch 28, Average Loss: 0.3538\n",
      "Epoch 29, Average Loss: 0.3554\n",
      "Epoch 30, Average Loss: 0.3550\n",
      "Epoch 31, Average Loss: 0.3533\n",
      "Epoch 32, Average Loss: 0.3462\n",
      "Epoch 33, Average Loss: 0.3483\n",
      "Epoch 34, Average Loss: 0.3423\n",
      "Epoch 35, Average Loss: 0.3523\n",
      "Epoch 36, Average Loss: 0.3466\n",
      "Epoch 37, Average Loss: 0.3342\n",
      "Epoch 38, Average Loss: 0.3306\n",
      "Epoch 39, Average Loss: 0.3388\n",
      "Epoch 40, Average Loss: 0.3319\n",
      "Epoch 41, Average Loss: 0.3499\n",
      "Epoch 42, Average Loss: 0.3328\n",
      "Epoch 43, Average Loss: 0.3249\n",
      "Epoch 44, Average Loss: 0.3367\n",
      "Epoch 45, Average Loss: 0.3295\n",
      "Epoch 46, Average Loss: 0.3215\n",
      "Epoch 47, Average Loss: 0.3240\n",
      "Epoch 48, Average Loss: 0.3289\n",
      "Epoch 49, Average Loss: 0.3231\n",
      "Epoch 50, Average Loss: 0.3126\n",
      "Epoch 51, Average Loss: 0.3148\n",
      "Epoch 52, Average Loss: 0.3224\n",
      "Epoch 53, Average Loss: 0.3129\n",
      "Epoch 54, Average Loss: 0.3102\n",
      "Epoch 55, Average Loss: 0.3201\n",
      "Epoch 56, Average Loss: 0.3077\n",
      "Epoch 57, Average Loss: 0.3174\n",
      "Epoch 58, Average Loss: 0.3143\n",
      "Epoch 59, Average Loss: 0.3051\n",
      "Epoch 60, Average Loss: 0.2997\n",
      "Epoch 61, Average Loss: 0.2978\n",
      "Epoch 62, Average Loss: 0.3109\n",
      "Epoch 63, Average Loss: 0.2998\n",
      "Epoch 64, Average Loss: 0.3004\n",
      "Epoch 65, Average Loss: 0.3044\n",
      "Epoch 66, Average Loss: 0.3141\n",
      "Epoch 67, Average Loss: 0.3033\n",
      "Epoch 68, Average Loss: 0.3059\n",
      "Epoch 69, Average Loss: 0.2939\n",
      "Epoch 70, Average Loss: 0.2934\n",
      "Epoch 71, Average Loss: 0.2860\n",
      "Epoch 72, Average Loss: 0.3129\n",
      "Epoch 73, Average Loss: 0.2946\n",
      "Epoch 74, Average Loss: 0.2856\n",
      "Epoch 75, Average Loss: 0.2951\n",
      "Epoch 76, Average Loss: 0.2805\n",
      "Epoch 77, Average Loss: 0.2940\n",
      "Epoch 78, Average Loss: 0.2780\n",
      "Epoch 79, Average Loss: 0.2921\n",
      "Epoch 80, Average Loss: 0.2872\n",
      "Epoch 81, Average Loss: 0.2919\n",
      "Epoch 82, Average Loss: 0.2917\n",
      "Epoch 83, Average Loss: 0.2887\n",
      "Epoch 84, Average Loss: 0.2861\n",
      "Epoch 85, Average Loss: 0.2879\n",
      "Epoch 86, Average Loss: 0.2796\n",
      "Epoch 87, Average Loss: 0.2870\n",
      "Epoch 88, Average Loss: 0.2754\n",
      "Epoch 89, Average Loss: 0.2921\n",
      "Epoch 90, Average Loss: 0.2832\n",
      "Epoch 91, Average Loss: 0.2828\n",
      "Epoch 92, Average Loss: 0.2773\n",
      "Epoch 93, Average Loss: 0.2740\n",
      "Epoch 94, Average Loss: 0.2815\n",
      "Epoch 95, Average Loss: 0.2886\n",
      "Epoch 96, Average Loss: 0.2932\n",
      "Epoch 97, Average Loss: 0.2734\n",
      "Epoch 98, Average Loss: 0.2590\n",
      "Epoch 99, Average Loss: 0.2797\n",
      "Epoch 100, Average Loss: 0.2721\n",
      "Epoch 101, Average Loss: 0.2751\n",
      "Epoch 102, Average Loss: 0.2649\n",
      "Epoch 103, Average Loss: 0.2777\n",
      "Epoch 104, Average Loss: 0.2804\n",
      "Epoch 105, Average Loss: 0.2847\n",
      "Epoch 106, Average Loss: 0.2802\n",
      "Epoch 107, Average Loss: 0.2698\n",
      "Epoch 108, Average Loss: 0.2648\n",
      "Early stopping at epoch 108\n",
      "Fold 4 Metrics: Accuracy: 0.8633, Precision: 0.8701, Recall: 0.8633, F1 Score: 0.8653\n",
      "\n",
      " Fold 5\n",
      "Epoch 1, Average Loss: 0.6772\n",
      "Epoch 2, Average Loss: 0.4802\n",
      "Epoch 3, Average Loss: 0.4724\n",
      "Epoch 4, Average Loss: 0.4495\n",
      "Epoch 5, Average Loss: 0.4474\n",
      "Epoch 6, Average Loss: 0.4279\n",
      "Epoch 7, Average Loss: 0.4234\n",
      "Epoch 8, Average Loss: 0.4248\n",
      "Epoch 9, Average Loss: 0.4157\n",
      "Epoch 10, Average Loss: 0.4105\n",
      "Epoch 11, Average Loss: 0.4179\n",
      "Epoch 12, Average Loss: 0.4031\n",
      "Epoch 13, Average Loss: 0.4042\n",
      "Epoch 14, Average Loss: 0.4023\n",
      "Epoch 15, Average Loss: 0.4007\n",
      "Epoch 16, Average Loss: 0.4065\n",
      "Epoch 17, Average Loss: 0.3914\n",
      "Epoch 18, Average Loss: 0.3935\n",
      "Epoch 19, Average Loss: 0.3843\n",
      "Epoch 20, Average Loss: 0.3769\n",
      "Epoch 21, Average Loss: 0.3848\n",
      "Epoch 22, Average Loss: 0.3863\n",
      "Epoch 23, Average Loss: 0.3772\n",
      "Epoch 24, Average Loss: 0.3754\n",
      "Epoch 25, Average Loss: 0.3741\n",
      "Epoch 26, Average Loss: 0.3726\n",
      "Epoch 27, Average Loss: 0.3679\n",
      "Epoch 28, Average Loss: 0.3599\n",
      "Epoch 29, Average Loss: 0.3606\n",
      "Epoch 30, Average Loss: 0.3648\n",
      "Epoch 31, Average Loss: 0.3552\n",
      "Epoch 32, Average Loss: 0.3470\n",
      "Epoch 33, Average Loss: 0.3463\n",
      "Epoch 34, Average Loss: 0.3520\n",
      "Epoch 35, Average Loss: 0.3591\n",
      "Epoch 36, Average Loss: 0.3453\n",
      "Epoch 37, Average Loss: 0.3361\n",
      "Epoch 38, Average Loss: 0.3431\n",
      "Epoch 39, Average Loss: 0.3536\n",
      "Epoch 40, Average Loss: 0.3285\n",
      "Epoch 41, Average Loss: 0.3462\n",
      "Epoch 42, Average Loss: 0.3337\n",
      "Epoch 43, Average Loss: 0.3386\n",
      "Epoch 44, Average Loss: 0.3309\n",
      "Epoch 45, Average Loss: 0.3344\n",
      "Epoch 46, Average Loss: 0.3302\n",
      "Epoch 47, Average Loss: 0.3291\n",
      "Epoch 48, Average Loss: 0.3230\n",
      "Epoch 49, Average Loss: 0.3183\n",
      "Epoch 50, Average Loss: 0.3233\n",
      "Epoch 51, Average Loss: 0.3214\n",
      "Epoch 52, Average Loss: 0.3222\n",
      "Epoch 53, Average Loss: 0.3248\n",
      "Epoch 54, Average Loss: 0.3066\n",
      "Epoch 55, Average Loss: 0.3196\n",
      "Epoch 56, Average Loss: 0.3235\n",
      "Epoch 57, Average Loss: 0.3078\n",
      "Epoch 58, Average Loss: 0.3129\n",
      "Epoch 59, Average Loss: 0.3230\n",
      "Epoch 60, Average Loss: 0.3067\n",
      "Epoch 61, Average Loss: 0.3108\n",
      "Epoch 62, Average Loss: 0.3057\n",
      "Epoch 63, Average Loss: 0.3159\n",
      "Epoch 64, Average Loss: 0.3118\n",
      "Epoch 65, Average Loss: 0.3013\n",
      "Epoch 66, Average Loss: 0.3040\n",
      "Epoch 67, Average Loss: 0.2961\n",
      "Epoch 68, Average Loss: 0.3090\n",
      "Epoch 69, Average Loss: 0.2957\n",
      "Epoch 70, Average Loss: 0.2991\n",
      "Epoch 71, Average Loss: 0.3006\n",
      "Epoch 72, Average Loss: 0.3089\n",
      "Epoch 73, Average Loss: 0.2939\n",
      "Epoch 74, Average Loss: 0.3016\n",
      "Epoch 75, Average Loss: 0.2954\n",
      "Epoch 76, Average Loss: 0.2943\n",
      "Epoch 77, Average Loss: 0.2947\n",
      "Epoch 78, Average Loss: 0.3087\n",
      "Epoch 79, Average Loss: 0.2908\n",
      "Epoch 80, Average Loss: 0.2972\n",
      "Epoch 81, Average Loss: 0.2960\n",
      "Epoch 82, Average Loss: 0.2809\n",
      "Epoch 83, Average Loss: 0.2998\n",
      "Epoch 84, Average Loss: 0.2834\n",
      "Epoch 85, Average Loss: 0.2863\n",
      "Epoch 86, Average Loss: 0.2933\n",
      "Epoch 87, Average Loss: 0.2844\n",
      "Epoch 88, Average Loss: 0.2975\n",
      "Epoch 89, Average Loss: 0.2950\n",
      "Epoch 90, Average Loss: 0.2907\n",
      "Epoch 91, Average Loss: 0.2790\n",
      "Epoch 92, Average Loss: 0.2828\n",
      "Epoch 93, Average Loss: 0.2855\n",
      "Epoch 94, Average Loss: 0.2976\n",
      "Epoch 95, Average Loss: 0.2907\n",
      "Epoch 96, Average Loss: 0.2786\n",
      "Epoch 97, Average Loss: 0.2792\n",
      "Epoch 98, Average Loss: 0.2731\n",
      "Epoch 99, Average Loss: 0.2726\n",
      "Epoch 100, Average Loss: 0.2741\n",
      "Epoch 101, Average Loss: 0.2831\n",
      "Epoch 102, Average Loss: 0.2791\n",
      "Epoch 103, Average Loss: 0.2884\n",
      "Epoch 104, Average Loss: 0.2787\n",
      "Epoch 105, Average Loss: 0.2739\n",
      "Epoch 106, Average Loss: 0.2805\n",
      "Epoch 107, Average Loss: 0.2738\n",
      "Epoch 108, Average Loss: 0.2785\n",
      "Epoch 109, Average Loss: 0.2733\n",
      "Early stopping at epoch 109\n",
      "Fold 5 Metrics: Accuracy: 0.8654, Precision: 0.8679, Recall: 0.8654, F1 Score: 0.8656\n",
      "Best model saved\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "input_dim = X_meta.shape[1]  # 2 * num_classes\n",
    "hidden_dim = 128\n",
    "output_dim = len(set(y_meta))  # number of emotion classes\n",
    "\n",
    "class_weights_path = '../../data/class_weights.pt'\n",
    "class_weights = torch.load(class_weights_path, weights_only=True).to(device)\n",
    "\n",
    "dataset = MetaDataset(X_meta, y_meta)\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize the best F1 score tracker\n",
    "best_f1 = 0.0\n",
    "best_model = None\n",
    "\n",
    "# Early stopping counters\n",
    "patience = 10\n",
    "patience_counter = 0\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(dataset.X, dataset.y)):\n",
    "    print(f\"\\n Fold {fold + 1}\")\n",
    "    \n",
    "    train_subset = torch.utils.data.Subset(dataset, train_idx)\n",
    "    val_subset = torch.utils.data.Subset(dataset, val_idx)\n",
    "    \n",
    "    train_loader = DataLoader(train_subset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_subset, batch_size=32)\n",
    "    \n",
    "    model = MetaFFNN(input_dim, hidden_dim, output_dim).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights) # Use weighted cross-entropy loss\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    best_loss = float('inf')  # Initialize best loss to a very high value\n",
    "\n",
    "    for epoch in range(1000):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        num_batches = len(train_loader)\n",
    "\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(xb)\n",
    "            loss = criterion(out, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        average_loss = total_loss / num_batches  # Calculate average loss\n",
    "        print(f\"Epoch {epoch+1}, Average Loss: {average_loss:.4f}\")\n",
    "\n",
    "        # Check if the loss has improved\n",
    "        if average_loss < best_loss:\n",
    "            best_loss = average_loss\n",
    "            patience_counter = 0  # Reset the counter since loss improved\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        # If patience is reached, stop training early\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "            break\n",
    "\n",
    "    # Evaluate\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            out = model(xb)\n",
    "            preds = torch.argmax(out, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(yb.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    # Print out the metrics for the current fold\n",
    "    print(f\"Fold {fold + 1} Metrics: Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
    "    \n",
    "    # Save the model if it has the best F1 score\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_model = model.state_dict()  # Save the state dict of the model\n",
    "\n",
    "# After all folds are done, save the best model\n",
    "torch.save(best_model, '../meta_learner/best_meta_ffnn_model.pt')\n",
    "print(\"Best model saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
