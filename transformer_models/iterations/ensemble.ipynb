{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from torch.nn.functional import softmax\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import set_seed, Wav2Vec2Processor, Wav2Vec2ForSequenceClassification, Wav2Vec2FeatureExtractor, WavLMForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_path = os.getcwd()\n",
    "project_root = os.path.abspath(os.path.join(notebook_path, '../..'))\n",
    "sys.path.insert(0, project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "seed = 42\n",
    "set_seed(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = pd.read_csv('../../data/val_dataset.csv')\n",
    "df_val = df_val[['Filepath', 'Emotion']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to integers\n",
    "unique_labels = sorted(df_val['Emotion'].unique())\n",
    "label_map = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "print(label_map)\n",
    "\n",
    "df_val['Emotion'] = df_val['Emotion'].map(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model 1: facebook/wav2vec2-base\n",
    "model1_checkpoint_path = '../models/wav2vec2-base_standardpad/checkpoint-16584' # change to wav2vec2 best model\n",
    "processor1 = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base\")\n",
    "model1 = Wav2Vec2ForSequenceClassification.from_pretrained(\n",
    "    model1_checkpoint_path, num_labels=len(label_map))\n",
    "\n",
    "# Load Model 2: microsoft/wavlm-base\n",
    "model2_checkpoint_path = '../models/wavlm-base_standardpad/checkpoint-13820' # change to wavlm best model\n",
    "processor2 = Wav2Vec2FeatureExtractor.from_pretrained(\"microsoft/wavlm-base\")\n",
    "model2 = WavLMForSequenceClassification.from_pretrained(\n",
    "    model2_checkpoint_path, num_labels=len(label_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_models.emotion_datasets.SpeechEmotionDatasetStandardPad import SpeechEmotionDatasetStandardPad\n",
    "\n",
    "# Create two validation datasets, one for each model\n",
    "val_dataset1 = SpeechEmotionDatasetStandardPad(df_val, processor1)\n",
    "val_dataset2 = SpeechEmotionDatasetStandardPad(df_val, processor2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset2[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get predictions from each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to obtain model probabilities\n",
    "def get_model_probs(model, dataset, batch_size=128):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            # The dataset returns a dict with 'input_values'\n",
    "            input_values = batch[\"input_values\"].to(device)\n",
    "            outputs = model(input_values).logits  # shape: (B, num_labels)\n",
    "            probs = softmax(outputs, dim=1).cpu().numpy()\n",
    "            all_probs.append(probs)\n",
    "    return np.vstack(all_probs)  # shape: (N, num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get probabilities for each model from their respective datasets\n",
    "probs1 = get_model_probs(model1, val_dataset1, batch_size=128)\n",
    "probs2 = get_model_probs(model2, val_dataset2, batch_size=128)\n",
    "\n",
    "# Stack predictions horizontally\n",
    "X_meta = np.hstack([probs1, probs2])  # shape: (N, num_labels * 2)\n",
    "\n",
    "# Extract ground truth labels from one of the datasets (they should be the same)\n",
    "y_meta = np.array([sample['labels'].item() for sample in val_dataset1])\n",
    "\n",
    "print(\"Shape of X_meta (stacked predictions):\", X_meta.shape)\n",
    "print(\"Shape of y_meta (labels):\", y_meta.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define simple Feed-Forward Neural Network for meta classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MetaFFNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(MetaFFNN, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            # First hidden layer\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            # Second hidden layer\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            # Third hidden layer\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            # Output layer\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define meta dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MetaDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train meta classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "input_dim = X_meta.shape[1]  # 2 * num_classes\n",
    "hidden_dim = 128\n",
    "output_dim = len(set(y_meta))  # number of emotion classes\n",
    "\n",
    "class_weights_path = '../../data/class_weights.pt'\n",
    "class_weights = torch.load(class_weights_path).to(device)\n",
    "\n",
    "dataset = MetaDataset(X_meta, y_meta)\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize the best F1 score tracker\n",
    "best_f1 = 0.0\n",
    "best_model = None\n",
    "\n",
    "# Early stopping counters\n",
    "patience = 10\n",
    "patience_counter = 0\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(dataset)):\n",
    "    print(f\"\\n Fold {fold + 1}\")\n",
    "    \n",
    "    train_subset = torch.utils.data.Subset(dataset, train_idx)\n",
    "    val_subset = torch.utils.data.Subset(dataset, val_idx)\n",
    "    \n",
    "    train_loader = DataLoader(train_subset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_subset, batch_size=32)\n",
    "    \n",
    "    model = MetaFFNN(input_dim, hidden_dim, output_dim).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights) # Use weighted cross-entropy loss\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    best_loss = float('inf')  # Initialize best loss to a very high value\n",
    "\n",
    "    for epoch in range(1000):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(xb)\n",
    "            loss = criterion(out, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "        # Check if the loss has improved\n",
    "        if total_loss < best_loss:\n",
    "            best_loss = total_loss\n",
    "            patience_counter = 0  # Reset the counter since loss improved\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        # If patience is reached, stop training early\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "            break\n",
    "\n",
    "    # Evaluate\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            out = model(xb)\n",
    "            preds = torch.argmax(out, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(yb.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    # Print out the metrics for the current fold\n",
    "    print(f\"Fold {fold + 1} Metrics: Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
    "    \n",
    "    # Save the model if it has the best F1 score\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_model = model.state_dict()  # Save the state dict of the model\n",
    "\n",
    "# After all folds are done, save the best model\n",
    "torch.save(best_model, 'best_meta_ffnn_model.pt')\n",
    "print(\"Best model saved\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
