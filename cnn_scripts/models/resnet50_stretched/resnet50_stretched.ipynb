{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune ResNet50\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 1000 x 400 time-stretched melspectrogram images without data augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the absolute path to the project root without relying on __file__\n",
    "notebook_path = os.getcwd()  # Gets current working directory\n",
    "project_root = os.path.abspath(os.path.join(notebook_path, \"../..\"))\n",
    "sys.path.insert(0, project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the seed for reproducability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "if (torch.cuda.is_available()):\n",
    "    torch.cuda.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set some constant strings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINETUNED_MODEL = 'resnet50_stretched'\n",
    "\n",
    "train_csv = '../../../data/melspectrogram_train_dataset.csv'\n",
    "test_csv = '../../../data/melspectrogram_test_dataset.csv'\n",
    "val_csv = '../../../data/melspectrogram_val_dataset.csv'\n",
    "root_dir = '../../../data/'\n",
    "class_weights_path = '../../../data/class_weights.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom dataset class for loading the mel spectrogram images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.MelspectrogramDataset import MelSpectrogramDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the training function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, trainloader, criterion, optimizer, device):\n",
    "    train_loss = 0.0\n",
    "    train_total = 0\n",
    "    train_correct = 0\n",
    "\n",
    "    # train mode\n",
    "    model.train()\n",
    "\n",
    "    epoch_start = time.time()\n",
    "    pbar = tqdm(enumerate(trainloader), total=len(\n",
    "        trainloader), desc=\"Training\")\n",
    "\n",
    "    for i, (inputs, labels) in pbar:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update training loss\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Calculate time metrics\n",
    "        elapsed = time.time() - epoch_start\n",
    "        progress = (i + 1) / len(trainloader)\n",
    "        eta = elapsed / progress - elapsed\n",
    "\n",
    "        # Update progress bar with current loss and ETA\n",
    "        pbar.set_postfix({\n",
    "            \"Loss\": f\"{loss.item()}\",\n",
    "            \"Elapsed\": f\"{elapsed:.4f}s\",\n",
    "            \"ETA\": f\"{eta:.4f}s\"\n",
    "        })\n",
    "\n",
    "    train_loss = train_loss / len(trainloader)\n",
    "    train_accuracy = train_correct / train_total * 100\n",
    "\n",
    "    return model, train_loss, train_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the validation function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, valloader, criterion, device):\n",
    "    val_loss = 0.0\n",
    "    val_total = 0\n",
    "    val_correct = 0\n",
    "\n",
    "    # Switch to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    epoch_start = time.time()\n",
    "    pbar = tqdm(enumerate(valloader), total=len(\n",
    "        valloader), desc=\"Validating\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in pbar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Update test loss\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Calculate time metrics\n",
    "            elapsed = time.time() - epoch_start\n",
    "            progress = (i + 1) / len(valloader)\n",
    "            eta = elapsed / progress - elapsed\n",
    "\n",
    "            # Update progress bar with current loss and ETA\n",
    "            pbar.set_postfix({\n",
    "                \"Loss\": f\"{loss.item()}\",\n",
    "                \"Elapsed\": f\"{elapsed:.4f}s\",\n",
    "                \"ETA\": f\"{eta:.4f}s\"\n",
    "            })\n",
    "\n",
    "    val_loss = val_loss / len(valloader)\n",
    "    val_accuracy = val_correct / val_total * 100\n",
    "\n",
    "    return val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define what happens in each epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epochs(model, trainloader, valloader, criterion, optimizer, device, num_epochs):\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    best_accuracy = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        epoch_start = time.time()\n",
    "\n",
    "        model, train_loss, train_accuracy = train(\n",
    "            model, trainloader, criterion, optimizer, device)\n",
    "        val_loss, val_accuracy = validate(\n",
    "            model, valloader, criterion, device)\n",
    "\n",
    "        epoch_elapsed = time.time() - epoch_start\n",
    "        print(f\"Epoch {epoch+1} completed in {epoch_elapsed:.4f}s\")\n",
    "        print(f'Train Loss: {train_loss} - Train Accuracy: {train_accuracy}')\n",
    "        print(\n",
    "            f'Validation Loss: {val_loss} - Validation Accuracy: {val_accuracy}')\n",
    "        print()\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        # Check if current model is best performing using test_accuracy\n",
    "        if val_accuracy > best_accuracy:\n",
    "            best_accuracy = val_accuracy\n",
    "            torch.save(model.state_dict(), f'best_{FINETUNED_MODEL}.pt')\n",
    "            checkpoint = {\n",
    "                'epoch': epoch + 1,\n",
    "                'train_losses': train_losses,\n",
    "                'train_accuracies': train_accuracies,\n",
    "                'val_losses': val_losses,\n",
    "                'val_accuracies': val_accuracies,\n",
    "            }\n",
    "            torch.save(checkpoint, f'best_{FINETUNED_MODEL}_checkpoint.pt')\n",
    "\n",
    "    return model, train_losses, train_accuracies, val_losses, val_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the loss and accuracy graphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(train_losses, val_losses):\n",
    "    plt.figure()\n",
    "    plt.plot(range(len(train_losses)), train_losses, label='Training Loss')\n",
    "    plt.plot(range(len(val_losses)), val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy(train_accuracies, val_accuracies):\n",
    "    plt.figure()\n",
    "    plt.plot(range(len(train_accuracies)),\n",
    "             train_accuracies, label='Training Accuracy')\n",
    "    plt.plot(range(len(val_accuracies)),\n",
    "             val_accuracies, label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare for fine-tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of classes\n",
    "num_classes = 9\n",
    "\n",
    "# Freeze all layers except the last fully connected layer\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False  # Freeze all layers\n",
    "\n",
    "# Modify final fully connected layer according to number of classes\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, num_classes)\n",
    "# print(\"Modified model\")\n",
    "# print(model)\n",
    "\n",
    "# Unfreeze the final fully connected layer so it will be trained\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Move model to GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the learning rate, criterion, optimizer, transformations, and number of epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "class_weights = torch.load(class_weights_path).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    # Resize the Mel spectrogram to 224x224, suitable for ResNet50\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),          # Convert to Tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[\n",
    "                         0.229, 0.224, 0.225])  # Normalize to ImageNet stats\n",
    "])\n",
    "\n",
    "epochs = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the fine-tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = MelSpectrogramDataset(\n",
    "    csv_file=train_csv, root_dir=root_dir, transform=transform)\n",
    "valset = MelSpectrogramDataset(\n",
    "    csv_file=val_csv, root_dir=root_dir, transform=transform)\n",
    "testset = MelSpectrogramDataset(\n",
    "    csv_file=test_csv, root_dir=root_dir, transform=transform)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=128,\n",
    "                         shuffle=True, num_workers=8, pin_memory=True)\n",
    "valloader = DataLoader(valset, batch_size=128,\n",
    "                       shuffle=False, num_workers=8, pin_memory=True)\n",
    "testloader = DataLoader(testset, batch_size=128,\n",
    "                        shuffle=False, num_workers=8, pin_memory=True)\n",
    "\n",
    "# Label mappings\n",
    "labelmap = trainset.label_map\n",
    "print(f\"Mapping from Emotion to Number: {labelmap}\")\n",
    "\n",
    "print(f\"Model is on: {next(model.parameters()).device}\")\n",
    "model, train_losses, train_accuracies, val_losses, val_accuracies = train_epochs(\n",
    "    model, trainloader, valloader, criterion, optimizer, device, epochs)\n",
    "torch.save(model.state_dict(), f'{FINETUNED_MODEL}_variables_{epochs}.pt')\n",
    "\n",
    "# Plots\n",
    "plot_loss(train_losses, val_losses)\n",
    "plot_accuracy(train_accuracies, val_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the function to plot the confusion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # Create figure and axes\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    # Create heatmap\n",
    "    sns.heatmap(cm,\n",
    "                annot=True,  # Show numbers in cells\n",
    "                fmt='d',     # Use integer formatting\n",
    "                cmap='Blues',  # Color scheme\n",
    "                xticklabels=trainset.label_map.keys(),\n",
    "                yticklabels=trainset.label_map.keys())\n",
    "\n",
    "    # Set labels and title\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.title('Confusion Matrix')\n",
    "\n",
    "    # Rotate axis labels for better readability\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=45)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the function to evaluate the best model on the test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_evaluate_best_model(model, testloader, criterion, device, model_path):\n",
    "    # Load the best model weights\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    print(\"Evaluating best model on test set...\")\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(testloader, desc='Testing'):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Store predictions for confusion matrix\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate final metrics\n",
    "    test_loss = running_loss / len(testloader)\n",
    "    test_accuracy = 100 * correct / total\n",
    "\n",
    "    print(f\"\\nTest Results (Best Model):\")\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "    return test_loss, test_accuracy, all_preds, all_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the best model on the test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and evaluate the best model\n",
    "best_model_path = f'best_{FINETUNED_MODEL}.pt'\n",
    "test_loss, test_accuracy, all_preds, all_labels = load_and_evaluate_best_model(\n",
    "    model=model,\n",
    "    testloader=testloader,\n",
    "    criterion=criterion,\n",
    "    device=device,\n",
    "    model_path=best_model_path\n",
    ")\n",
    "\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(all_labels, all_preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
