{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune ResNet50\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 1000 x 400 melspectrogram images without data augmentation\n",
    "\n",
    "Optimized pipeline with precomputed tensors (.pt) from the melspectrogram images (.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "import sys\n",
    "# Adjust the path to the parent directory of `datasets`\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set some constant strings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINETUNED_MODEL = 'resnet50'\n",
    "\n",
    "train_csv = '../../data/melspectrogram_train_dataset_tensors.csv'\n",
    "test_csv = '../../data/melspectrogram_test_dataset_tensors.csv'\n",
    "root_dir = '../../data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom dataset class for loading the precomputed tensors of the mel spectrogram images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.MelspectrogramTensorDataset import MelspectrogramTensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the training function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, trainloader, criterion, optimizer, device):\n",
    "    train_loss = 0.0\n",
    "    train_total = 0\n",
    "    train_correct = 0\n",
    "    model.train()\n",
    "\n",
    "    epoch_start = time.time()\n",
    "    # Wrap the DataLoader with tqdm so that it displays progress, elapsed time, and ETA\n",
    "    pbar = tqdm(enumerate(trainloader), total=len(\n",
    "        trainloader), desc=\"Training\")\n",
    "    for i, (inputs, labels) in pbar:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Calculate time metrics\n",
    "        elapsed = time.time() - epoch_start\n",
    "        progress = (i+1) / len(trainloader)\n",
    "        eta = elapsed / progress - elapsed\n",
    "\n",
    "        # Update progress bar with current loss and ETA\n",
    "        pbar.set_postfix({\n",
    "            \"Loss\": f\"{loss.item():.4f}\",\n",
    "            \"Elapsed\": f\"{elapsed:.1f}s\",\n",
    "            \"ETA\": f\"{eta:.1f}s\"\n",
    "        })\n",
    "\n",
    "    train_loss /= len(trainloader)\n",
    "    train_accuracy = train_correct / train_total * 100\n",
    "    return model, train_loss, train_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the testing/evaluation function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, testloader, criterion, device):\n",
    "    test_loss = 0.0\n",
    "    test_total = 0\n",
    "    test_correct = 0\n",
    "\n",
    "    # Switch to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Update test loss\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_loss = test_loss / len(testloader)\n",
    "    test_accuracy = test_correct / test_total * 100\n",
    "\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define what happens in each epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epochs(model, trainloader, testloader, criterion, optimizer, device, num_epochs):\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "    best_accuracy = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'\\nEpoch {epoch+1}/{num_epochs}')\n",
    "        epoch_start = time.time()\n",
    "\n",
    "        model, train_loss, train_accuracy = train(\n",
    "            model, trainloader, criterion, optimizer, device)\n",
    "        test_loss, test_accuracy = test(model, testloader, criterion, device)\n",
    "\n",
    "        epoch_elapsed = time.time() - epoch_start\n",
    "        print(f\"Epoch {epoch+1} completed in {epoch_elapsed:.1f} seconds\")\n",
    "        print(\n",
    "            f\"Train Loss: {train_loss:.4f} - Train Accuracy: {train_accuracy:.2f}%\")\n",
    "        print(\n",
    "            f\"Test Loss: {test_loss:.4f} - Test Accuracy: {test_accuracy:.2f}%\\n\")\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        test_losses.append(test_loss)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "\n",
    "        # Save checkpoint if best so far\n",
    "        if test_accuracy > best_accuracy:\n",
    "            best_accuracy = test_accuracy\n",
    "            torch.save(model.state_dict(), f'best_{FINETUNED_MODEL}.pt')\n",
    "            checkpoint = {\n",
    "                'epoch': epoch + 1,\n",
    "                'train_losses': train_losses,\n",
    "                'train_accuracies': train_accuracies,\n",
    "                'test_losses': test_losses,\n",
    "                'test_accuracies': test_accuracies,\n",
    "            }\n",
    "            torch.save(checkpoint, f'best_{FINETUNED_MODEL}_checkpoint.pt')\n",
    "\n",
    "    return model, train_losses, train_accuracies, test_losses, test_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the loss and accuracy graphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(train_losses, test_losses):\n",
    "    plt.figure()\n",
    "    plt.plot(range(len(train_losses)), train_losses, label='Training Loss')\n",
    "    plt.plot(range(len(test_losses)), test_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy(train_accuracies, test_accuracies):\n",
    "    plt.figure()\n",
    "    plt.plot(range(len(train_accuracies)),\n",
    "             train_accuracies, label='Training Accuracy')\n",
    "    plt.plot(range(len(test_accuracies)),\n",
    "             test_accuracies, label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define model, learning rate, optimizer, transformations, criterion and number of epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([])\n",
    "\n",
    "epochs = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View pre-trained model architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the fine-tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducability\n",
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "# Number of classes\n",
    "num_classes = 9\n",
    "\n",
    "# Freeze all layers except the last fully connected layer\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False  # Freeze all layers\n",
    "\n",
    "# Modify final fully connected layer according to number of classes\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, num_classes)\n",
    "# print(\"Modified model\")\n",
    "# print(model)\n",
    "\n",
    "# Unfreeze the final fully connected layer so it will be trained\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Move model to GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "trainset = MelspectrogramTensorDataset(\n",
    "    csv_file=train_csv, root_dir=root_dir, transform=transform)\n",
    "testset = MelspectrogramTensorDataset(\n",
    "    csv_file=test_csv, root_dir=root_dir, transform=transform)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=128,\n",
    "                         shuffle=True, num_workers=8, pin_memory=True)\n",
    "testloader = DataLoader(testset, batch_size=128,\n",
    "                        shuffle=False, num_workers=8, pin_memory=True)\n",
    "\n",
    "# Label mappings\n",
    "labelmap = trainset.label_map\n",
    "print(f\"Mapping from Emotion to Number: {labelmap}\")\n",
    "\n",
    "# Training\n",
    "print(f\"Model is on: {next(model.parameters()).device}\")\n",
    "model, train_losses, train_accuracies, test_losses, test_accuracies = train_epochs(\n",
    "    model, trainloader, testloader, criterion, optimizer, device, epochs)\n",
    "torch.save(model.state_dict(), f'{FINETUNED_MODEL}_variables_{epochs}.pt')\n",
    "\n",
    "# Plots\n",
    "plot_loss(train_losses, test_losses)\n",
    "plot_accuracy(train_accuracies, test_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "artificial-intelligence",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
