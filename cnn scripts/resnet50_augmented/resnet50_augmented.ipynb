{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune ResNet50\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 1000 x 400 melspectrogram images and data augmentation (artificial noise addition with Gaussian noise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set some constant strings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINETUNED_MODEL = 'resnet50_augmented'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu121\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom dataset class for loading mel spectrogram images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset class for loading Melspectrograms\n",
    "class MelSpectrogramDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with Melspectrogram paths and labels.\n",
    "            root_dir (string): Directory with all the Melspectrograms.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        df = pd.read_csv(csv_file)  # Read the CSV into a DataFrame\n",
    "        self.data_frame = df[['Melspectrogrampath', 'Emotion']]\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        # Sort unique labels before mapping\n",
    "        unique_labels = sorted(df['Emotion'].unique())\n",
    "        self.label_map = {label: idx for idx,\n",
    "                          label in enumerate(unique_labels)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the path to the Melspectrogram and the emotion label (string)\n",
    "        # First column is path, second column is label (emotion as string)\n",
    "        mel_path = os.path.join(self.root_dir, self.data_frame.iloc[idx, 0])\n",
    "        emotion_label_str = self.data_frame.iloc[idx, 1]\n",
    "\n",
    "        # Convert the emotion string to its corresponding integer\n",
    "        emotion_label = self.label_map[emotion_label_str]\n",
    "\n",
    "        # Load the Melspectrogram\n",
    "        mel_image = Image.open(mel_path)\n",
    "        mel_image = mel_image.convert(\"RGB\")\n",
    "\n",
    "        # Apply transformations if any\n",
    "        if self.transform:\n",
    "            mel_image = self.transform(mel_image)\n",
    "\n",
    "        # Convert emotion label to tensor\n",
    "        emotion_label = torch.tensor(emotion_label, dtype=torch.long)\n",
    "\n",
    "        return mel_image, emotion_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the training function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, trainloader, criterion, optimizer, device):\n",
    "    train_loss = 0.0\n",
    "    train_total = 0\n",
    "    train_correct = 0\n",
    "\n",
    "    # train mode\n",
    "    model.train()\n",
    "\n",
    "    for inputs, labels in trainloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update training loss\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    train_loss = train_loss / len(trainloader)\n",
    "    train_accuracy = train_correct / train_total * 100\n",
    "\n",
    "    return model, train_loss, train_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the testing/evaluation function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, testloader, criterion, device):\n",
    "    test_loss = 0.0\n",
    "    test_total = 0\n",
    "    test_correct = 0\n",
    "\n",
    "    # Switch to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Update test loss\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_loss = test_loss / len(testloader)\n",
    "    test_accuracy = test_correct / test_total * 100\n",
    "\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define what happens in each epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epochs(model, trainloader, testloader, criterion, optimizer, device, num_epochs):\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "    best_accuracy = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        model, train_loss, train_accuracy = train(\n",
    "            model, trainloader, criterion, optimizer, device)\n",
    "        test_loss, test_accuracy = test(model, testloader, criterion, device)\n",
    "        print(f'Train Loss: {train_loss} - Train Accuracy: {train_accuracy}')\n",
    "        print(f'Test Loss: {test_loss} - Test Accuracy: {test_accuracy}')\n",
    "        print()\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        test_losses.append(test_loss)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "\n",
    "        # Check if current model is best performing using test_accuracy\n",
    "        if test_accuracy > best_accuracy:\n",
    "            best_accuracy = test_accuracy\n",
    "            torch.save(model.state_dict(), f'best_{FINETUNED_MODEL}.pt')\n",
    "            checkpoint = {\n",
    "                'epoch': epoch + 1,\n",
    "                'train_losses': train_losses,\n",
    "                'train_accuracies': train_accuracies,\n",
    "                'test_losses': test_losses,\n",
    "                'test_accuracies': test_accuracies,\n",
    "            }\n",
    "            torch.save(checkpoint, f'best_{FINETUNED_MODEL}_checkpoint.pt')\n",
    "\n",
    "    return model, train_losses, train_accuracies, test_losses, test_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the loss and accuracy graphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(train_losses, test_losses):\n",
    "    plt.figure()\n",
    "    plt.plot(range(len(train_losses)), train_losses, label='Training Loss')\n",
    "    plt.plot(range(len(test_losses)), test_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy(train_accuracies, test_accuracies):\n",
    "    plt.figure()\n",
    "    plt.plot(range(len(train_accuracies)),\n",
    "             train_accuracies, label='Training Accuracy')\n",
    "    plt.plot(range(len(test_accuracies)),\n",
    "             test_accuracies, label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a class to add Gaussian noise to the mel spectrogram images for onlien data augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0.0, std_range=(0.0, 0.1)):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            mean (float): Mean of the Gaussian noise.\n",
    "            std_range (tuple): Range (min, max) from which to sample the noise std.\n",
    "        \"\"\"\n",
    "        self.mean = mean\n",
    "        self.std_range = std_range\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        # Sample a random standard deviation for this call\n",
    "        std = random.uniform(self.std_range[0], self.std_range[1])\n",
    "        noise = torch.randn(tensor.size()) * std + self.mean\n",
    "        return tensor + noise\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}(mean={self.mean}, std_range={self.std_range})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define model, learning rate, optimizer, transformations, and number of epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\profi\\OneDrive\\Desktop\\AI-Project--Speech-Emotion-Recognition\\myenv\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\profi\\OneDrive\\Desktop\\AI-Project--Speech-Emotion-Recognition\\myenv\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'torchvision.transforms' has no attribute 'resize'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Define train transformations, also the online data augmentation\u001b[39;00m\n\u001b[0;32m      8\u001b[0m train_transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[1;32m----> 9\u001b[0m     \u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m((\u001b[38;5;241m448\u001b[39m, \u001b[38;5;241m448\u001b[39m)),  \u001b[38;5;66;03m# Resize the Mel spectrogram to 448x448\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mToTensor(),          \u001b[38;5;66;03m# Convert to Tensor\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     AddGaussianNoise(mean\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m, std_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.1\u001b[39m)\n\u001b[0;32m     12\u001b[0m                      ),  \u001b[38;5;66;03m# Online noise augmentation\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mNormalize(mean\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.485\u001b[39m, \u001b[38;5;241m0.456\u001b[39m, \u001b[38;5;241m0.406\u001b[39m], std\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     14\u001b[0m                          \u001b[38;5;241m0.229\u001b[39m, \u001b[38;5;241m0.224\u001b[39m, \u001b[38;5;241m0.225\u001b[39m])  \u001b[38;5;66;03m# Normalize to ImageNet stats\u001b[39;00m\n\u001b[0;32m     15\u001b[0m ])\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Define test transformations\u001b[39;00m\n\u001b[0;32m     18\u001b[0m test_transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[0;32m     19\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mresize((\u001b[38;5;241m448\u001b[39m, \u001b[38;5;241m448\u001b[39m)),  \u001b[38;5;66;03m# Resize the Mel spectrogram to 448x448\u001b[39;00m\n\u001b[0;32m     20\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mToTensor(),          \u001b[38;5;66;03m# Convert to Tensor\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mNormalize(mean\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.485\u001b[39m, \u001b[38;5;241m0.456\u001b[39m, \u001b[38;5;241m0.406\u001b[39m], std\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     22\u001b[0m                          \u001b[38;5;241m0.229\u001b[39m, \u001b[38;5;241m0.224\u001b[39m, \u001b[38;5;241m0.225\u001b[39m])  \u001b[38;5;66;03m# Normalize to ImageNet stats\u001b[39;00m\n\u001b[0;32m     23\u001b[0m ])\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torchvision.transforms' has no attribute 'resize'"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Define train transformations, also the online data augmentation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((448, 448)),  # Resize the Mel spectrogram to 448x448\n",
    "    transforms.ToTensor(),          # Convert to Tensor\n",
    "    AddGaussianNoise(mean=0.0, std_range=(0.0, 0.1)\n",
    "                     ),  # Online noise augmentation\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[\n",
    "                         0.229, 0.224, 0.225])  # Normalize to ImageNet stats\n",
    "])\n",
    "\n",
    "# Define test transformations\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((448, 448)),  # Resize the Mel spectrogram to 448x448\n",
    "    transforms.ToTensor(),          # Convert to Tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[\n",
    "                         0.229, 0.224, 0.225])  # Normalize to ImageNet stats\n",
    "])\n",
    "\n",
    "epochs = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View pre-trained model architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the fine-tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\profi\\OneDrive\\Desktop\\AI-Project--Speech-Emotion-Recognition\\myenv\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\profi\\OneDrive\\Desktop\\AI-Project--Speech-Emotion-Recognition\\myenv\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping from Emotion to Number: {'Anger': 0, 'Bored': 1, 'Disgust': 2, 'Fear': 3, 'Happy': 4, 'Neutral': 5, 'Question': 6, 'Sad': 7, 'Surprise': 8}\n",
      "Model is on: cuda:0\n",
      "Epoch 1/20\n"
     ]
    }
   ],
   "source": [
    "# Set random seed for reproducability\n",
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "# Number of classes\n",
    "num_classes = 9\n",
    "\n",
    "# Freeze all layers except the last fully connected layer\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False  # Freeze all layers\n",
    "\n",
    "# Modify final fully connected layer according to number of classes\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, num_classes)\n",
    "# print(\"Modified model\")\n",
    "# print(model)\n",
    "\n",
    "# Unfreeze the final fully connected layer so it will be trained\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Move model to GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Load dataset\n",
    "train_csv = '../../data/melspectrogram_train_dataset.csv'\n",
    "test_csv = '../../data/melspectrogram_test_dataset.csv'\n",
    "root_dir = '../../data/'\n",
    "\n",
    "trainset = MelSpectrogramDataset(\n",
    "    csv_file=train_csv, root_dir=root_dir, transform=train_transform)\n",
    "testset = MelSpectrogramDataset(\n",
    "    csv_file=test_csv, root_dir=root_dir, transform=test_transform)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=128, shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=128, shuffle=False)\n",
    "\n",
    "# Label mappings\n",
    "labelmap = trainset.label_map\n",
    "print(f\"Mapping from Emotion to Number: {labelmap}\")\n",
    "\n",
    "# Training\n",
    "print(f\"Model is on: {next(model.parameters()).device}\")\n",
    "model, train_losses, train_accuracies, test_losses, test_accuracies = train_epochs(\n",
    "    model, trainloader, testloader, criterion, optimizer, device, epochs)\n",
    "torch.save(model.state_dict(), f'{FINETUNED_MODEL}_variables_{epochs}.pt')\n",
    "\n",
    "# Plots\n",
    "plot_loss(train_losses, test_losses)\n",
    "plot_accuracy(train_accuracies, test_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
