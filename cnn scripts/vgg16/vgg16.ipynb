{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune VGG16\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 224x224 mel spectrogram images and data augmentation (artifical noise addition with Gaussian noise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set some constant strings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAINED_MODEL = 'vgg16'\n",
    "PRETRAINED_MODEL_NAME = \"VGG16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom dataset class for loading mel spectrogram images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset class for loading Melspectrograms\n",
    "class MelSpectrogramDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with Melspectrogram paths and labels.\n",
    "            root_dir (string): Directory with all the Melspectrograms.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        df = pd.read_csv(csv_file)  # Read the CSV into a DataFrame\n",
    "        self.data_frame = df[['Melspectrogrampath', 'Emotion']]\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        # Sort unique labels before mapping\n",
    "        unique_labels = sorted(df['Emotion'].unique())\n",
    "        self.label_map = {label: idx for idx,\n",
    "                          label in enumerate(unique_labels)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the path to the Melspectrogram and the emotion label (string)\n",
    "        # First column is path, second column is label (emotion as string)\n",
    "        mel_path = os.path.join(self.root_dir, self.data_frame.iloc[idx, 0])\n",
    "        emotion_label_str = self.data_frame.iloc[idx, 1]\n",
    "\n",
    "        # Convert the emotion string to its corresponding integer\n",
    "        emotion_label = self.label_map[emotion_label_str]\n",
    "\n",
    "        # Load the Melspectrogram\n",
    "        mel_image = Image.open(mel_path)\n",
    "        mel_image = mel_image.convert(\"RGB\")\n",
    "\n",
    "        # Apply transformations if any\n",
    "        if self.transform:\n",
    "            mel_image = self.transform(mel_image)\n",
    "\n",
    "        # Convert emotion label to tensor\n",
    "        emotion_label = torch.tensor(emotion_label, dtype=torch.long)\n",
    "\n",
    "        return mel_image, emotion_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the training function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, trainloader, criterion, optimizer, device):\n",
    "    train_loss = 0.0\n",
    "    train_total = 0\n",
    "    train_correct = 0\n",
    "\n",
    "    # train mode\n",
    "    model.train()\n",
    "\n",
    "    for inputs, labels in trainloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update training loss\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    train_loss = train_loss / len(trainloader)\n",
    "    train_accuracy = train_correct / train_total * 100\n",
    "\n",
    "    return model, train_loss, train_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the testing/evaluation function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, testloader, criterion, device):\n",
    "    test_loss = 0.0\n",
    "    test_total = 0\n",
    "    test_correct = 0\n",
    "\n",
    "    # Switch to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Update test loss\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_loss = test_loss / len(testloader)\n",
    "    test_accuracy = test_correct / test_total * 100\n",
    "\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define what happens in each epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epochs(model, trainloader, testloader, criterion, optimizer, device, num_epochs):\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "    best_accuracy = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        model, train_loss, train_accuracy = train(\n",
    "            model, trainloader, criterion, optimizer, device)\n",
    "        test_loss, test_accuracy = test(model, testloader, criterion, device)\n",
    "        print(f'Train Loss: {train_loss} - Train Accuracy: {train_accuracy}')\n",
    "        print(f'Test Loss: {test_loss} - Test Accuracy: {test_accuracy}')\n",
    "        print()\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        test_losses.append(test_loss)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "\n",
    "        # Check if current model is best performing using test_accuracy\n",
    "        if test_accuracy > best_accuracy:\n",
    "            best_accuracy = test_accuracy\n",
    "            torch.save(model.state_dict(), f'best_{PRETRAINED_MODEL}.pth')\n",
    "            checkpoint = {\n",
    "                'epoch': epoch + 1,\n",
    "                'train_losses': train_losses,\n",
    "                'train_accuracies': train_accuracies,\n",
    "                'test_losses': test_losses,\n",
    "                'test_accuracies': test_accuracies,\n",
    "            }\n",
    "            torch.save(checkpoint, f'best_{PRETRAINED_MODEL}_checkpoint.pth')\n",
    "\n",
    "    return model, train_losses, train_accuracies, test_losses, test_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the loss and accuracy graphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(train_losses, test_losses):\n",
    "    plt.figure()\n",
    "    plt.plot(range(len(train_losses)), train_losses, label='Training Loss')\n",
    "    plt.plot(range(len(test_losses)), test_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy(train_accuracies, test_accuracies):\n",
    "    plt.figure()\n",
    "    plt.plot(range(len(train_accuracies)),\n",
    "             train_accuracies, label='Training Accuracy')\n",
    "    plt.plot(range(len(test_accuracies)),\n",
    "             test_accuracies, label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a class to add Gaussian noise to the mel spectrogram images for online data augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0.0, std_range=(0.0, 0.1)):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            mean (float): Mean of the Gaussian noise.\n",
    "            std_range (tuple): Range (min, max) from which to sample the noise std.\n",
    "        \"\"\"\n",
    "        self.mean = mean\n",
    "        self.std_range = std_range\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        # Sample a random standard deviation for this call\n",
    "        std = random.uniform(self.std_range[0], self.std_range[1])\n",
    "        noise = torch.randn(tensor.size()) * std + self.mean\n",
    "        return tensor + noise\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}(mean={self.mean}, std_range={self.std_range})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define model, learning rate, optimizer, transformations, and number of epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.vgg16(pretrained=True)\n",
    "pretrained_model = models.vgg16(pretrained=True)\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Define transformations, also the online data augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),          # Convert to Tensor\n",
    "    AddGaussianNoise(mean=0.0, std_range=(0.0, 0.1)\n",
    "                     ),  # Online noise augmentation\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[\n",
    "                         0.229, 0.224, 0.225])  # Normalize to ImageNet stats\n",
    "])\n",
    "\n",
    "epochs = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View pre-trained model architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the fine-tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducability\n",
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "# Number of classes\n",
    "num_classes = 9\n",
    "\n",
    "# Freeze all layers except the last fully connected layer\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False  # Freeze all layers\n",
    "\n",
    "# Modify final fully connected layer according to number of classes\n",
    "num_features = model.classifier[-1].in_features\n",
    "model.classifier[-1] = nn.Linear(num_features, num_classes)\n",
    "# print(\"Modified model\")\n",
    "# print(model)\n",
    "\n",
    "# Unfreeze the final fully connected layer so it will be trained\n",
    "for param in model.classifier[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Move model to GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Load dataset\n",
    "train_csv = '../../data/melspectrogram_train_dataset.csv'\n",
    "test_csv = '../../data/melspectrogram_test_dataset.csv'\n",
    "root_dir = '../../data/'\n",
    "\n",
    "trainset = MelSpectrogramDataset(\n",
    "    csv_file=train_csv, root_dir=root_dir, transform=transform)\n",
    "testset = MelSpectrogramDataset(\n",
    "    csv_file=test_csv, root_dir=root_dir, transform=transform)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=128, shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=128, shuffle=False)\n",
    "\n",
    "# Label mappings\n",
    "labelmap = trainset.label_map\n",
    "print(f\"Mapping from Emotion to Number: {labelmap}\")\n",
    "\n",
    "print(f\"Model is on: {next(model.parameters()).device}\")\n",
    "model, train_losses, train_accuracies, test_losses, test_accuracies = train_epochs(\n",
    "    model, trainloader, testloader, criterion, optimizer, device, epochs)\n",
    "torch.save(model.state_dict(), f'{pretrained_model}_variables_{epochs}.pth')\n",
    "\n",
    "# Plots\n",
    "plot_loss(train_losses, test_losses)\n",
    "plot_accuracy(train_accuracies, test_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare pretrained VGG16 against finetuned VGG16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all layers\n",
    "for param in pretrained_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modify the final fully connected layer to match the number of classes in your dataset\n",
    "num_features = pretrained_model.fc.in_features\n",
    "pretrained_model.fc = nn.Linear(num_features, num_classes)\n",
    "\n",
    "# Ensure the new fully connected layer is set to evaluation mode\n",
    "pretrained_model.fc.eval()\n",
    "\n",
    "# Move the model to the appropriate device\n",
    "pretrained_model = pretrained_model.to(device)\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Evaluate the model using the test function\n",
    "test_loss, test_accuracy = test(\n",
    "    pretrained_model, testloader, criterion, device)\n",
    "print(\n",
    "    f'Pretrained {PRETRAINED_MODEL_NAME} - Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "artificial-intelligence",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
