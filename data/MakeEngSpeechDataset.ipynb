{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62324c04",
   "metadata": {},
   "source": [
    "# Make English Speech Dataset\n",
    "- Combining 8 English Speech Dataset\n",
    "- Dataset: CREMA-D, MELD, MLEND, RAVDESS, SAVEE, TESS, ESD, JL-Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed70dbbc",
   "metadata": {},
   "source": [
    "## 0. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a2c1ed4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:09:32.712372Z",
     "start_time": "2023-11-01T02:09:30.079134Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6eaac34f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:09:32.717287Z",
     "start_time": "2023-11-01T02:09:32.712372Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy Version: 2.1.3\n",
      "Pandas Version: 2.2.3\n"
     ]
    }
   ],
   "source": [
    "print(\"Numpy Version:\", np.__version__)\n",
    "print(\"Pandas Version:\", pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dc495f",
   "metadata": {},
   "source": [
    "## 1. Load Dataset and Make Sub Dataframes\n",
    "### 1) CREMA-D\n",
    "> https://github.com/CheyneyComputerScience/CREMA-D\n",
    "\n",
    "- `VideoDemographics.csv` - a mapping of ActorID (the first 4 digits of each video file) to Age, Sex, Race, and Ethicity.\n",
    "```shell\n",
    "\"ActorID\" - the first 4 digits of the video/audio file that identifies the actor in the video.\n",
    "\"Age\" - the age in years of the actor at the time of the recording\n",
    "\"Sex\" - the binary sex that the actor identified\n",
    "\"Race\" - African American, Asian, Caucasian, or Unknown\n",
    "\"Ethnicity\" - Hispanic or Not Hispanic\n",
    "```\n",
    "- Actors spoke from a selection of 12 sentences (in parentheses is the three letter acronym used in the second part of the filename):\n",
    "```\n",
    "It's eleven o'clock (IEO).\n",
    "That is exactly what happened (TIE).\n",
    "I'm on my way to the meeting (IOM).\n",
    "I wonder what this is about (IWW).\n",
    "The airplane is almost full (TAI).\n",
    "Maybe tomorrow it will be cold (MTI).\n",
    "I would like a new alarm clock (IWL)\n",
    "I think I have a doctor's appointment (ITH).\n",
    "Don't forget a jacket (DFA).\n",
    "I think I've seen this before (ITS).\n",
    "The surface is slick (TSI).\n",
    "We'll stop in a couple of minutes (WSI).\n",
    "```\n",
    "- The sentences were presented using different emotion (in parentheses is the three letter code used in the third part of the filename):\n",
    "```\n",
    "Anger (ANG)\n",
    "Disgust (DIS)\n",
    "Fear (FEA)\n",
    "Happy/Joy (HAP)\n",
    "Neutral (NEU)\n",
    "Sad (SAD)\n",
    "```\n",
    "- Emotion level (in parentheses is the two letter code used in the fourth part of the filename):\n",
    "```\n",
    "Low (LO)\n",
    "Medium (MD)\n",
    "High (HI)\n",
    "Unspecified (XX)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ccd81fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:11:01.898213Z",
     "start_time": "2023-11-01T02:11:01.856966Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1001_DFA_ANG_XX.wav', '1001_DFA_DIS_XX.wav', '1001_DFA_FEA_XX.wav', '1001_DFA_HAP_XX.wav', '1001_DFA_NEU_XX.wav']\n"
     ]
    }
   ],
   "source": [
    "crema_dir = './dataset/crema-d'\n",
    "crema_filepath = glob.glob(os.path.join(crema_dir, \"AudioWAV\", \"*.wav\"))\n",
    "crema_filename = os.listdir(os.path.join(crema_dir, \"AudioWAV\"))\n",
    "\n",
    "print(crema_filename[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5308d60d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:11:02.062894Z",
     "start_time": "2023-11-01T02:11:02.048320Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Number of CREMA-D Dataset: 7442\n"
     ]
    }
   ],
   "source": [
    "crema_count = len(crema_filename)\n",
    "print(\"The Number of CREMA-D Dataset:\", crema_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2201aca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:11:02.748495Z",
     "start_time": "2023-11-01T02:11:02.736846Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_list = []\n",
    "for fn in crema_filename:\n",
    "    feature_list.append(fn.split(\".wav\")[0].split(\"_\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0771d397",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:11:02.981190Z",
     "start_time": "2023-11-01T02:11:02.965264Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7442, 4)\n",
      "[['1001', 'DFA', 'ANG', 'XX'], ['1001', 'DFA', 'DIS', 'XX'], ['1001', 'DFA', 'FEA', 'XX'], ['1001', 'DFA', 'HAP', 'XX'], ['1001', 'DFA', 'NEU', 'XX'], ['1001', 'DFA', 'SAD', 'XX'], ['1001', 'IEO', 'ANG', 'HI'], ['1001', 'IEO', 'ANG', 'LO'], ['1001', 'IEO', 'ANG', 'MD'], ['1001', 'IEO', 'DIS', 'HI']]\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(feature_list))\n",
    "print(feature_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e066e244",
   "metadata": {},
   "outputs": [],
   "source": [
    "crema_ext = [os.path.splitext(fn)[-1] for fn in crema_filename]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "853dad7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:11:04.747108Z",
     "start_time": "2023-11-01T02:11:04.728391Z"
    }
   },
   "outputs": [],
   "source": [
    "crema_emotion_list = {\"ANG\":\"Anger\", \"DIS\":\"Disgust\", \"FEA\":\"Fear\", \"HAP\":\"Happy\", \"NEU\":\"Neutral\", \"SAD\":\"Sad\"}\n",
    "crema_emotion = [crema_emotion_list[f[2]] for f in feature_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "970997ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:36:48.157331Z",
     "start_time": "2023-11-01T02:36:48.151673Z"
    }
   },
   "outputs": [],
   "source": [
    "crema_df = pd.DataFrame(index = range(0, crema_count), \n",
    "                  columns = ['Id', 'Dataset', 'Filepath', 'Filename', 'Ext', 'Emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e222d379",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:36:48.392707Z",
     "start_time": "2023-11-01T02:36:48.361356Z"
    }
   },
   "outputs": [],
   "source": [
    "crema_df['Dataset'] = ['CREMA-D'] * crema_count\n",
    "crema_df['Filepath'] = crema_filepath\n",
    "crema_df['Filename'] = crema_filename\n",
    "crema_df['Ext'] = crema_ext\n",
    "crema_df['Emotion'] = crema_emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37c72f6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:36:48.592881Z",
     "start_time": "2023-11-01T02:36:48.577806Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Id",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Dataset",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Filepath",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Filename",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Ext",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Emotion",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "c83a4374-0986-4dbf-8e5b-5694396d5b99",
       "rows": [
        [
         "0",
         null,
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_DFA_ANG_XX.wav",
         "1001_DFA_ANG_XX.wav",
         ".wav",
         "Anger"
        ],
        [
         "1",
         null,
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_DFA_DIS_XX.wav",
         "1001_DFA_DIS_XX.wav",
         ".wav",
         "Disgust"
        ],
        [
         "2",
         null,
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_DFA_FEA_XX.wav",
         "1001_DFA_FEA_XX.wav",
         ".wav",
         "Fear"
        ],
        [
         "3",
         null,
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_DFA_HAP_XX.wav",
         "1001_DFA_HAP_XX.wav",
         ".wav",
         "Happy"
        ],
        [
         "4",
         null,
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_DFA_NEU_XX.wav",
         "1001_DFA_NEU_XX.wav",
         ".wav",
         "Neutral"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Filepath</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Ext</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>CREMA-D</td>\n",
       "      <td>./dataset/crema-d\\AudioWAV\\1001_DFA_ANG_XX.wav</td>\n",
       "      <td>1001_DFA_ANG_XX.wav</td>\n",
       "      <td>.wav</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>CREMA-D</td>\n",
       "      <td>./dataset/crema-d\\AudioWAV\\1001_DFA_DIS_XX.wav</td>\n",
       "      <td>1001_DFA_DIS_XX.wav</td>\n",
       "      <td>.wav</td>\n",
       "      <td>Disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>CREMA-D</td>\n",
       "      <td>./dataset/crema-d\\AudioWAV\\1001_DFA_FEA_XX.wav</td>\n",
       "      <td>1001_DFA_FEA_XX.wav</td>\n",
       "      <td>.wav</td>\n",
       "      <td>Fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>CREMA-D</td>\n",
       "      <td>./dataset/crema-d\\AudioWAV\\1001_DFA_HAP_XX.wav</td>\n",
       "      <td>1001_DFA_HAP_XX.wav</td>\n",
       "      <td>.wav</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>CREMA-D</td>\n",
       "      <td>./dataset/crema-d\\AudioWAV\\1001_DFA_NEU_XX.wav</td>\n",
       "      <td>1001_DFA_NEU_XX.wav</td>\n",
       "      <td>.wav</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id  Dataset                                        Filepath  \\\n",
       "0  NaN  CREMA-D  ./dataset/crema-d\\AudioWAV\\1001_DFA_ANG_XX.wav   \n",
       "1  NaN  CREMA-D  ./dataset/crema-d\\AudioWAV\\1001_DFA_DIS_XX.wav   \n",
       "2  NaN  CREMA-D  ./dataset/crema-d\\AudioWAV\\1001_DFA_FEA_XX.wav   \n",
       "3  NaN  CREMA-D  ./dataset/crema-d\\AudioWAV\\1001_DFA_HAP_XX.wav   \n",
       "4  NaN  CREMA-D  ./dataset/crema-d\\AudioWAV\\1001_DFA_NEU_XX.wav   \n",
       "\n",
       "              Filename   Ext  Emotion  \n",
       "0  1001_DFA_ANG_XX.wav  .wav    Anger  \n",
       "1  1001_DFA_DIS_XX.wav  .wav  Disgust  \n",
       "2  1001_DFA_FEA_XX.wav  .wav     Fear  \n",
       "3  1001_DFA_HAP_XX.wav  .wav    Happy  \n",
       "4  1001_DFA_NEU_XX.wav  .wav  Neutral  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crema_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba15aaea",
   "metadata": {},
   "source": [
    "### 2) MELD\n",
    "> https://affective-meld.github.io/\n",
    "- There are `train`, `test` and `dev` data in MELD dataset\n",
    "- We only use `train`.\n",
    "\n",
    "- `train_sent_emo.csv`, `test_sent_emo.csv`\n",
    "```shell\n",
    "\"Sr No.\"\tSerial numbers of the utterances mainly for referencing the utterances in case of different versions or multiple copies with different subsets\n",
    "\"Utterance\"\tIndividual utterances from EmotionLines as a string.\n",
    "\"Speaker\"\tName of the speaker associated with the utterance.\n",
    "\"Emotion\"\tThe emotion (neutral, joy, sadness, anger, surprise, fear, disgust) expressed by the speaker in the utterance.\n",
    "\"Sentiment\"\tThe sentiment (positive, neutral, negative) expressed by the speaker in the utterance.\n",
    "\"Dialogue_ID\"\tThe index of the dialogue starting from 0.\n",
    "\"Utterance_ID\"\tThe index of the particular utterance in the dialogue starting from 0.\n",
    "\"Season\"\tThe season no. of Friends TV Show to which a particular utterance belongs.\n",
    "\"Episode\"\tThe episode no. of Friends TV Show in a particular season to which the utterance belongs.\n",
    "\"StartTime\"\tThe starting time of the utterance in the given episode in the format 'hh:mm:ss,ms'.\n",
    "\"EndTime\"\tThe ending time of the utterance in the given episode in the format 'hh:mm:ss,ms'.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a62d5ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:36:51.623636Z",
     "start_time": "2023-11-01T02:36:51.575578Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dia0_utt0.mp4', 'dia0_utt1.mp4', 'dia0_utt10.mp4', 'dia0_utt11.mp4', 'dia0_utt12.mp4']\n"
     ]
    }
   ],
   "source": [
    "meld_dir = './dataset/meld'\n",
    "\n",
    "meld_filepath = glob.glob(os.path.join(meld_dir, \"train\", \"*.mp4\"))\n",
    "meld_filename = os.listdir(os.path.join(meld_dir, \"train\"))\n",
    "\n",
    "print(meld_filename[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "163b45a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:36:51.760397Z",
     "start_time": "2023-11-01T02:36:51.728150Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Sr No.",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Utterance",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Speaker",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Emotion",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Sentiment",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Dialogue_ID",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Utterance_ID",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Season",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Episode",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "StartTime",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "EndTime",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "a84efe99-c7c4-4ddd-889b-5e8b4a3aa510",
       "rows": [
        [
         "0",
         "1",
         "also I was the point person on my companys transition from the KL-5 to GR-6 system.",
         "Chandler",
         "neutral",
         "neutral",
         "0",
         "0",
         "8",
         "21",
         "00:16:16,059",
         "00:16:21,731"
        ],
        [
         "1",
         "2",
         "You mustve had your hands full.",
         "The Interviewer",
         "neutral",
         "neutral",
         "0",
         "1",
         "8",
         "21",
         "00:16:21,940",
         "00:16:23,442"
        ],
        [
         "2",
         "3",
         "That I did. That I did.",
         "Chandler",
         "neutral",
         "neutral",
         "0",
         "2",
         "8",
         "21",
         "00:16:23,442",
         "00:16:26,389"
        ],
        [
         "3",
         "4",
         "So lets talk a little bit about your duties.",
         "The Interviewer",
         "neutral",
         "neutral",
         "0",
         "3",
         "8",
         "21",
         "00:16:26,820",
         "00:16:29,572"
        ],
        [
         "4",
         "5",
         "My duties?  All right.",
         "Chandler",
         "surprise",
         "positive",
         "0",
         "4",
         "8",
         "21",
         "00:16:34,452",
         "00:16:40,917"
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sr No.</th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Dialogue_ID</th>\n",
       "      <th>Utterance_ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>StartTime</th>\n",
       "      <th>EndTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>also I was the point person on my companys tr...</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>00:16:16,059</td>\n",
       "      <td>00:16:21,731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>You mustve had your hands full.</td>\n",
       "      <td>The Interviewer</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>00:16:21,940</td>\n",
       "      <td>00:16:23,442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>That I did. That I did.</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>00:16:23,442</td>\n",
       "      <td>00:16:26,389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>So lets talk a little bit about your duties.</td>\n",
       "      <td>The Interviewer</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>00:16:26,820</td>\n",
       "      <td>00:16:29,572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>My duties?  All right.</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>surprise</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>00:16:34,452</td>\n",
       "      <td>00:16:40,917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sr No.                                          Utterance          Speaker  \\\n",
       "0       1  also I was the point person on my companys tr...         Chandler   \n",
       "1       2                   You mustve had your hands full.  The Interviewer   \n",
       "2       3                            That I did. That I did.         Chandler   \n",
       "3       4      So lets talk a little bit about your duties.  The Interviewer   \n",
       "4       5                             My duties?  All right.         Chandler   \n",
       "\n",
       "    Emotion Sentiment  Dialogue_ID  Utterance_ID  Season  Episode  \\\n",
       "0   neutral   neutral            0             0       8       21   \n",
       "1   neutral   neutral            0             1       8       21   \n",
       "2   neutral   neutral            0             2       8       21   \n",
       "3   neutral   neutral            0             3       8       21   \n",
       "4  surprise  positive            0             4       8       21   \n",
       "\n",
       "      StartTime       EndTime  \n",
       "0  00:16:16,059  00:16:21,731  \n",
       "1  00:16:21,940  00:16:23,442  \n",
       "2  00:16:23,442  00:16:26,389  \n",
       "3  00:16:26,820  00:16:29,572  \n",
       "4  00:16:34,452  00:16:40,917  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meld_sub_df = pd.read_csv(os.path.join(meld_dir, 'train_sent_emo.csv'))\n",
    "\n",
    "meld_sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af2d7a3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:36:55.113429Z",
     "start_time": "2023-11-01T02:36:53.064016Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m dia \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(dia\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdia\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m      9\u001b[0m utt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(utt\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m---> 11\u001b[0m row \u001b[38;5;241m=\u001b[39m meld_sub_df[(\u001b[43mmeld_sub_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDialogue_ID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43mdia\u001b[49m) \u001b[38;5;241m&\u001b[39m (meld_sub_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUtterance_ID\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mutt)]\n\u001b[0;32m     13\u001b[0m emo \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEmotion\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     14\u001b[0m meld_emotion\u001b[38;5;241m.\u001b[39mappend(emotion_list[emo])\n",
      "File \u001b[1;32mc:\\Users\\profi\\OneDrive\\Desktop\\AI-Project--Speech-Emotion-Recognition\\myenv\\lib\\site-packages\\pandas\\core\\ops\\common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\profi\\OneDrive\\Desktop\\AI-Project--Speech-Emotion-Recognition\\myenv\\lib\\site-packages\\pandas\\core\\arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\profi\\OneDrive\\Desktop\\AI-Project--Speech-Emotion-Recognition\\myenv\\lib\\site-packages\\pandas\\core\\series.py:6119\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   6116\u001b[0m lvalues \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m   6117\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 6119\u001b[0m res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[1;32mc:\\Users\\profi\\OneDrive\\Desktop\\AI-Project--Speech-Emotion-Recognition\\myenv\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:347\u001b[0m, in \u001b[0;36mcomparison_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    344\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m comp_method_OBJECT_ARRAY(op, lvalues, rvalues)\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 347\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43m_na_arithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_cmp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res_values\n",
      "File \u001b[1;32mc:\\Users\\profi\\OneDrive\\Desktop\\AI-Project--Speech-Emotion-Recognition\\myenv\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:218\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[1;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[0;32m    215\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(expressions\u001b[38;5;241m.\u001b[39mevaluate, op)\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 218\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cmp \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m    221\u001b[0m         left\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(right, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m\n\u001b[0;32m    222\u001b[0m     ):\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;66;03m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[0;32m    226\u001b[0m         \u001b[38;5;66;03m#  incorrectly, see GH#32047\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\profi\\OneDrive\\Desktop\\AI-Project--Speech-Emotion-Recognition\\myenv\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:242\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m op_str \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_numexpr:\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;66;03m# error: \"None\" not callable\u001b[39;00m\n\u001b[1;32m--> 242\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "File \u001b[1;32mc:\\Users\\profi\\OneDrive\\Desktop\\AI-Project--Speech-Emotion-Recognition\\myenv\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:73\u001b[0m, in \u001b[0;36m_evaluate_standard\u001b[1;34m(op, op_str, a, b)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _TEST_MODE:\n\u001b[0;32m     72\u001b[0m     _store_test_result(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "meld_emotion = []\n",
    "meld_ext = []\n",
    "emotion_list = {\"anger\":\"Anger\", \"disgust\":\"Disgust\", \"fear\":\"Fear\", \"joy\":\"Happy\", \n",
    "                \"neutral\":\"Neutral\", \"sadness\":\"Sad\", \"surprise\":\"Surprise\"}\n",
    "for fn in meld_filename:\n",
    "    name, ext = os.path.splitext(fn)\n",
    "    dia, utt = name.split(\"_\")\n",
    "    dia = int(dia.replace(\"dia\", \"\"))\n",
    "    utt = int(utt.replace(\"utt\", \"\"))\n",
    "    \n",
    "    row = meld_sub_df[(meld_sub_df['Dialogue_ID']==dia) & (meld_sub_df['Utterance_ID']==utt)]\n",
    "    \n",
    "    emo = row['Emotion'].values[0]\n",
    "    meld_emotion.append(emotion_list[emo])\n",
    "    \n",
    "    meld_ext.append(ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4358de3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:36:55.129429Z",
     "start_time": "2023-11-01T02:36:55.114512Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Number of MELD Dataset: 9988\n"
     ]
    }
   ],
   "source": [
    "meld_count = len(meld_ext)\n",
    "print(\"The Number of MELD Dataset:\", meld_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4c27f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:36:56.076883Z",
     "start_time": "2023-11-01T02:36:56.071822Z"
    }
   },
   "outputs": [],
   "source": [
    "meld_df = pd.DataFrame(index = range(0, meld_count), \n",
    "                  columns = ['Id', 'Dataset', 'Filepath', 'Filename', 'Ext', 'Emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573d1a50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:36:56.992838Z",
     "start_time": "2023-11-01T02:36:56.975663Z"
    }
   },
   "outputs": [],
   "source": [
    "meld_df['Dataset'] = [\"MELD\"] * meld_count\n",
    "meld_df['Filepath'] = meld_filepath\n",
    "meld_df['Filename'] = meld_filename\n",
    "meld_df['Ext'] = meld_ext\n",
    "meld_df['Emotion'] = meld_emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37d1ede",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:36:57.218438Z",
     "start_time": "2023-11-01T02:36:57.196885Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Id",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Dataset",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Filepath",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Filename",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Ext",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Emotion",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "8b73a6ad-3e34-42f5-bfc9-6d8f03b3def3",
       "rows": [
        [
         "0",
         null,
         "MELD",
         "./dataset/meld\\train\\dia0_utt0.mp4",
         "dia0_utt0.mp4",
         ".mp4",
         "Neutral"
        ],
        [
         "1",
         null,
         "MELD",
         "./dataset/meld\\train\\dia0_utt1.mp4",
         "dia0_utt1.mp4",
         ".mp4",
         "Neutral"
        ],
        [
         "2",
         null,
         "MELD",
         "./dataset/meld\\train\\dia0_utt10.mp4",
         "dia0_utt10.mp4",
         ".mp4",
         "Fear"
        ],
        [
         "3",
         null,
         "MELD",
         "./dataset/meld\\train\\dia0_utt11.mp4",
         "dia0_utt11.mp4",
         ".mp4",
         "Neutral"
        ],
        [
         "4",
         null,
         "MELD",
         "./dataset/meld\\train\\dia0_utt12.mp4",
         "dia0_utt12.mp4",
         ".mp4",
         "Surprise"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Filepath</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Ext</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>MELD</td>\n",
       "      <td>./dataset/meld\\train\\dia0_utt0.mp4</td>\n",
       "      <td>dia0_utt0.mp4</td>\n",
       "      <td>.mp4</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>MELD</td>\n",
       "      <td>./dataset/meld\\train\\dia0_utt1.mp4</td>\n",
       "      <td>dia0_utt1.mp4</td>\n",
       "      <td>.mp4</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>MELD</td>\n",
       "      <td>./dataset/meld\\train\\dia0_utt10.mp4</td>\n",
       "      <td>dia0_utt10.mp4</td>\n",
       "      <td>.mp4</td>\n",
       "      <td>Fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>MELD</td>\n",
       "      <td>./dataset/meld\\train\\dia0_utt11.mp4</td>\n",
       "      <td>dia0_utt11.mp4</td>\n",
       "      <td>.mp4</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>MELD</td>\n",
       "      <td>./dataset/meld\\train\\dia0_utt12.mp4</td>\n",
       "      <td>dia0_utt12.mp4</td>\n",
       "      <td>.mp4</td>\n",
       "      <td>Surprise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id Dataset                             Filepath        Filename   Ext  \\\n",
       "0  NaN    MELD   ./dataset/meld\\train\\dia0_utt0.mp4   dia0_utt0.mp4  .mp4   \n",
       "1  NaN    MELD   ./dataset/meld\\train\\dia0_utt1.mp4   dia0_utt1.mp4  .mp4   \n",
       "2  NaN    MELD  ./dataset/meld\\train\\dia0_utt10.mp4  dia0_utt10.mp4  .mp4   \n",
       "3  NaN    MELD  ./dataset/meld\\train\\dia0_utt11.mp4  dia0_utt11.mp4  .mp4   \n",
       "4  NaN    MELD  ./dataset/meld\\train\\dia0_utt12.mp4  dia0_utt12.mp4  .mp4   \n",
       "\n",
       "    Emotion  \n",
       "0   Neutral  \n",
       "1   Neutral  \n",
       "2      Fear  \n",
       "3   Neutral  \n",
       "4  Surprise  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meld_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626c421b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T00:41:33.040641Z",
     "start_time": "2023-10-30T00:41:33.024528Z"
    }
   },
   "source": [
    "### 3) MLEnd\n",
    "> https://www.kaggle.com/datasets/jesusrequena/mlend-spoken-numerals\n",
    "- Speakers read one english word (zero to billion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287f16ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:36:58.833811Z",
     "start_time": "2023-11-01T02:36:58.739197Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00000.wav', '00001.wav', '00003.wav', '00004.wav', '00005.wav']\n"
     ]
    }
   ],
   "source": [
    "mlend_dir = './dataset/mlend'\n",
    "\n",
    "mlend_filepath = glob.glob(os.path.join(mlend_dir, 'MLEndSND_Public', \"*.wav\"))\n",
    "mlend_filename = os.listdir(os.path.join(mlend_dir, 'MLEndSND_Public'))\n",
    "\n",
    "print(mlend_filename[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7852d819",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:36:58.904314Z",
     "start_time": "2023-11-01T02:36:58.878215Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dataset/mlend\\MLEndSND_Audio_Attributes.csv\n",
      "       Public filename     Numeral Intonation  Speaker\n",
      "32649            47063          11    neutral       33\n",
      "32650            47064           9    excited       91\n",
      "32651            47065  1000000000    neutral      111\n",
      "32652            47066        1000    neutral       15\n",
      "32653            47067           0    neutral       82 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for path in glob.glob(os.path.join(mlend_dir, \"*.csv\")):\n",
    "    print(path)\n",
    "    csv = pd.read_csv(path)\n",
    "    print(csv.tail(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a6b214",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:36:59.070894Z",
     "start_time": "2023-11-01T02:36:59.047992Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Public filename",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Numeral",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Intonation",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Speaker",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "7066d38e-ab4b-4486-8e26-13b1e03ba78b",
       "rows": [
        [
         "0",
         "0",
         "3",
         "excited",
         "59"
        ],
        [
         "1",
         "1",
         "1000000",
         "question",
         "31"
        ],
        [
         "2",
         "3",
         "15",
         "excited",
         "107"
        ],
        [
         "3",
         "4",
         "13",
         "excited",
         "114"
        ],
        [
         "4",
         "5",
         "19",
         "neutral",
         "132"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Public filename</th>\n",
       "      <th>Numeral</th>\n",
       "      <th>Intonation</th>\n",
       "      <th>Speaker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>excited</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1000000</td>\n",
       "      <td>question</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>excited</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>excited</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>neutral</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Public filename  Numeral Intonation  Speaker\n",
       "0                0        3    excited       59\n",
       "1                1  1000000   question       31\n",
       "2                3       15    excited      107\n",
       "3                4       13    excited      114\n",
       "4                5       19    neutral      132"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlend_sub_df1 = pd.read_csv(\"./dataset/mlend\\MLEndSND_Audio_Attributes.csv\")\n",
    "mlend_sub_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb16d6a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:37:00.026802Z",
     "start_time": "2023-11-01T02:37:00.016054Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Number of MLEND Dataset: 32654\n"
     ]
    }
   ],
   "source": [
    "mlend_count = len(mlend_filename)\n",
    "print(\"The Number of MLEND Dataset:\", mlend_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd66ca7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:37:05.639683Z",
     "start_time": "2023-11-01T02:37:01.061002Z"
    }
   },
   "outputs": [],
   "source": [
    "mlend_emotion = []\n",
    "mlend_ext = []\n",
    "emotion_list = {\"excited\":\"Happy\", \"neutral\":\"Neutral\", \"bored\":\"Bored\", \"question\":\"Question\"}\n",
    "for i in range(mlend_count):\n",
    "    _, ext = os.path.splitext(mlend_filename[i])\n",
    "    speaker_num = mlend_sub_df1.iloc[i][\"Speaker\"]\n",
    "    speaker = \"Mlend_\" + str(speaker_num)\n",
    "        \n",
    "    emotion = mlend_sub_df1.iloc[i][\"Intonation\"]\n",
    "    emotion = emotion_list[emotion]\n",
    "    \n",
    "    mlend_emotion.append(emotion)\n",
    "    mlend_ext.append(ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113462ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:37:05.660052Z",
     "start_time": "2023-11-01T02:37:05.639683Z"
    }
   },
   "outputs": [],
   "source": [
    "mlend_df = pd.DataFrame(index = range(0, mlend_count), \n",
    "                  columns = ['Id', 'Dataset', 'Filepath', 'Filename', 'Ext', 'Emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e22955",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:37:06.511346Z",
     "start_time": "2023-11-01T02:37:06.502164Z"
    }
   },
   "outputs": [],
   "source": [
    "mlend_df['Dataset'] = [\"MLEND\"] * mlend_count\n",
    "mlend_df['Filepath'] = mlend_filepath\n",
    "mlend_df['Filename'] = mlend_filename\n",
    "mlend_df['Ext'] = mlend_ext\n",
    "mlend_df['Emotion'] = mlend_emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adf2872",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:37:06.709133Z",
     "start_time": "2023-11-01T02:37:06.676759Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Id",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Dataset",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Filepath",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Filename",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Ext",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Emotion",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "cb3ca084-2584-4435-ad0a-35a187c17c8f",
       "rows": [
        [
         "0",
         null,
         "MLEND",
         "./dataset/mlend\\MLEndSND_Public\\00000.wav",
         "00000.wav",
         ".wav",
         "Happy"
        ],
        [
         "1",
         null,
         "MLEND",
         "./dataset/mlend\\MLEndSND_Public\\00001.wav",
         "00001.wav",
         ".wav",
         "Question"
        ],
        [
         "2",
         null,
         "MLEND",
         "./dataset/mlend\\MLEndSND_Public\\00003.wav",
         "00003.wav",
         ".wav",
         "Happy"
        ],
        [
         "3",
         null,
         "MLEND",
         "./dataset/mlend\\MLEndSND_Public\\00004.wav",
         "00004.wav",
         ".wav",
         "Happy"
        ],
        [
         "4",
         null,
         "MLEND",
         "./dataset/mlend\\MLEndSND_Public\\00005.wav",
         "00005.wav",
         ".wav",
         "Neutral"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Filepath</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Ext</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>MLEND</td>\n",
       "      <td>./dataset/mlend\\MLEndSND_Public\\00000.wav</td>\n",
       "      <td>00000.wav</td>\n",
       "      <td>.wav</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>MLEND</td>\n",
       "      <td>./dataset/mlend\\MLEndSND_Public\\00001.wav</td>\n",
       "      <td>00001.wav</td>\n",
       "      <td>.wav</td>\n",
       "      <td>Question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>MLEND</td>\n",
       "      <td>./dataset/mlend\\MLEndSND_Public\\00003.wav</td>\n",
       "      <td>00003.wav</td>\n",
       "      <td>.wav</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>MLEND</td>\n",
       "      <td>./dataset/mlend\\MLEndSND_Public\\00004.wav</td>\n",
       "      <td>00004.wav</td>\n",
       "      <td>.wav</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>MLEND</td>\n",
       "      <td>./dataset/mlend\\MLEndSND_Public\\00005.wav</td>\n",
       "      <td>00005.wav</td>\n",
       "      <td>.wav</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id Dataset                                   Filepath   Filename   Ext  \\\n",
       "0  NaN   MLEND  ./dataset/mlend\\MLEndSND_Public\\00000.wav  00000.wav  .wav   \n",
       "1  NaN   MLEND  ./dataset/mlend\\MLEndSND_Public\\00001.wav  00001.wav  .wav   \n",
       "2  NaN   MLEND  ./dataset/mlend\\MLEndSND_Public\\00003.wav  00003.wav  .wav   \n",
       "3  NaN   MLEND  ./dataset/mlend\\MLEndSND_Public\\00004.wav  00004.wav  .wav   \n",
       "4  NaN   MLEND  ./dataset/mlend\\MLEndSND_Public\\00005.wav  00005.wav  .wav   \n",
       "\n",
       "    Emotion  \n",
       "0     Happy  \n",
       "1  Question  \n",
       "2     Happy  \n",
       "3     Happy  \n",
       "4   Neutral  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlend_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ed6f47",
   "metadata": {},
   "source": [
    "### 4) RAVDESS\n",
    "> https://www.kaggle.com/datasets/uwrfkaggler/ravdess-emotional-speech-audio\n",
    "- Only two kinds of statement.\n",
    "\n",
    "- Labels in Filename.\n",
    "```shell\n",
    "Modality (01 = full-AV, 02 = video-only, 03 = audio-only).\n",
    "Vocal channel (01 = speech, 02 = song).\n",
    "Emotion (01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised).\n",
    "Emotional intensity (01 = normal, 02 = strong). NOTE: There is no strong intensity for the 'neutral' emotion.\n",
    "Statement (01 = \"Kids are talking by the door\", 02 = \"Dogs are sitting by the door\").\n",
    "Repetition (01 = 1st repetition, 02 = 2nd repetition).\n",
    "Actor (01 to 24. Odd numbered actors are male, even numbered actors are female).\n",
    "```\n",
    "```shell\n",
    "Filename example: 03-01-06-01-02-01-12.wav\n",
    "\n",
    "Audio-only (03)\n",
    "Speech (01)\n",
    "Fearful (06)\n",
    "Normal intensity (01)\n",
    "Statement \"dogs\" (02)\n",
    "1st Repetition (01)\n",
    "12th Actor (12)\n",
    "Female, as the actor ID number is even.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be541cb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:37:08.399698Z",
     "start_time": "2023-11-01T02:37:08.391575Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Actor_01', 'Actor_02', 'Actor_03', 'Actor_04', 'Actor_05']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rav_dir = './dataset/ravdess'\n",
    "actor_list = os.listdir(rav_dir)\n",
    "actor_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcadccd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:37:08.877006Z",
     "start_time": "2023-11-01T02:37:08.832321Z"
    }
   },
   "outputs": [],
   "source": [
    "rav_filepath = []\n",
    "rav_filename = []\n",
    "rav_ext = []\n",
    "rav_emotion = []\n",
    "\n",
    "emotion_list = {'01':'Neutral', '02':'Calm', '03':'Happy', '04':'Sad', '05':'Anger', '06':'Fear', '07':'Disgust', '08':'Surprise'}\n",
    "\n",
    "for act in actor_list:\n",
    "    paths = glob.glob(os.path.join(rav_dir, act, \"*.wav\")) \n",
    "    names = os.listdir(os.path.join(rav_dir, act))\n",
    "    \n",
    "    for i in range(len(names)):\n",
    "        name, ext = os.path.splitext(names[i])\n",
    "        num_list = name.split(\"-\")\n",
    "        \n",
    "        emotion = emotion_list[num_list[2]]\n",
    "        speaker = \"Ravdess_\" + num_list[6]\n",
    "        \n",
    "        if int(num_list[6])%2 == 0:\n",
    "            gender = 'Female'\n",
    "        else:\n",
    "            gender = \"Male\"\n",
    "        \n",
    "        rav_filepath.append(paths[i])\n",
    "        rav_filename.append(names[i])\n",
    "        rav_ext.append(ext)\n",
    "        \n",
    "        rav_emotion.append(emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fffb11e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:37:09.709999Z",
     "start_time": "2023-11-01T02:37:09.703688Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Number of RAVDESS Dataset: 1440\n"
     ]
    }
   ],
   "source": [
    "rav_count = len(rav_filepath)\n",
    "print(\"The Number of RAVDESS Dataset:\", rav_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5c56a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:37:11.360244Z",
     "start_time": "2023-11-01T02:37:11.352199Z"
    }
   },
   "outputs": [],
   "source": [
    "rav_df = pd.DataFrame(index = range(0, rav_count), \n",
    "                  columns = ['Id', 'Dataset', 'Filepath', 'Filename', 'Ext', 'Emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b96524",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:37:11.543005Z",
     "start_time": "2023-11-01T02:37:11.527381Z"
    }
   },
   "outputs": [],
   "source": [
    "rav_df[\"Dataset\"] = [\"RAVDESS\"] * rav_count\n",
    "rav_df['Filepath'] = rav_filepath\n",
    "rav_df['Filename'] = rav_filename\n",
    "rav_df['Ext'] = rav_ext\n",
    "rav_df['Emotion'] = rav_emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e906952",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:37:11.759183Z",
     "start_time": "2023-11-01T02:37:11.727689Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Id",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Dataset",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Filepath",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Filename",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Ext",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Emotion",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "e352567d-23dc-4191-a150-79d814ba8c30",
       "rows": [
        [
         "0",
         null,
         "RAVDESS",
         "./dataset/ravdess\\Actor_01\\03-01-01-01-01-01-01.wav",
         "03-01-01-01-01-01-01.wav",
         ".wav",
         "Neutral"
        ],
        [
         "1",
         null,
         "RAVDESS",
         "./dataset/ravdess\\Actor_01\\03-01-01-01-01-02-01.wav",
         "03-01-01-01-01-02-01.wav",
         ".wav",
         "Neutral"
        ],
        [
         "2",
         null,
         "RAVDESS",
         "./dataset/ravdess\\Actor_01\\03-01-01-01-02-01-01.wav",
         "03-01-01-01-02-01-01.wav",
         ".wav",
         "Neutral"
        ],
        [
         "3",
         null,
         "RAVDESS",
         "./dataset/ravdess\\Actor_01\\03-01-01-01-02-02-01.wav",
         "03-01-01-01-02-02-01.wav",
         ".wav",
         "Neutral"
        ],
        [
         "4",
         null,
         "RAVDESS",
         "./dataset/ravdess\\Actor_01\\03-01-02-01-01-01-01.wav",
         "03-01-02-01-01-01-01.wav",
         ".wav",
         "Calm"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Filepath</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Ext</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>RAVDESS</td>\n",
       "      <td>./dataset/ravdess\\Actor_01\\03-01-01-01-01-01-0...</td>\n",
       "      <td>03-01-01-01-01-01-01.wav</td>\n",
       "      <td>.wav</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>RAVDESS</td>\n",
       "      <td>./dataset/ravdess\\Actor_01\\03-01-01-01-01-02-0...</td>\n",
       "      <td>03-01-01-01-01-02-01.wav</td>\n",
       "      <td>.wav</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>RAVDESS</td>\n",
       "      <td>./dataset/ravdess\\Actor_01\\03-01-01-01-02-01-0...</td>\n",
       "      <td>03-01-01-01-02-01-01.wav</td>\n",
       "      <td>.wav</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>RAVDESS</td>\n",
       "      <td>./dataset/ravdess\\Actor_01\\03-01-01-01-02-02-0...</td>\n",
       "      <td>03-01-01-01-02-02-01.wav</td>\n",
       "      <td>.wav</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>RAVDESS</td>\n",
       "      <td>./dataset/ravdess\\Actor_01\\03-01-02-01-01-01-0...</td>\n",
       "      <td>03-01-02-01-01-01-01.wav</td>\n",
       "      <td>.wav</td>\n",
       "      <td>Calm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id  Dataset                                           Filepath  \\\n",
       "0  NaN  RAVDESS  ./dataset/ravdess\\Actor_01\\03-01-01-01-01-01-0...   \n",
       "1  NaN  RAVDESS  ./dataset/ravdess\\Actor_01\\03-01-01-01-01-02-0...   \n",
       "2  NaN  RAVDESS  ./dataset/ravdess\\Actor_01\\03-01-01-01-02-01-0...   \n",
       "3  NaN  RAVDESS  ./dataset/ravdess\\Actor_01\\03-01-01-01-02-02-0...   \n",
       "4  NaN  RAVDESS  ./dataset/ravdess\\Actor_01\\03-01-02-01-01-01-0...   \n",
       "\n",
       "                   Filename   Ext  Emotion  \n",
       "0  03-01-01-01-01-01-01.wav  .wav  Neutral  \n",
       "1  03-01-01-01-01-02-01.wav  .wav  Neutral  \n",
       "2  03-01-01-01-02-01-01.wav  .wav  Neutral  \n",
       "3  03-01-01-01-02-02-01.wav  .wav  Neutral  \n",
       "4  03-01-02-01-01-01-01.wav  .wav     Calm  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rav_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df572ebd",
   "metadata": {},
   "source": [
    "### 5) SAVEE\n",
    "> https://www.kaggle.com/datasets/ejlok1/surrey-audiovisual-expressed-emotion-savee\n",
    "\n",
    "- Labels in Filename\n",
    "```shell\n",
    "\"a\":\"Anger\"\n",
    "\"d\":\"Disgust\"\n",
    "\"f\":\"Fear\"\n",
    "\"h\":\"Happy\"\n",
    "\"n\":\"Neutral\"\n",
    "\"sa\":\"Sad\"\n",
    "\"su\":\"Surprise\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d697a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:37:13.407082Z",
     "start_time": "2023-11-01T02:37:13.400078Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DC_a01.wav', 'DC_a02.wav', 'DC_a03.wav', 'DC_a04.wav', 'DC_a05.wav']\n",
      "The Number of SAVEE Dataset: 480\n"
     ]
    }
   ],
   "source": [
    "savee_dir = './dataset/savee'\n",
    "savee_filename = os.listdir(savee_dir)\n",
    "savee_filepath = glob.glob(os.path.join(savee_dir, \"*.wav\"))\n",
    "print(savee_filename[:5])\n",
    "\n",
    "savee_count = len(savee_filepath)\n",
    "print(\"The Number of SAVEE Dataset:\", savee_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25702ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:37:13.592442Z",
     "start_time": "2023-11-01T02:37:13.575995Z"
    }
   },
   "outputs": [],
   "source": [
    "savee_ext = []\n",
    "savee_emotion = []\n",
    "emotion_list = {\"a\":\"Anger\", \"d\":\"Disgust\", \"f\":\"Fear\", \"h\":\"Happy\", \"n\":\"Neutral\", \"sa\":\"Sad\", \"su\":\"Surprise\"}\n",
    "for fn in savee_filename:\n",
    "    name, ext = os.path.splitext(fn)\n",
    "    \n",
    "    speaker, emo = name.split(\"_\")\n",
    "    emo = emo[:-2]\n",
    "    emotion = emotion_list[emo]\n",
    "    speaker = \"Savee_\" + speaker\n",
    "\n",
    "    savee_ext.append(ext)\n",
    "    savee_emotion.append(emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7157de48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:37:18.540828Z",
     "start_time": "2023-11-01T02:37:18.534638Z"
    }
   },
   "outputs": [],
   "source": [
    "savee_df = pd.DataFrame(index = range(0, savee_count), \n",
    "                  columns = ['Id', 'Dataset', 'Filepath', 'Filename', 'Ext', 'Emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b730278c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:37:18.709347Z",
     "start_time": "2023-11-01T02:37:18.693717Z"
    }
   },
   "outputs": [],
   "source": [
    "savee_df['Dataset'] = [\"SAVEE\"] * savee_count\n",
    "savee_df['Filepath'] = savee_filepath\n",
    "savee_df['Filename'] = savee_filename\n",
    "savee_df['Ext'] = savee_ext\n",
    "savee_df['Emotion'] = savee_emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e33dd7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:37:18.892904Z",
     "start_time": "2023-11-01T02:37:18.877279Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Id",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Dataset",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Filepath",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Filename",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Ext",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Emotion",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "bb2400f8-d6e7-496c-817d-1957719e72d2",
       "rows": [
        [
         "0",
         null,
         "SAVEE",
         "./dataset/savee\\DC_a01.wav",
         "DC_a01.wav",
         ".wav",
         "Anger"
        ],
        [
         "1",
         null,
         "SAVEE",
         "./dataset/savee\\DC_a02.wav",
         "DC_a02.wav",
         ".wav",
         "Anger"
        ],
        [
         "2",
         null,
         "SAVEE",
         "./dataset/savee\\DC_a03.wav",
         "DC_a03.wav",
         ".wav",
         "Anger"
        ],
        [
         "3",
         null,
         "SAVEE",
         "./dataset/savee\\DC_a04.wav",
         "DC_a04.wav",
         ".wav",
         "Anger"
        ],
        [
         "4",
         null,
         "SAVEE",
         "./dataset/savee\\DC_a05.wav",
         "DC_a05.wav",
         ".wav",
         "Anger"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Filepath</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Ext</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SAVEE</td>\n",
       "      <td>./dataset/savee\\DC_a01.wav</td>\n",
       "      <td>DC_a01.wav</td>\n",
       "      <td>.wav</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SAVEE</td>\n",
       "      <td>./dataset/savee\\DC_a02.wav</td>\n",
       "      <td>DC_a02.wav</td>\n",
       "      <td>.wav</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SAVEE</td>\n",
       "      <td>./dataset/savee\\DC_a03.wav</td>\n",
       "      <td>DC_a03.wav</td>\n",
       "      <td>.wav</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SAVEE</td>\n",
       "      <td>./dataset/savee\\DC_a04.wav</td>\n",
       "      <td>DC_a04.wav</td>\n",
       "      <td>.wav</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SAVEE</td>\n",
       "      <td>./dataset/savee\\DC_a05.wav</td>\n",
       "      <td>DC_a05.wav</td>\n",
       "      <td>.wav</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id Dataset                    Filepath    Filename   Ext Emotion\n",
       "0  NaN   SAVEE  ./dataset/savee\\DC_a01.wav  DC_a01.wav  .wav   Anger\n",
       "1  NaN   SAVEE  ./dataset/savee\\DC_a02.wav  DC_a02.wav  .wav   Anger\n",
       "2  NaN   SAVEE  ./dataset/savee\\DC_a03.wav  DC_a03.wav  .wav   Anger\n",
       "3  NaN   SAVEE  ./dataset/savee\\DC_a04.wav  DC_a04.wav  .wav   Anger\n",
       "4  NaN   SAVEE  ./dataset/savee\\DC_a05.wav  DC_a05.wav  .wav   Anger"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "savee_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c66ebf4",
   "metadata": {},
   "source": [
    "### 6) TESS\n",
    "> https://www.kaggle.com/datasets/ejlok1/toronto-emotional-speech-set-tess\n",
    "\n",
    "- Labels in Folder name\n",
    "\n",
    "```shell\n",
    "OAF: 64, Female\n",
    "YAF: 26, Female\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261a08dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:37:21.187962Z",
     "start_time": "2023-11-01T02:37:21.175760Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OAF_angry', 'OAF_disgust', 'OAF_Fear', 'OAF_happy', 'OAF_neutral', 'OAF_Pleasant_surprise', 'OAF_Sad', 'YAF_angry', 'YAF_disgust', 'YAF_fear', 'YAF_happy', 'YAF_neutral', 'YAF_pleasant_surprised', 'YAF_sad']\n"
     ]
    }
   ],
   "source": [
    "tess_dir = './dataset/tess'\n",
    "tess_folders = os.listdir(tess_dir)\n",
    "print(tess_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d704cbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:37:21.446171Z",
     "start_time": "2023-11-01T02:37:21.411137Z"
    }
   },
   "outputs": [],
   "source": [
    "tess_filepath = []\n",
    "tess_filename = []\n",
    "tess_ext = []\n",
    "tess_emotion = []\n",
    "emotion_list = {\"angry\":\"Anger\", \"disgust\":\"Disgust\", \"happy\": \"Happy\", \"neutral\":\"Neutral\", \"Sad\":\"Sad\", \"sad\":\"Sad\", \n",
    "                \"Fear\":\"Fear\", \"fear\":\"Fear\", \"Pleasant_surprise\":\"Surprise\", \"pleasant_surprised\":\"Surprise\"}\n",
    "for f in tess_folders:\n",
    "    speaker = f[:3]\n",
    "    emotion = emotion_list[f[4:]]\n",
    "        \n",
    "    speaker = \"Tess_\" + speaker    \n",
    "    filenames = os.listdir(os.path.join(tess_dir, f))\n",
    "    filepaths = glob.glob(os.path.join(tess_dir, f, \"*.wav\"))\n",
    "    \n",
    "    for i in range(len(filenames)):\n",
    "        _, ext = os.path.splitext(filenames[i])\n",
    "        \n",
    "    \n",
    "        tess_filepath.append(filepaths[i])\n",
    "        tess_filename.append(filenames[i])\n",
    "        tess_ext.append(ext)\n",
    "        tess_emotion.append(emotion)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9235ad62",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:37:22.694724Z",
     "start_time": "2023-11-01T02:37:22.685552Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Number of TESS Dataset: 2798\n"
     ]
    }
   ],
   "source": [
    "tess_count = len(tess_filepath)\n",
    "print(\"The Number of TESS Dataset:\", tess_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ec66cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:37:22.875880Z",
     "start_time": "2023-11-01T02:37:22.860254Z"
    }
   },
   "outputs": [],
   "source": [
    "tess_df = pd.DataFrame(index = range(0, tess_count), \n",
    "                  columns = ['Id', 'Dataset', 'Filepath', 'Filename', 'Ext', 'Emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f0e778",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:37:23.092470Z",
     "start_time": "2023-11-01T02:37:23.076845Z"
    }
   },
   "outputs": [],
   "source": [
    "tess_df[\"Dataset\"] = [\"TESS\"] * tess_count\n",
    "tess_df[\"Filepath\"] = tess_filepath\n",
    "tess_df[\"Filename\"] = tess_filename\n",
    "tess_df[\"Ext\"] = tess_ext\n",
    "tess_df[\"Emotion\"] = tess_emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32298caa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:37:23.309305Z",
     "start_time": "2023-11-01T02:37:23.276821Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Id",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Dataset",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Filepath",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Filename",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Ext",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Emotion",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "d9b82b5a-21fc-4dd6-b879-c9b7f240a951",
       "rows": [
        [
         "0",
         null,
         "TESS",
         "./dataset/tess\\OAF_angry\\OAF_back_angry.wav",
         "OAF_back_angry.wav",
         ".wav",
         "Anger"
        ],
        [
         "1",
         null,
         "TESS",
         "./dataset/tess\\OAF_angry\\OAF_bar_angry.wav",
         "OAF_bar_angry.wav",
         ".wav",
         "Anger"
        ],
        [
         "2",
         null,
         "TESS",
         "./dataset/tess\\OAF_angry\\OAF_base_angry.wav",
         "OAF_base_angry.wav",
         ".wav",
         "Anger"
        ],
        [
         "3",
         null,
         "TESS",
         "./dataset/tess\\OAF_angry\\OAF_bath_angry.wav",
         "OAF_bath_angry.wav",
         ".wav",
         "Anger"
        ],
        [
         "4",
         null,
         "TESS",
         "./dataset/tess\\OAF_angry\\OAF_bean_angry.wav",
         "OAF_bean_angry.wav",
         ".wav",
         "Anger"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Filepath</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Ext</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>TESS</td>\n",
       "      <td>./dataset/tess\\OAF_angry\\OAF_back_angry.wav</td>\n",
       "      <td>OAF_back_angry.wav</td>\n",
       "      <td>.wav</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>TESS</td>\n",
       "      <td>./dataset/tess\\OAF_angry\\OAF_bar_angry.wav</td>\n",
       "      <td>OAF_bar_angry.wav</td>\n",
       "      <td>.wav</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>TESS</td>\n",
       "      <td>./dataset/tess\\OAF_angry\\OAF_base_angry.wav</td>\n",
       "      <td>OAF_base_angry.wav</td>\n",
       "      <td>.wav</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>TESS</td>\n",
       "      <td>./dataset/tess\\OAF_angry\\OAF_bath_angry.wav</td>\n",
       "      <td>OAF_bath_angry.wav</td>\n",
       "      <td>.wav</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>TESS</td>\n",
       "      <td>./dataset/tess\\OAF_angry\\OAF_bean_angry.wav</td>\n",
       "      <td>OAF_bean_angry.wav</td>\n",
       "      <td>.wav</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id Dataset                                     Filepath  \\\n",
       "0  NaN    TESS  ./dataset/tess\\OAF_angry\\OAF_back_angry.wav   \n",
       "1  NaN    TESS   ./dataset/tess\\OAF_angry\\OAF_bar_angry.wav   \n",
       "2  NaN    TESS  ./dataset/tess\\OAF_angry\\OAF_base_angry.wav   \n",
       "3  NaN    TESS  ./dataset/tess\\OAF_angry\\OAF_bath_angry.wav   \n",
       "4  NaN    TESS  ./dataset/tess\\OAF_angry\\OAF_bean_angry.wav   \n",
       "\n",
       "             Filename   Ext Emotion  \n",
       "0  OAF_back_angry.wav  .wav   Anger  \n",
       "1   OAF_bar_angry.wav  .wav   Anger  \n",
       "2  OAF_base_angry.wav  .wav   Anger  \n",
       "3  OAF_bath_angry.wav  .wav   Anger  \n",
       "4  OAF_bean_angry.wav  .wav   Anger  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tess_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141969be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T06:51:35.527911Z",
     "start_time": "2023-10-30T06:51:35.524425Z"
    }
   },
   "source": [
    "## 7) ESD\n",
    "> https://hltsingapore.github.io/ESD/download.html\n",
    "- There is only English data in folder `0011` to `0020`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2202e721",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:37:23.985266Z",
     "start_time": "2023-11-01T02:37:23.975687Z"
    }
   },
   "outputs": [],
   "source": [
    "esd_dir = './dataset/esd'\n",
    "esd_folders = os.listdir(esd_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e121db1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:37:24.192249Z",
     "start_time": "2023-11-01T02:37:24.160233Z"
    }
   },
   "outputs": [],
   "source": [
    "esd_sub_df = []\n",
    "for f in esd_folders:\n",
    "    path = os.path.join(esd_dir, f, f+\".txt\")\n",
    "    with open(path, \"r\") as f:\n",
    "        for line in f:\n",
    "            esd_sub_df.append(line.strip().split(\"\\t\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c425beb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:37:24.363835Z",
     "start_time": "2023-11-01T02:37:24.344127Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17500, 3)\n",
      "['0011_000001', 'The nine the eggs, I keep.', 'Neutral']\n",
      "The Number of ESD Dataset: 17500\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(esd_sub_df))\n",
    "print(esd_sub_df[0])\n",
    "\n",
    "esd_count = len(esd_sub_df)\n",
    "print(\"The Number of ESD Dataset:\", esd_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a7b2a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:37:24.606193Z",
     "start_time": "2023-11-01T02:37:24.526764Z"
    }
   },
   "outputs": [],
   "source": [
    "esd_ext = []\n",
    "esd_filename = []\n",
    "esd_filepath = []\n",
    "esd_emotion = []\n",
    "emotion_list = {\"Angry\":\"Anger\", \"Happy\":\"Happy\", \"Neutral\":\"Neutral\", \"Sad\":\"Sad\", \"Surprise\":\"Surprise\"}\n",
    "for sub in esd_sub_df:\n",
    "    ext = \".wav\"\n",
    "    filename = sub[0] + ext\n",
    "    speaker = sub[0][:4]\n",
    "    filepath = os.path.join(esd_dir, speaker, sub[2], filename)\n",
    "    \n",
    "    emotion = emotion_list[sub[2]]\n",
    "    \n",
    "    esd_ext.append(ext)\n",
    "    esd_filename.append(filename)\n",
    "    esd_filepath.append(filepath)\n",
    "    esd_emotion.append(emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad092d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:37:25.032595Z",
     "start_time": "2023-11-01T02:37:25.011342Z"
    }
   },
   "outputs": [],
   "source": [
    "esd_df = pd.DataFrame(index = range(0, esd_count), \n",
    "                  columns = ['Id', 'Dataset', 'Filepath', 'Filename', 'Ext', 'Emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677a5483",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:37:25.449594Z",
     "start_time": "2023-11-01T02:37:25.427535Z"
    }
   },
   "outputs": [],
   "source": [
    "esd_df['Dataset'] = [\"ESD\"] * esd_count\n",
    "esd_df['Filepath'] = esd_filepath\n",
    "esd_df['Filename'] = esd_filename\n",
    "esd_df['Ext'] = esd_ext\n",
    "esd_df['Emotion'] = esd_emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcb18d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:37:25.776061Z",
     "start_time": "2023-11-01T02:37:25.765063Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Id",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Dataset",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Filepath",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Filename",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Ext",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Emotion",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "5a415570-c2b7-4f36-9dcc-e95eb02ef24a",
       "rows": [
        [
         "0",
         null,
         "ESD",
         "./dataset/esd\\0011\\Neutral\\0011_000001.wav",
         "0011_000001.wav",
         ".wav",
         "Neutral"
        ],
        [
         "1",
         null,
         "ESD",
         "./dataset/esd\\0011\\Neutral\\0011_000002.wav",
         "0011_000002.wav",
         ".wav",
         "Neutral"
        ],
        [
         "2",
         null,
         "ESD",
         "./dataset/esd\\0011\\Neutral\\0011_000003.wav",
         "0011_000003.wav",
         ".wav",
         "Neutral"
        ],
        [
         "3",
         null,
         "ESD",
         "./dataset/esd\\0011\\Neutral\\0011_000004.wav",
         "0011_000004.wav",
         ".wav",
         "Neutral"
        ],
        [
         "4",
         null,
         "ESD",
         "./dataset/esd\\0011\\Neutral\\0011_000005.wav",
         "0011_000005.wav",
         ".wav",
         "Neutral"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Filepath</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Ext</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ESD</td>\n",
       "      <td>./dataset/esd\\0011\\Neutral\\0011_000001.wav</td>\n",
       "      <td>0011_000001.wav</td>\n",
       "      <td>.wav</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ESD</td>\n",
       "      <td>./dataset/esd\\0011\\Neutral\\0011_000002.wav</td>\n",
       "      <td>0011_000002.wav</td>\n",
       "      <td>.wav</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ESD</td>\n",
       "      <td>./dataset/esd\\0011\\Neutral\\0011_000003.wav</td>\n",
       "      <td>0011_000003.wav</td>\n",
       "      <td>.wav</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ESD</td>\n",
       "      <td>./dataset/esd\\0011\\Neutral\\0011_000004.wav</td>\n",
       "      <td>0011_000004.wav</td>\n",
       "      <td>.wav</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ESD</td>\n",
       "      <td>./dataset/esd\\0011\\Neutral\\0011_000005.wav</td>\n",
       "      <td>0011_000005.wav</td>\n",
       "      <td>.wav</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id Dataset                                    Filepath         Filename  \\\n",
       "0  NaN     ESD  ./dataset/esd\\0011\\Neutral\\0011_000001.wav  0011_000001.wav   \n",
       "1  NaN     ESD  ./dataset/esd\\0011\\Neutral\\0011_000002.wav  0011_000002.wav   \n",
       "2  NaN     ESD  ./dataset/esd\\0011\\Neutral\\0011_000003.wav  0011_000003.wav   \n",
       "3  NaN     ESD  ./dataset/esd\\0011\\Neutral\\0011_000004.wav  0011_000004.wav   \n",
       "4  NaN     ESD  ./dataset/esd\\0011\\Neutral\\0011_000005.wav  0011_000005.wav   \n",
       "\n",
       "    Ext  Emotion  \n",
       "0  .wav  Neutral  \n",
       "1  .wav  Neutral  \n",
       "2  .wav  Neutral  \n",
       "3  .wav  Neutral  \n",
       "4  .wav  Neutral  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "esd_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fc88d9",
   "metadata": {},
   "source": [
    "## 8) JL Corpus\n",
    "> https://www.kaggle.com/datasets/tli725/jl-corpus\n",
    "\n",
    "- Labels in Filename\n",
    "```\n",
    "File naming rule: (Gender)(speaker.ID)_(Emotion)_(Sentence.ID)(session.ID)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5916795a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:37:26.674342Z",
     "start_time": "2023-11-01T02:37:26.662549Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['female1_angry_10a_1.txt', 'female1_angry_10a_1.wav', 'female1_angry_10a_2.txt', 'female1_angry_10a_2.wav', 'female1_angry_10b_1.txt']\n"
     ]
    }
   ],
   "source": [
    "jl_dir = './dataset/jl-corpus/Raw JL corpus (unchecked and unannotated)/JL(wav+txt)'\n",
    "print(os.listdir(jl_dir)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0229fb85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:37:26.943652Z",
     "start_time": "2023-11-01T02:37:26.913973Z"
    }
   },
   "outputs": [],
   "source": [
    "jl_filename = os.listdir(jl_dir)\n",
    "jl_filename = [fn for fn in jl_filename if os.path.splitext(fn)[1] == '.wav']\n",
    "jl_filepath = glob.glob(os.path.join(jl_dir, \"*.wav\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d64a76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:37:27.178445Z",
     "start_time": "2023-11-01T02:37:27.161920Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Number of JL-Corpus Dataset: 2400\n"
     ]
    }
   ],
   "source": [
    "jl_count = len(jl_filename)\n",
    "print(\"The Number of JL-Corpus Dataset:\", jl_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fe418d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:37:27.525294Z",
     "start_time": "2023-11-01T02:37:27.362998Z"
    }
   },
   "outputs": [],
   "source": [
    "jl_ext = []\n",
    "jl_emotion = []\n",
    "emotion_list = {\"angry\":\"Anger\", \"anxious\":\"Anxious\", \"apologetic\":\"Apologetic\", \"assertive\":\"Assertive\", \"concerned\":\"Concerned\", \n",
    "                \"encouraging\":\"Encouraging\", \"excited\":\"Excited\", \"happy\":\"Happy\", \"neutral\":\"Neutral\", \"sad\":\"Sad\"}\n",
    "gender_list = {\"female1\":\"Female\", \"female2\":\"Female\", \"male1\":\"Male\", \"male2\":\"Male\"}\n",
    "for i in range(jl_count):\n",
    "    name, ext = os.path.splitext(jl_filename[i])\n",
    "    fn_list = jl_filename[i].split(\"_\")\n",
    "    \n",
    "    emotion = emotion_list[fn_list[1]]\n",
    "    \n",
    "    text = ''\n",
    "    with open(os.path.join(jl_dir, name + \".txt\"), \"r\") as f:\n",
    "        for line in f:\n",
    "            text += line\n",
    "\n",
    "    jl_ext.append(ext)\n",
    "    jl_emotion.append(emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56887d02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:37:27.628494Z",
     "start_time": "2023-11-01T02:37:27.612591Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Anger' 'Anxious' 'Apologetic' 'Assertive' 'Concerned' 'Encouraging'\n",
      " 'Excited' 'Happy' 'Neutral' 'Sad']\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(jl_emotion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f88d06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:37:27.893103Z",
     "start_time": "2023-11-01T02:37:27.877912Z"
    }
   },
   "outputs": [],
   "source": [
    "jl_df = pd.DataFrame(index = range(0, jl_count), \n",
    "                  columns = ['Id', 'Dataset', 'Filepath', 'Filename', 'Ext', 'Emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61003010",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:37:28.178573Z",
     "start_time": "2023-11-01T02:37:28.163916Z"
    }
   },
   "outputs": [],
   "source": [
    "jl_df['Dataset'] = ['JL-CORPUS'] * jl_count\n",
    "jl_df['Filepath'] = jl_filepath\n",
    "jl_df['Filename'] = jl_filename\n",
    "jl_df['Ext'] = jl_ext\n",
    "jl_df['Emotion'] = jl_emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae06bd66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:37:28.511865Z",
     "start_time": "2023-11-01T02:37:28.480898Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Id",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Dataset",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Filepath",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Filename",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Ext",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Emotion",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "271f4c43-1b4b-4936-9a1d-4c8db69f6d86",
       "rows": [
        [
         "0",
         null,
         "JL-CORPUS",
         "./dataset/jl-corpus/Raw JL corpus (unchecked and unannotated)/JL(wav+txt)\\female1_angry_10a_1.wav",
         "female1_angry_10a_1.wav",
         ".wav",
         "Anger"
        ],
        [
         "1",
         null,
         "JL-CORPUS",
         "./dataset/jl-corpus/Raw JL corpus (unchecked and unannotated)/JL(wav+txt)\\female1_angry_10a_2.wav",
         "female1_angry_10a_2.wav",
         ".wav",
         "Anger"
        ],
        [
         "2",
         null,
         "JL-CORPUS",
         "./dataset/jl-corpus/Raw JL corpus (unchecked and unannotated)/JL(wav+txt)\\female1_angry_10b_1.wav",
         "female1_angry_10b_1.wav",
         ".wav",
         "Anger"
        ],
        [
         "3",
         null,
         "JL-CORPUS",
         "./dataset/jl-corpus/Raw JL corpus (unchecked and unannotated)/JL(wav+txt)\\female1_angry_10b_2.wav",
         "female1_angry_10b_2.wav",
         ".wav",
         "Anger"
        ],
        [
         "4",
         null,
         "JL-CORPUS",
         "./dataset/jl-corpus/Raw JL corpus (unchecked and unannotated)/JL(wav+txt)\\female1_angry_11a_1.wav",
         "female1_angry_11a_1.wav",
         ".wav",
         "Anger"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Filepath</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Ext</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>JL-CORPUS</td>\n",
       "      <td>./dataset/jl-corpus/Raw JL corpus (unchecked a...</td>\n",
       "      <td>female1_angry_10a_1.wav</td>\n",
       "      <td>.wav</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>JL-CORPUS</td>\n",
       "      <td>./dataset/jl-corpus/Raw JL corpus (unchecked a...</td>\n",
       "      <td>female1_angry_10a_2.wav</td>\n",
       "      <td>.wav</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>JL-CORPUS</td>\n",
       "      <td>./dataset/jl-corpus/Raw JL corpus (unchecked a...</td>\n",
       "      <td>female1_angry_10b_1.wav</td>\n",
       "      <td>.wav</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>JL-CORPUS</td>\n",
       "      <td>./dataset/jl-corpus/Raw JL corpus (unchecked a...</td>\n",
       "      <td>female1_angry_10b_2.wav</td>\n",
       "      <td>.wav</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>JL-CORPUS</td>\n",
       "      <td>./dataset/jl-corpus/Raw JL corpus (unchecked a...</td>\n",
       "      <td>female1_angry_11a_1.wav</td>\n",
       "      <td>.wav</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id    Dataset                                           Filepath  \\\n",
       "0  NaN  JL-CORPUS  ./dataset/jl-corpus/Raw JL corpus (unchecked a...   \n",
       "1  NaN  JL-CORPUS  ./dataset/jl-corpus/Raw JL corpus (unchecked a...   \n",
       "2  NaN  JL-CORPUS  ./dataset/jl-corpus/Raw JL corpus (unchecked a...   \n",
       "3  NaN  JL-CORPUS  ./dataset/jl-corpus/Raw JL corpus (unchecked a...   \n",
       "4  NaN  JL-CORPUS  ./dataset/jl-corpus/Raw JL corpus (unchecked a...   \n",
       "\n",
       "                  Filename   Ext Emotion  \n",
       "0  female1_angry_10a_1.wav  .wav   Anger  \n",
       "1  female1_angry_10a_2.wav  .wav   Anger  \n",
       "2  female1_angry_10b_1.wav  .wav   Anger  \n",
       "3  female1_angry_10b_2.wav  .wav   Anger  \n",
       "4  female1_angry_11a_1.wav  .wav   Anger  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jl_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e592482",
   "metadata": {},
   "source": [
    "## 2. Make Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432efbda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T02:37:29.658813Z",
     "start_time": "2023-11-01T02:37:29.479816Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Id",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Dataset",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Filepath",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Filename",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Ext",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Emotion",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "d077e66a-7f30-489d-b3b6-f784394189ee",
       "rows": [
        [
         "0",
         null,
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_DFA_ANG_XX.wav",
         "1001_DFA_ANG_XX.wav",
         ".wav",
         "Anger"
        ],
        [
         "1",
         null,
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_DFA_DIS_XX.wav",
         "1001_DFA_DIS_XX.wav",
         ".wav",
         "Disgust"
        ],
        [
         "2",
         null,
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_DFA_FEA_XX.wav",
         "1001_DFA_FEA_XX.wav",
         ".wav",
         "Fear"
        ],
        [
         "3",
         null,
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_DFA_HAP_XX.wav",
         "1001_DFA_HAP_XX.wav",
         ".wav",
         "Happy"
        ],
        [
         "4",
         null,
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_DFA_NEU_XX.wav",
         "1001_DFA_NEU_XX.wav",
         ".wav",
         "Neutral"
        ],
        [
         "5",
         null,
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_DFA_SAD_XX.wav",
         "1001_DFA_SAD_XX.wav",
         ".wav",
         "Sad"
        ],
        [
         "6",
         null,
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_IEO_ANG_HI.wav",
         "1001_IEO_ANG_HI.wav",
         ".wav",
         "Anger"
        ],
        [
         "7",
         null,
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_IEO_ANG_LO.wav",
         "1001_IEO_ANG_LO.wav",
         ".wav",
         "Anger"
        ],
        [
         "8",
         null,
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_IEO_ANG_MD.wav",
         "1001_IEO_ANG_MD.wav",
         ".wav",
         "Anger"
        ],
        [
         "9",
         null,
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_IEO_DIS_HI.wav",
         "1001_IEO_DIS_HI.wav",
         ".wav",
         "Disgust"
        ],
        [
         "10",
         null,
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_IEO_DIS_LO.wav",
         "1001_IEO_DIS_LO.wav",
         ".wav",
         "Disgust"
        ],
        [
         "11",
         null,
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_IEO_DIS_MD.wav",
         "1001_IEO_DIS_MD.wav",
         ".wav",
         "Disgust"
        ],
        [
         "12",
         null,
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_IEO_FEA_HI.wav",
         "1001_IEO_FEA_HI.wav",
         ".wav",
         "Fear"
        ],
        [
         "13",
         null,
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_IEO_FEA_LO.wav",
         "1001_IEO_FEA_LO.wav",
         ".wav",
         "Fear"
        ],
        [
         "14",
         null,
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_IEO_FEA_MD.wav",
         "1001_IEO_FEA_MD.wav",
         ".wav",
         "Fear"
        ],
        [
         "15",
         null,
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_IEO_HAP_HI.wav",
         "1001_IEO_HAP_HI.wav",
         ".wav",
         "Happy"
        ],
        [
         "16",
         null,
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_IEO_HAP_LO.wav",
         "1001_IEO_HAP_LO.wav",
         ".wav",
         "Happy"
        ],
        [
         "17",
         null,
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_IEO_HAP_MD.wav",
         "1001_IEO_HAP_MD.wav",
         ".wav",
         "Happy"
        ],
        [
         "18",
         null,
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_IEO_NEU_XX.wav",
         "1001_IEO_NEU_XX.wav",
         ".wav",
         "Neutral"
        ],
        [
         "19",
         null,
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_IEO_SAD_HI.wav",
         "1001_IEO_SAD_HI.wav",
         ".wav",
         "Sad"
        ],
        [
         "20",
         null,
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_IEO_SAD_LO.wav",
         "1001_IEO_SAD_LO.wav",
         ".wav",
         "Sad"
        ],
        [
         "21",
         null,
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_IEO_SAD_MD.wav",
         "1001_IEO_SAD_MD.wav",
         ".wav",
         "Sad"
        ],
        [
         "22",
         null,
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_IOM_ANG_XX.wav",
         "1001_IOM_ANG_XX.wav",
         ".wav",
         "Anger"
        ],
        [
         "23",
         null,
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_IOM_DIS_XX.wav",
         "1001_IOM_DIS_XX.wav",
         ".wav",
         "Disgust"
        ],
        [
         "24",
         null,
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_IOM_FEA_XX.wav",
         "1001_IOM_FEA_XX.wav",
         ".wav",
         "Fear"
        ],
        [
         "25",
         null,
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_IOM_HAP_XX.wav",
         "1001_IOM_HAP_XX.wav",
         ".wav",
         "Happy"
        ],
        [
         "26",
         null,
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_IOM_NEU_XX.wav",
         "1001_IOM_NEU_XX.wav",
         ".wav",
         "Neutral"
        ],
        [
         "27",
         null,
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_IOM_SAD_XX.wav",
         "1001_IOM_SAD_XX.wav",
         ".wav",
         "Sad"
        ],
        [
         "28",
         null,
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_ITH_ANG_XX.wav",
         "1001_ITH_ANG_XX.wav",
         ".wav",
         "Anger"
        ],
        [
         "29",
         null,
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_ITH_DIS_XX.wav",
         "1001_ITH_DIS_XX.wav",
         ".wav",
         "Disgust"
        ],
        [
         "30",
         null,
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_ITH_FEA_XX.wav",
         "1001_ITH_FEA_XX.wav",
         ".wav",
         "Fear"
        ],
        [
         "31",
         null,
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_ITH_HAP_XX.wav",
         "1001_ITH_HAP_XX.wav",
         ".wav",
         "Happy"
        ],
        [
         "32",
         null,
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_ITH_NEU_XX.wav",
         "1001_ITH_NEU_XX.wav",
         ".wav",
         "Neutral"
        ],
        [
         "33",
         null,
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_ITH_SAD_XX.wav",
         "1001_ITH_SAD_XX.wav",
         ".wav",
         "Sad"
        ],
        [
         "34",
         null,
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_ITS_ANG_XX.wav",
         "1001_ITS_ANG_XX.wav",
         ".wav",
         "Anger"
        ],
        [
         "35",
         null,
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_ITS_DIS_XX.wav",
         "1001_ITS_DIS_XX.wav",
         ".wav",
         "Disgust"
        ],
        [
         "36",
         null,
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_ITS_FEA_XX.wav",
         "1001_ITS_FEA_XX.wav",
         ".wav",
         "Fear"
        ],
        [
         "37",
         null,
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_ITS_HAP_XX.wav",
         "1001_ITS_HAP_XX.wav",
         ".wav",
         "Happy"
        ],
        [
         "38",
         null,
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_ITS_NEU_XX.wav",
         "1001_ITS_NEU_XX.wav",
         ".wav",
         "Neutral"
        ],
        [
         "39",
         null,
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_ITS_SAD_XX.wav",
         "1001_ITS_SAD_XX.wav",
         ".wav",
         "Sad"
        ],
        [
         "40",
         null,
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_IWL_ANG_XX.wav",
         "1001_IWL_ANG_XX.wav",
         ".wav",
         "Anger"
        ],
        [
         "41",
         null,
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_IWL_DIS_XX.wav",
         "1001_IWL_DIS_XX.wav",
         ".wav",
         "Disgust"
        ],
        [
         "42",
         null,
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_IWL_FEA_XX.wav",
         "1001_IWL_FEA_XX.wav",
         ".wav",
         "Fear"
        ],
        [
         "43",
         null,
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_IWL_HAP_XX.wav",
         "1001_IWL_HAP_XX.wav",
         ".wav",
         "Happy"
        ],
        [
         "44",
         null,
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_IWL_NEU_XX.wav",
         "1001_IWL_NEU_XX.wav",
         ".wav",
         "Neutral"
        ],
        [
         "45",
         null,
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_IWL_SAD_XX.wav",
         "1001_IWL_SAD_XX.wav",
         ".wav",
         "Sad"
        ],
        [
         "46",
         null,
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_IWW_ANG_XX.wav",
         "1001_IWW_ANG_XX.wav",
         ".wav",
         "Anger"
        ],
        [
         "47",
         null,
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_IWW_DIS_XX.wav",
         "1001_IWW_DIS_XX.wav",
         ".wav",
         "Disgust"
        ],
        [
         "48",
         null,
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_IWW_FEA_XX.wav",
         "1001_IWW_FEA_XX.wav",
         ".wav",
         "Fear"
        ],
        [
         "49",
         null,
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_IWW_HAP_XX.wav",
         "1001_IWW_HAP_XX.wav",
         ".wav",
         "Happy"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 74702
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Filepath</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Ext</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>CREMA-D</td>\n",
       "      <td>./dataset/crema-d\\AudioWAV\\1001_DFA_ANG_XX.wav</td>\n",
       "      <td>1001_DFA_ANG_XX.wav</td>\n",
       "      <td>.wav</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>CREMA-D</td>\n",
       "      <td>./dataset/crema-d\\AudioWAV\\1001_DFA_DIS_XX.wav</td>\n",
       "      <td>1001_DFA_DIS_XX.wav</td>\n",
       "      <td>.wav</td>\n",
       "      <td>Disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>CREMA-D</td>\n",
       "      <td>./dataset/crema-d\\AudioWAV\\1001_DFA_FEA_XX.wav</td>\n",
       "      <td>1001_DFA_FEA_XX.wav</td>\n",
       "      <td>.wav</td>\n",
       "      <td>Fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>CREMA-D</td>\n",
       "      <td>./dataset/crema-d\\AudioWAV\\1001_DFA_HAP_XX.wav</td>\n",
       "      <td>1001_DFA_HAP_XX.wav</td>\n",
       "      <td>.wav</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>CREMA-D</td>\n",
       "      <td>./dataset/crema-d\\AudioWAV\\1001_DFA_NEU_XX.wav</td>\n",
       "      <td>1001_DFA_NEU_XX.wav</td>\n",
       "      <td>.wav</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74697</th>\n",
       "      <td>NaN</td>\n",
       "      <td>JL-CORPUS</td>\n",
       "      <td>./dataset/jl-corpus/Raw JL corpus (unchecked a...</td>\n",
       "      <td>male2_sad_8b_2.wav</td>\n",
       "      <td>.wav</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74698</th>\n",
       "      <td>NaN</td>\n",
       "      <td>JL-CORPUS</td>\n",
       "      <td>./dataset/jl-corpus/Raw JL corpus (unchecked a...</td>\n",
       "      <td>male2_sad_9a_1.wav</td>\n",
       "      <td>.wav</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74699</th>\n",
       "      <td>NaN</td>\n",
       "      <td>JL-CORPUS</td>\n",
       "      <td>./dataset/jl-corpus/Raw JL corpus (unchecked a...</td>\n",
       "      <td>male2_sad_9a_2.wav</td>\n",
       "      <td>.wav</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74700</th>\n",
       "      <td>NaN</td>\n",
       "      <td>JL-CORPUS</td>\n",
       "      <td>./dataset/jl-corpus/Raw JL corpus (unchecked a...</td>\n",
       "      <td>male2_sad_9b_1.wav</td>\n",
       "      <td>.wav</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74701</th>\n",
       "      <td>NaN</td>\n",
       "      <td>JL-CORPUS</td>\n",
       "      <td>./dataset/jl-corpus/Raw JL corpus (unchecked a...</td>\n",
       "      <td>male2_sad_9b_2.wav</td>\n",
       "      <td>.wav</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74702 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id    Dataset                                           Filepath  \\\n",
       "0      NaN    CREMA-D     ./dataset/crema-d\\AudioWAV\\1001_DFA_ANG_XX.wav   \n",
       "1      NaN    CREMA-D     ./dataset/crema-d\\AudioWAV\\1001_DFA_DIS_XX.wav   \n",
       "2      NaN    CREMA-D     ./dataset/crema-d\\AudioWAV\\1001_DFA_FEA_XX.wav   \n",
       "3      NaN    CREMA-D     ./dataset/crema-d\\AudioWAV\\1001_DFA_HAP_XX.wav   \n",
       "4      NaN    CREMA-D     ./dataset/crema-d\\AudioWAV\\1001_DFA_NEU_XX.wav   \n",
       "...    ...        ...                                                ...   \n",
       "74697  NaN  JL-CORPUS  ./dataset/jl-corpus/Raw JL corpus (unchecked a...   \n",
       "74698  NaN  JL-CORPUS  ./dataset/jl-corpus/Raw JL corpus (unchecked a...   \n",
       "74699  NaN  JL-CORPUS  ./dataset/jl-corpus/Raw JL corpus (unchecked a...   \n",
       "74700  NaN  JL-CORPUS  ./dataset/jl-corpus/Raw JL corpus (unchecked a...   \n",
       "74701  NaN  JL-CORPUS  ./dataset/jl-corpus/Raw JL corpus (unchecked a...   \n",
       "\n",
       "                  Filename   Ext  Emotion  \n",
       "0      1001_DFA_ANG_XX.wav  .wav    Anger  \n",
       "1      1001_DFA_DIS_XX.wav  .wav  Disgust  \n",
       "2      1001_DFA_FEA_XX.wav  .wav     Fear  \n",
       "3      1001_DFA_HAP_XX.wav  .wav    Happy  \n",
       "4      1001_DFA_NEU_XX.wav  .wav  Neutral  \n",
       "...                    ...   ...      ...  \n",
       "74697   male2_sad_8b_2.wav  .wav      Sad  \n",
       "74698   male2_sad_9a_1.wav  .wav      Sad  \n",
       "74699   male2_sad_9a_2.wav  .wav      Sad  \n",
       "74700   male2_sad_9b_1.wav  .wav      Sad  \n",
       "74701   male2_sad_9b_2.wav  .wav      Sad  \n",
       "\n",
       "[74702 rows x 6 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([crema_df, meld_df, mlend_df, rav_df, savee_df, tess_df, esd_df, jl_df], ignore_index = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1d6eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Dataset",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Filepath",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Filename",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Ext",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Emotion",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "9e5bb167-51be-4475-9926-a477e0ab09db",
       "rows": [
        [
         "74697",
         "74697",
         "JL-CORPUS",
         "./dataset/jl-corpus/Raw JL corpus (unchecked and unannotated)/JL(wav+txt)\\male2_sad_8b_2.wav",
         "male2_sad_8b_2.wav",
         ".wav",
         "Sad"
        ],
        [
         "74698",
         "74698",
         "JL-CORPUS",
         "./dataset/jl-corpus/Raw JL corpus (unchecked and unannotated)/JL(wav+txt)\\male2_sad_9a_1.wav",
         "male2_sad_9a_1.wav",
         ".wav",
         "Sad"
        ],
        [
         "74699",
         "74699",
         "JL-CORPUS",
         "./dataset/jl-corpus/Raw JL corpus (unchecked and unannotated)/JL(wav+txt)\\male2_sad_9a_2.wav",
         "male2_sad_9a_2.wav",
         ".wav",
         "Sad"
        ],
        [
         "74700",
         "74700",
         "JL-CORPUS",
         "./dataset/jl-corpus/Raw JL corpus (unchecked and unannotated)/JL(wav+txt)\\male2_sad_9b_1.wav",
         "male2_sad_9b_1.wav",
         ".wav",
         "Sad"
        ],
        [
         "74701",
         "74701",
         "JL-CORPUS",
         "./dataset/jl-corpus/Raw JL corpus (unchecked and unannotated)/JL(wav+txt)\\male2_sad_9b_2.wav",
         "male2_sad_9b_2.wav",
         ".wav",
         "Sad"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Filepath</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Ext</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74697</th>\n",
       "      <td>74697</td>\n",
       "      <td>JL-CORPUS</td>\n",
       "      <td>./dataset/jl-corpus/Raw JL corpus (unchecked a...</td>\n",
       "      <td>male2_sad_8b_2.wav</td>\n",
       "      <td>.wav</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74698</th>\n",
       "      <td>74698</td>\n",
       "      <td>JL-CORPUS</td>\n",
       "      <td>./dataset/jl-corpus/Raw JL corpus (unchecked a...</td>\n",
       "      <td>male2_sad_9a_1.wav</td>\n",
       "      <td>.wav</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74699</th>\n",
       "      <td>74699</td>\n",
       "      <td>JL-CORPUS</td>\n",
       "      <td>./dataset/jl-corpus/Raw JL corpus (unchecked a...</td>\n",
       "      <td>male2_sad_9a_2.wav</td>\n",
       "      <td>.wav</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74700</th>\n",
       "      <td>74700</td>\n",
       "      <td>JL-CORPUS</td>\n",
       "      <td>./dataset/jl-corpus/Raw JL corpus (unchecked a...</td>\n",
       "      <td>male2_sad_9b_1.wav</td>\n",
       "      <td>.wav</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74701</th>\n",
       "      <td>74701</td>\n",
       "      <td>JL-CORPUS</td>\n",
       "      <td>./dataset/jl-corpus/Raw JL corpus (unchecked a...</td>\n",
       "      <td>male2_sad_9b_2.wav</td>\n",
       "      <td>.wav</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id    Dataset                                           Filepath  \\\n",
       "74697  74697  JL-CORPUS  ./dataset/jl-corpus/Raw JL corpus (unchecked a...   \n",
       "74698  74698  JL-CORPUS  ./dataset/jl-corpus/Raw JL corpus (unchecked a...   \n",
       "74699  74699  JL-CORPUS  ./dataset/jl-corpus/Raw JL corpus (unchecked a...   \n",
       "74700  74700  JL-CORPUS  ./dataset/jl-corpus/Raw JL corpus (unchecked a...   \n",
       "74701  74701  JL-CORPUS  ./dataset/jl-corpus/Raw JL corpus (unchecked a...   \n",
       "\n",
       "                 Filename   Ext Emotion  \n",
       "74697  male2_sad_8b_2.wav  .wav     Sad  \n",
       "74698  male2_sad_9a_1.wav  .wav     Sad  \n",
       "74699  male2_sad_9a_2.wav  .wav     Sad  \n",
       "74700  male2_sad_9b_1.wav  .wav     Sad  \n",
       "74701  male2_sad_9b_2.wav  .wav     Sad  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Id'] = np.arange(len(df))\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4daba8c0",
   "metadata": {},
   "source": [
    "## 3. EDA Analysis of raw audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d6c3bb",
   "metadata": {},
   "source": [
    "### Audio duration analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de8699d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import matplotlib.pyplot as plt\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868daca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Dataset",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Filepath",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Filename",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Ext",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Emotion",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "134d4cec-6910-4eff-8478-7570f79a7e5b",
       "rows": [
        [
         "0",
         "0",
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_DFA_ANG_XX.wav",
         "1001_DFA_ANG_XX.wav",
         ".wav",
         "Anger"
        ],
        [
         "1",
         "1",
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_DFA_DIS_XX.wav",
         "1001_DFA_DIS_XX.wav",
         ".wav",
         "Disgust"
        ],
        [
         "2",
         "2",
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_DFA_FEA_XX.wav",
         "1001_DFA_FEA_XX.wav",
         ".wav",
         "Fear"
        ],
        [
         "3",
         "3",
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_DFA_HAP_XX.wav",
         "1001_DFA_HAP_XX.wav",
         ".wav",
         "Happy"
        ],
        [
         "4",
         "4",
         "CREMA-D",
         "./dataset/crema-d\\AudioWAV\\1001_DFA_NEU_XX.wav",
         "1001_DFA_NEU_XX.wav",
         ".wav",
         "Neutral"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Filepath</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Ext</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>CREMA-D</td>\n",
       "      <td>./dataset/crema-d\\AudioWAV\\1001_DFA_ANG_XX.wav</td>\n",
       "      <td>1001_DFA_ANG_XX.wav</td>\n",
       "      <td>.wav</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CREMA-D</td>\n",
       "      <td>./dataset/crema-d\\AudioWAV\\1001_DFA_DIS_XX.wav</td>\n",
       "      <td>1001_DFA_DIS_XX.wav</td>\n",
       "      <td>.wav</td>\n",
       "      <td>Disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CREMA-D</td>\n",
       "      <td>./dataset/crema-d\\AudioWAV\\1001_DFA_FEA_XX.wav</td>\n",
       "      <td>1001_DFA_FEA_XX.wav</td>\n",
       "      <td>.wav</td>\n",
       "      <td>Fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CREMA-D</td>\n",
       "      <td>./dataset/crema-d\\AudioWAV\\1001_DFA_HAP_XX.wav</td>\n",
       "      <td>1001_DFA_HAP_XX.wav</td>\n",
       "      <td>.wav</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>CREMA-D</td>\n",
       "      <td>./dataset/crema-d\\AudioWAV\\1001_DFA_NEU_XX.wav</td>\n",
       "      <td>1001_DFA_NEU_XX.wav</td>\n",
       "      <td>.wav</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Dataset                                        Filepath  \\\n",
       "0   0  CREMA-D  ./dataset/crema-d\\AudioWAV\\1001_DFA_ANG_XX.wav   \n",
       "1   1  CREMA-D  ./dataset/crema-d\\AudioWAV\\1001_DFA_DIS_XX.wav   \n",
       "2   2  CREMA-D  ./dataset/crema-d\\AudioWAV\\1001_DFA_FEA_XX.wav   \n",
       "3   3  CREMA-D  ./dataset/crema-d\\AudioWAV\\1001_DFA_HAP_XX.wav   \n",
       "4   4  CREMA-D  ./dataset/crema-d\\AudioWAV\\1001_DFA_NEU_XX.wav   \n",
       "\n",
       "              Filename   Ext  Emotion  \n",
       "0  1001_DFA_ANG_XX.wav  .wav    Anger  \n",
       "1  1001_DFA_DIS_XX.wav  .wav  Disgust  \n",
       "2  1001_DFA_FEA_XX.wav  .wav     Fear  \n",
       "3  1001_DFA_HAP_XX.wav  .wav    Happy  \n",
       "4  1001_DFA_NEU_XX.wav  .wav  Neutral  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd422d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['Id', 'Dataset', 'Filepath', 'Filename', 'Ext', 'Emotion']\n",
      "The number of dataset: 74702\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns:\", list(df.columns))\n",
    "print(\"The number of dataset:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c665ddc6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Use parallel processing to get durations\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutor() \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m---> 24\u001b[0m     durations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_duration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilepaths\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mduration\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m durations\n",
      "File \u001b[1;32mC:\\Python310\\lib\\concurrent\\futures\\_base.py:621\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[1;34m()\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[0;32m    619\u001b[0m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[0;32m    620\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 621\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_result_or_cancel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    623\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs\u001b[38;5;241m.\u001b[39mpop(), end_time \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic())\n",
      "File \u001b[1;32mC:\\Python310\\lib\\concurrent\\futures\\_base.py:319\u001b[0m, in \u001b[0;36m_result_or_cancel\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 319\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    321\u001b[0m         fut\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[1;32mC:\\Python310\\lib\\concurrent\\futures\\_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m--> 453\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mC:\\Python310\\lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def get_duration(filepath):\n",
    "    \"\"\"\n",
    "    Uses ffprobe to extract the duration (in seconds) of an audio/video file.\n",
    "    \"\"\"\n",
    "    command = [\n",
    "        'ffprobe',\n",
    "        '-v', 'error',\n",
    "        '-show_entries', 'format=duration',\n",
    "        '-of', 'default=noprint_wrappers=1:nokey=1',\n",
    "        filepath\n",
    "    ]\n",
    "    result = subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True)\n",
    "    try:\n",
    "        duration = float(result.stdout.strip())\n",
    "    except ValueError:\n",
    "        duration = None\n",
    "    return duration\n",
    "\n",
    "# Read your CSV file\n",
    "filepaths = df['Filepath'].tolist()\n",
    "\n",
    "# Use parallel processing to get durations\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    durations = list(executor.map(get_duration, filepaths))\n",
    "\n",
    "df['duration'] = durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccf3ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee4457b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bins for the histogram in intervals of 5 seconds\n",
    "max_duration = df['duration'].max()\n",
    "bins = np.arange(0, max_duration + 5, 5)\n",
    "\n",
    "# Plot the histogram of audio durations\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot the histogram and capture the returned values (counts, bin_edges, patches)\n",
    "counts, bin_edges, patches = plt.hist(df['duration'], bins=bins, edgecolor='black')\n",
    "\n",
    "plt.xlabel(\"Duration (seconds)\")\n",
    "plt.ylabel(\"Number of Audio Files\")\n",
    "plt.title(\"Histogram of Audio File Durations (5-second intervals)\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# Annotate each bar with its count value\n",
    "for patch in patches:\n",
    "    height = patch.get_height()\n",
    "    # Only annotate bars that have a non-zero count\n",
    "    if height > 0:\n",
    "        x = patch.get_x() + patch.get_width() / 2\n",
    "        plt.annotate(f'{int(height)}',\n",
    "                     (x, height),\n",
    "                     ha='center',\n",
    "                     va='bottom')\n",
    "\n",
    "plt.savefig(\"./plots/audio_duration_histogram_5seconds.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f77de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bins for the histogram in intervals of 2 seconds\n",
    "max_duration = df['duration'].max()\n",
    "bins = np.arange(0, max_duration + 2, 2)\n",
    "\n",
    "# Plot the histogram of audio durations\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot the histogram and capture the returned values (counts, bin_edges, patches)\n",
    "counts, bin_edges, patches = plt.hist(df['duration'], bins=bins, edgecolor='black')\n",
    "\n",
    "plt.xlabel(\"Duration (seconds)\")\n",
    "plt.ylabel(\"Number of Audio Files\")\n",
    "plt.title(\"Histogram of Audio File Durations (2-second intervals)\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# Annotate each bar with its count value\n",
    "for patch in patches:\n",
    "    height = patch.get_height()\n",
    "    # Only annotate bars that have a non-zero count\n",
    "    if height > 0:\n",
    "        x = patch.get_x() + patch.get_width() / 2\n",
    "        plt.annotate(f'{int(height)}',\n",
    "                     (x, height),\n",
    "                     ha='center',\n",
    "                     va='bottom')\n",
    "\n",
    "plt.savefig(\"./plots/audio_duration_histogram_2seconds.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43a0f99",
   "metadata": {},
   "source": [
    "The distribution shows a few outliers (some are very long), we filter those out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b43cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 7\n",
    "df = df[df['duration'] <= threshold].reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd608bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Id'] = np.arange(len(df))\n",
    "df = df[['Id', 'Dataset', 'Filepath', 'Filename', 'Ext', 'duration', 'Emotion']]\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62b9639",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./speech_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a2fec6",
   "metadata": {},
   "source": [
    "### Emotion distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b635b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_counts = df['Emotion'].value_counts()\n",
    "emotion_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29db9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the emotion counts as a bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = emotion_counts.plot(kind=\"bar\", edgecolor='black')\n",
    "plt.xlabel(\"Emotion\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Emotion Frequency Distribution\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Annotate each bar with its count value\n",
    "for p in ax.patches:\n",
    "    # Get the height of each bar (i.e., the count)\n",
    "    height = p.get_height()\n",
    "    # Place the annotation above the bar\n",
    "    ax.annotate(f'{int(height)}', \n",
    "                (p.get_x() + p.get_width() / 2, height),\n",
    "                ha='center', va='bottom')\n",
    "\n",
    "# Save the plot as an image file\n",
    "plt.savefig(\"./plots/emotion_counts_bar_chart.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8838ed3f",
   "metadata": {},
   "source": [
    "## 3. Splitting into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9faad572",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c52ee97",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Emotion', axis=1)\n",
    "y = df['Emotion']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf63ba93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape of the dataframes:\n",
    "print(\"Training set shapes:\", X_train.shape, y_train.shape)\n",
    "print(\"Test set shapes:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8272bca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25c159a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81847498",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc66913",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a14284b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d219a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ec2fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recombine the train dataset\n",
    "train_df = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "# Recombine the test dataset\n",
    "test_df = pd.concat([X_test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544fb1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7994cadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"./train_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3da426b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb53377",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(\"./test_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e85e496",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
