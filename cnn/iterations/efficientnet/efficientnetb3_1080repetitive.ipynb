{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune EfficientNet-B3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## efficientnetb3_1080repetitive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 1920x1080 repetitive-padded melspectrogram images without data augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the absolute path to the project root without relying on __file__\n",
    "notebook_path = os.getcwd()  # Gets current working directory\n",
    "project_root = os.path.abspath(os.path.join(notebook_path, \"../../..\"))\n",
    "sys.path.insert(0, project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the seed for reproducability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "if (torch.cuda.is_available()):\n",
    "    torch.cuda.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set some constant strings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'efficientnetb3_1080repetitive'\n",
    "\n",
    "train_csv = '../../../data/melspectrogram_train_dataset.csv'\n",
    "test_csv = '../../../data/melspectrogram_test_dataset.csv'\n",
    "val_csv = '../../../data/melspectrogram_val_dataset.csv'\n",
    "root_dir = '../../../data/'\n",
    "class_weights_path = '../../../data/class_weights.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import other helper classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnn.datasets.MelspectrogramDataset import MelSpectrogramDataset\n",
    "from cnn.pipeline.Pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.efficientnet_b3(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare for fine-tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of classes\n",
    "num_classes = 9\n",
    "\n",
    "# Freeze all layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modify final fully connected layer according to number of classes\n",
    "num_features = model.classifier[1].in_features\n",
    "model.classifier[1] = nn.Linear(num_features, num_classes)\n",
    "\n",
    "# Unfreeze the last 3 layers so that they can be fine-tuned\n",
    "# Adjust the indices based on the actual number of layers in model.features\n",
    "for idx in [-3, -2, -1]:  # Use negative indices to target the last 3 layers\n",
    "    for param in model.features[idx].parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "# Replace classifier\n",
    "num_features = model.classifier[1].in_features\n",
    "model.classifier[1] = nn.Linear(num_features, num_classes)\n",
    "\n",
    "# Unfreeze classifier\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Move model to GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the learning rate, criterion, optimizer, transformations, and number of epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "class_weights = torch.load(class_weights_path).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    # Resize the Mel spectrogram to 300x300, suitable for EfficientNet-B3\n",
    "    transforms.Resize((300, 300)),\n",
    "    transforms.ToTensor(),          # Convert to Tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[\n",
    "                         0.229, 0.224, 0.225])  # Normalize to ImageNet stats\n",
    "])\n",
    "\n",
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare datasets and dataloaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = MelSpectrogramDataset(\n",
    "    csv_file=train_csv, root_dir=root_dir, transform=transform)\n",
    "valset = MelSpectrogramDataset(\n",
    "    csv_file=val_csv, root_dir=root_dir, transform=transform)\n",
    "testset = MelSpectrogramDataset(\n",
    "    csv_file=test_csv, root_dir=root_dir, transform=transform)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=128,\n",
    "                         shuffle=True, num_workers=8, pin_memory=True)\n",
    "valloader = DataLoader(valset, batch_size=128,\n",
    "                       shuffle=False, num_workers=8, pin_memory=True)\n",
    "testloader = DataLoader(testset, batch_size=128,\n",
    "                        shuffle=False, num_workers=8, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pipeline.execute(\n",
    "    model=model,\n",
    "    labelmap=trainset.label_map,\n",
    "    trainloader=trainloader,\n",
    "    valloader=valloader,\n",
    "    testloader=testloader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    num_epochs=num_epochs,\n",
    "    model_name=model_name,\n",
    "    patience=5\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
